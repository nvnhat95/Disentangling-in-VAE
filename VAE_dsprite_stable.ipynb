{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_dsprite_stable.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3HPSfyfJUE1",
        "colab_type": "code",
        "outputId": "54c451f0-92ca-4fd7-a6be-3fd608e6de06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 29.4MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 34.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 34.9MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 37.9MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 41.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 32.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 34.1MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 36.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 32.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 32.9MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 32.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 32.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 32.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 32.9MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPH6FrBAJmDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_YbKr9HJowp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmhpBJVQJozP",
        "colab_type": "code",
        "outputId": "ce35409d-f9c4-4326-a9a4-7350235e8b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('data')\n",
        "try:\n",
        "    os.makedirs(local_download_path)\n",
        "except:\n",
        "    print(\"error\")\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'18qyv3XEVWeQKyQNeCFfpUu--PkPaRdpM' in parents\"}).GetList()\n",
        "\n",
        "for f in file_list:\n",
        "    # 3. Create & download by id.\n",
        "    print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "    fname = os.path.join(local_download_path, f['title'])\n",
        "    print('downloading to {}'.format(fname))\n",
        "    f_ = drive.CreateFile({'id': f['id']})\n",
        "    f_.GetContentFile(fname)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error\n",
            "title: dsprites_ndarray_64x64.npz, id: 1sLoovx3oF6XYZ4m7Ol99Wb4ykBzyaKDv\n",
            "downloading to data/dsprites_ndarray_64x64.npz\n",
            "title: datasets.py, id: 1M_qXS4b7214yBATneK6GS9dgee58rAyo\n",
            "downloading to data/datasets.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz0mD4eIJo2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mv data/datasets.py datasets.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36jOunX6KEzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "import torchvision\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "import os\n",
        "import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edaaVaCCKJI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CONFIG(object):\n",
        "    def __init__(self):\n",
        "        self.image_size = 64\n",
        "        self.device = torch.device(\"cuda\") # or \"cpu\"\n",
        "        self.batch_size = 64\n",
        "        self.num_classes = 10\n",
        "        self.latten_size = 10\n",
        "        self.beta = 4\n",
        "        self.use_BN = False\n",
        "        self.version = 'B-VAE'\n",
        "        self.KL_penalty = 'abs'\n",
        "        self.use_label = False\n",
        "        self.C_max = 20\n",
        "        self.iter_increase_C = 2e4\n",
        "        self.gamma = 10\n",
        "        \n",
        "config = CONFIG()\n",
        "assert config.version in ['VAE', 'B-VAE', 'U-VAE']\n",
        "assert config.KL_penalty in ['relu', 'abs']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMwwXYmzJo4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dsprites_dataloader = datasets.get_dsprites_dataloader(batch_size=config.batch_size, \n",
        "                                                       path_to_data='data/dsprites_ndarray_64x64.npz', subsample=-1)\n",
        "                                                      #subsample=256000)\n",
        "\n",
        "dataloader = dsprites_dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-M4tDJTJo7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # encoder\n",
        "        self._conv1    = nn.Conv2d(1, 32, 4, stride=2, padding=1)\n",
        "        self._conv1_BN = nn.BatchNorm2d(num_features=32)\n",
        "        self._conv2    = nn.Conv2d(32, 32, 4, stride=2, padding=1)\n",
        "        self._conv2_BN = nn.BatchNorm2d(num_features=32)\n",
        "        self._conv3    = nn.Conv2d(32, 32, 4, stride=2, padding=1)\n",
        "        self._conv3_BN = nn.BatchNorm2d(num_features=32)\n",
        "        self._conv4    = nn.Conv2d(32, 32, 4, stride=2, padding=1)\n",
        "        self._conv4_BN = nn.BatchNorm2d(num_features=32)\n",
        "        self._fc5     = nn.Linear(512, 256)\n",
        "        self._fc5_BN  = nn.BatchNorm1d(num_features=256)\n",
        "        self._fc6     = nn.Linear(256, 256)\n",
        "        self._fc6_BN  = nn.BatchNorm1d(num_features=256)\n",
        "        self._fc71     = nn.Linear(256, config.latten_size)\n",
        "        self._fc72     = nn.Linear(256, config.latten_size)\n",
        "        self._fc8      = nn.Linear(config.latten_size * 2, config.latten_size * 2)\n",
        "\n",
        "        # decoder\n",
        "        if config.use_label:\n",
        "            self.fc7_   = nn.Linear(config.latten_size + config.num_classes, 256)\n",
        "        else:\n",
        "            self.fc7_   = nn.Linear(config.latten_size, 256)\n",
        "        self.fc7_BN     = nn.BatchNorm1d(num_features=256)\n",
        "        self.fc6_      = nn.Linear(256, 256)\n",
        "        self.fc6_BN     = nn.BatchNorm1d(num_features=256)\n",
        "        self.fc5_      = nn.Linear(256, 512)\n",
        "        self.fc5_BN     = nn.BatchNorm1d(num_features=512)\n",
        "        \n",
        "        self.conv4_    = nn.ConvTranspose2d(32, 32, 4, stride=2, padding=1)\n",
        "        self.conv4_BN  = nn.BatchNorm2d(num_features=32)\n",
        "        self.conv3_    = nn.ConvTranspose2d(32, 32, 4, stride=2, padding=1)\n",
        "        self.conv3_BN  = nn.BatchNorm2d(num_features=32)\n",
        "        self.conv2_    = nn.ConvTranspose2d(32, 32, 4, stride=2, padding=1)\n",
        "        self.conv2_BN  = nn.BatchNorm2d(num_features=32)\n",
        "        self.conv1_    = nn.ConvTranspose2d(32, 1, 4, stride=2, padding=1)\n",
        "        \n",
        "        self.mask = torch.ones((config.latten_size * 2, config.latten_size * 2), device=config.device)\n",
        "        for i in range(config.latten_size):\n",
        "            self.mask[i, i] = self.mask[i, i + config.latten_size] = 0\n",
        "            self.mask[i + config.latten_size, i + config.latten_size] = self.mask[i + config.latten_size, i] = 0\n",
        "        self.mask.to(config.device)\n",
        "        \n",
        "    def encode(self, x):\n",
        "        h = self._conv1(x)\n",
        "        h = self._conv1_BN(h) if config.use_BN else h\n",
        "        h = F.relu(h)\n",
        "        \n",
        "        h = self._conv2(h)\n",
        "        h = self._conv2_BN(h) if config.use_BN else h\n",
        "        h = F.relu(h)\n",
        "        \n",
        "        h = self._conv3(h)\n",
        "        h = self._conv3_BN(h) if config.use_BN else h\n",
        "        h = F.relu(h)\n",
        "        \n",
        "        h = self._conv4(h)\n",
        "        h = self._conv4_BN(h) if config.use_BN else h\n",
        "        h = F.relu(h)\n",
        "            \n",
        "        h = h.view(-1, 512)\n",
        "        h = self._fc5(h)\n",
        "        if config.use_BN:\n",
        "            h = self._fc5_BN(h)\n",
        "        h = F.relu(h)\n",
        "        \n",
        "        h = self._fc6(h)\n",
        "        if config.use_BN:\n",
        "            h = self._fc6_BN(h)\n",
        "        h = F.relu(h)\n",
        "        \n",
        "        mean = self._fc71(h)\n",
        "        var = self._fc72(h)\n",
        "\n",
        "        return mean, var, h\n",
        "    \n",
        "    \n",
        "    def decode(self, z, y=None):\n",
        "        if config.use_label and y is not None:\n",
        "            z = torch.cat((z, y), dim=1)\n",
        "        \n",
        "        h = self.fc7_(z)\n",
        "        h = self.fc7_BN(h) if config.use_BN else h\n",
        "        h = F.relu(h)\n",
        "        \n",
        "        h = self.fc6_(h)\n",
        "        h = self.fc6_BN(h) if config.use_BN else h\n",
        "        h = F.relu(h)\n",
        "        \n",
        "        h = self.fc5_(h)\n",
        "        h = self.fc5_BN(h) if config.use_BN else h\n",
        "        h = F.relu(h)\n",
        "        \n",
        "        h = h.view(-1, 32, 4, 4)\n",
        "        \n",
        "        h = self.conv4_(h)\n",
        "        h = self.conv4_BN(h) if config.use_BN else h\n",
        "        h = F.relu(h)\n",
        "        \n",
        "        h = self.conv3_(h)\n",
        "        h = self.conv3_BN(h) if config.use_BN else h\n",
        "        h = F.relu(h)\n",
        "        \n",
        "        h = self.conv2_(h)\n",
        "        h = self.conv2_BN(h) if config.use_BN else h\n",
        "        h = F.relu(h)\n",
        "        \n",
        "        recon_x = self.conv1_(h)\n",
        "        \n",
        "        return recon_x\n",
        "\n",
        "    \n",
        "    def compute_predict(self, mean, var):\n",
        "        t = torch.cat((mean, var), dim=1)\n",
        "        self.mask.to(config.device)\n",
        "        self._fc8.weight = torch.nn.Parameter(self._fc8.weight.to(config.device) * self.mask)\n",
        "        #print(t.shape)\n",
        "        pred = self._fc8(t)\n",
        "        return pred\n",
        "    \n",
        "        \n",
        "    def forward(self, x, iteration, y=None):\n",
        "        mean, var, h = self.encode(x.view(-1, 1, config.image_size, config.image_size))\n",
        "\n",
        "        var = var.exp()\n",
        "        samples = torch.randn_like(mean) # sample: Normal distribution\n",
        "        z = mean + samples * torch.sqrt(var)\n",
        "\n",
        "        recon_x = self.decode(z, y)\n",
        "        \n",
        "        return mean, var, recon_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kn92BbzJo9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_recon_loss(x, recon_x):\n",
        "    return F.binary_cross_entropy_with_logits(recon_x, x, reduction='sum') / x.shape[0]\n",
        "\n",
        "def compute_KL_loss(mean, var):\n",
        "    KL_loss = -0.5 * torch.sum(1 + torch.log(var) - torch.pow(mean, 2) - var)\n",
        "    return KL_loss / mean.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziOmt4CtJpAR",
        "colab_type": "code",
        "outputId": "36b2fcf4-7fc3-4b9c-b861-007dbc8c6835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 44755
        }
      },
      "source": [
        "model = VAE().to(config.device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
        "\n",
        "global_iter = 0\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    \n",
        "    train_loss_accum = recon_loss_accum = 0\n",
        "    global global_iter\n",
        "    print(global_iter)\n",
        "    \n",
        "    C_max = torch.autograd.Variable(torch.cuda.FloatTensor([config.C_max]), requires_grad=False)\n",
        "    \n",
        "    for batch_idx, (X, Y) in enumerate(dataloader):\n",
        "        # load data to GPU\n",
        "        X = X.to(config.device)\n",
        "        Y_onehot = (Y.reshape(-1, 1) == torch.arange(config.num_classes).reshape(1, config.num_classes)).float()\n",
        "        Y_onehot = Y_onehot.to(config.device)\n",
        "        \n",
        "        # update iteration counter and reset gradients\n",
        "        global_iter += 1\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward\n",
        "        mean, var, recon_x = model(X, Y_onehot)\n",
        "        \n",
        "        # compute losses\n",
        "        recon_loss = compute_recon_loss(X, recon_x)\n",
        "        KL_loss = compute_KL_loss(mean, var)\n",
        "        \n",
        "        loss = recon_loss + KL_loss\n",
        "        if config.version == 'B-VAE':\n",
        "            loss = recon_loss + KL_loss * config.beta\n",
        "        elif config.version == 'U-VAE':\n",
        "            C = torch.clamp(C_max * global_iter / config.iter_increase_C, 0, config.C_max)\n",
        "            if config.KL_penalty == 'abs':\n",
        "                t = config.gamma * torch.abs((KL_loss - C))\n",
        "            elif config.KL_penalty == 'relu':\n",
        "                t = config.gamma * F.relu((KL_loss - C))\n",
        "            loss = recon_loss + t\n",
        "        \n",
        "        train_loss_accum += loss.item()\n",
        "        recon_loss_accum += recon_loss.item()\n",
        "        \n",
        "        # caculate gradients\n",
        "        loss.backward()\n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % 200 == 0:\n",
        "            print(recon_loss.item(), KL_loss.item())\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(X), len(dataloader.dataset),\n",
        "                100. * batch_idx / len(dataloader),\n",
        "                loss.item()))\n",
        "            \n",
        "    epoch_loss = train_loss_accum / len(dataloader.dataset) * config.batch_size\n",
        "    epoch_recon_loss = recon_loss_accum / len(dataloader.dataset) * config.batch_size\n",
        "    \n",
        "    print('====> Epoch: {} Average loss: {:.4f} \\tRecon Loss: {:.4f}'.format(epoch, epoch_loss, epoch_recon_loss))\n",
        "\n",
        "for epoch in range(0, 100):\n",
        "    train(epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "2423.5849609375 0.012721960432827473\n",
            "Train Epoch: 0 [0/737279 (0%)]\tLoss: 2423.635742\n",
            "537.4815673828125 0.006772113032639027\n",
            "Train Epoch: 0 [12800/737279 (2%)]\tLoss: 537.508667\n",
            "558.64013671875 0.7754918932914734\n",
            "Train Epoch: 0 [25600/737279 (3%)]\tLoss: 561.742126\n",
            "256.086181640625 7.606057167053223\n",
            "Train Epoch: 0 [38400/737279 (5%)]\tLoss: 286.510406\n",
            "131.8016815185547 11.484402656555176\n",
            "Train Epoch: 0 [51200/737279 (7%)]\tLoss: 177.739288\n",
            "115.77548217773438 10.171117782592773\n",
            "Train Epoch: 0 [64000/737279 (9%)]\tLoss: 156.459961\n",
            "116.3048324584961 9.98398208618164\n",
            "Train Epoch: 0 [76800/737279 (10%)]\tLoss: 156.240753\n",
            "116.44170379638672 9.781201362609863\n",
            "Train Epoch: 0 [89600/737279 (12%)]\tLoss: 155.566513\n",
            "109.57201385498047 9.532739639282227\n",
            "Train Epoch: 0 [102400/737279 (14%)]\tLoss: 147.702972\n",
            "113.14666748046875 9.79623031616211\n",
            "Train Epoch: 0 [115200/737279 (16%)]\tLoss: 152.331589\n",
            "116.96055603027344 9.615743637084961\n",
            "Train Epoch: 0 [128000/737279 (17%)]\tLoss: 155.423523\n",
            "122.450927734375 10.246109008789062\n",
            "Train Epoch: 0 [140800/737279 (19%)]\tLoss: 163.435364\n",
            "100.75709533691406 9.13283920288086\n",
            "Train Epoch: 0 [153600/737279 (21%)]\tLoss: 137.288452\n",
            "100.8324203491211 9.568601608276367\n",
            "Train Epoch: 0 [166400/737279 (23%)]\tLoss: 139.106827\n",
            "114.76675415039062 9.270282745361328\n",
            "Train Epoch: 0 [179200/737279 (24%)]\tLoss: 151.847885\n",
            "113.58191680908203 9.858699798583984\n",
            "Train Epoch: 0 [192000/737279 (26%)]\tLoss: 153.016724\n",
            "116.76106262207031 9.469005584716797\n",
            "Train Epoch: 0 [204800/737279 (28%)]\tLoss: 154.637085\n",
            "106.5410385131836 9.082473754882812\n",
            "Train Epoch: 0 [217600/737279 (30%)]\tLoss: 142.870941\n",
            "109.9217758178711 9.35281753540039\n",
            "Train Epoch: 0 [230400/737279 (31%)]\tLoss: 147.333038\n",
            "113.15160369873047 9.519816398620605\n",
            "Train Epoch: 0 [243200/737279 (33%)]\tLoss: 151.230865\n",
            "114.13005828857422 9.856270790100098\n",
            "Train Epoch: 0 [256000/737279 (35%)]\tLoss: 153.555145\n",
            "112.34197998046875 9.734370231628418\n",
            "Train Epoch: 0 [268800/737279 (36%)]\tLoss: 151.279465\n",
            "111.13212585449219 9.418840408325195\n",
            "Train Epoch: 0 [281600/737279 (38%)]\tLoss: 148.807495\n",
            "119.17984771728516 9.439023971557617\n",
            "Train Epoch: 0 [294400/737279 (40%)]\tLoss: 156.935944\n",
            "102.49982452392578 9.184325218200684\n",
            "Train Epoch: 0 [307200/737279 (42%)]\tLoss: 139.237122\n",
            "110.82048034667969 8.874897956848145\n",
            "Train Epoch: 0 [320000/737279 (43%)]\tLoss: 146.320068\n",
            "109.17408752441406 9.36862850189209\n",
            "Train Epoch: 0 [332800/737279 (45%)]\tLoss: 146.648605\n",
            "107.07388305664062 8.999224662780762\n",
            "Train Epoch: 0 [345600/737279 (47%)]\tLoss: 143.070786\n",
            "105.81427001953125 9.201749801635742\n",
            "Train Epoch: 0 [358400/737279 (49%)]\tLoss: 142.621277\n",
            "94.2724380493164 9.29859733581543\n",
            "Train Epoch: 0 [371200/737279 (50%)]\tLoss: 131.466827\n",
            "109.91603088378906 8.939194679260254\n",
            "Train Epoch: 0 [384000/737279 (52%)]\tLoss: 145.672806\n",
            "102.93241882324219 9.315130233764648\n",
            "Train Epoch: 0 [396800/737279 (54%)]\tLoss: 140.192932\n",
            "101.49113464355469 9.654218673706055\n",
            "Train Epoch: 0 [409600/737279 (56%)]\tLoss: 140.108002\n",
            "102.4616470336914 9.218908309936523\n",
            "Train Epoch: 0 [422400/737279 (57%)]\tLoss: 139.337280\n",
            "102.0239486694336 9.573700904846191\n",
            "Train Epoch: 0 [435200/737279 (59%)]\tLoss: 140.318756\n",
            "112.02299499511719 9.841198921203613\n",
            "Train Epoch: 0 [448000/737279 (61%)]\tLoss: 151.387787\n",
            "102.19355010986328 9.977725982666016\n",
            "Train Epoch: 0 [460800/737279 (62%)]\tLoss: 142.104462\n",
            "107.0903091430664 9.865142822265625\n",
            "Train Epoch: 0 [473600/737279 (64%)]\tLoss: 146.550873\n",
            "97.74943542480469 9.667768478393555\n",
            "Train Epoch: 0 [486400/737279 (66%)]\tLoss: 136.420502\n",
            "100.52359008789062 9.64207649230957\n",
            "Train Epoch: 0 [499200/737279 (68%)]\tLoss: 139.091888\n",
            "100.37039184570312 9.69517707824707\n",
            "Train Epoch: 0 [512000/737279 (69%)]\tLoss: 139.151093\n",
            "95.38465118408203 9.509245872497559\n",
            "Train Epoch: 0 [524800/737279 (71%)]\tLoss: 133.421631\n",
            "101.07923889160156 9.576539993286133\n",
            "Train Epoch: 0 [537600/737279 (73%)]\tLoss: 139.385406\n",
            "100.74665832519531 9.814074516296387\n",
            "Train Epoch: 0 [550400/737279 (75%)]\tLoss: 140.002960\n",
            "100.78971099853516 9.357959747314453\n",
            "Train Epoch: 0 [563200/737279 (76%)]\tLoss: 138.221558\n",
            "101.69707489013672 9.425983428955078\n",
            "Train Epoch: 0 [576000/737279 (78%)]\tLoss: 139.401001\n",
            "96.0453109741211 9.854124069213867\n",
            "Train Epoch: 0 [588800/737279 (80%)]\tLoss: 135.461807\n",
            "108.10983276367188 9.80765438079834\n",
            "Train Epoch: 0 [601600/737279 (82%)]\tLoss: 147.340454\n",
            "98.40576171875 9.654447555541992\n",
            "Train Epoch: 0 [614400/737279 (83%)]\tLoss: 137.023560\n",
            "91.86590576171875 9.575169563293457\n",
            "Train Epoch: 0 [627200/737279 (85%)]\tLoss: 130.166580\n",
            "96.65579223632812 9.822983741760254\n",
            "Train Epoch: 0 [640000/737279 (87%)]\tLoss: 135.947723\n",
            "103.44390869140625 9.801641464233398\n",
            "Train Epoch: 0 [652800/737279 (89%)]\tLoss: 142.650482\n",
            "99.44627380371094 10.071063995361328\n",
            "Train Epoch: 0 [665600/737279 (90%)]\tLoss: 139.730530\n",
            "102.19534301757812 9.806745529174805\n",
            "Train Epoch: 0 [678400/737279 (92%)]\tLoss: 141.422333\n",
            "99.09625244140625 9.584651947021484\n",
            "Train Epoch: 0 [691200/737279 (94%)]\tLoss: 137.434860\n",
            "97.61213684082031 9.922151565551758\n",
            "Train Epoch: 0 [704000/737279 (95%)]\tLoss: 137.300751\n",
            "93.88941192626953 9.586283683776855\n",
            "Train Epoch: 0 [716800/737279 (97%)]\tLoss: 132.234543\n",
            "95.50251007080078 9.763535499572754\n",
            "Train Epoch: 0 [729600/737279 (99%)]\tLoss: 134.556656\n",
            "====> Epoch: 0 Average loss: 171.6514 \tRecon Loss: 134.8243\n",
            "11520\n",
            "92.43900299072266 9.968830108642578\n",
            "Train Epoch: 1 [0/737279 (0%)]\tLoss: 132.314331\n",
            "106.82907104492188 9.655112266540527\n",
            "Train Epoch: 1 [12800/737279 (2%)]\tLoss: 145.449524\n",
            "106.08171081542969 9.991537094116211\n",
            "Train Epoch: 1 [25600/737279 (3%)]\tLoss: 146.047852\n",
            "103.14176940917969 9.8927640914917\n",
            "Train Epoch: 1 [38400/737279 (5%)]\tLoss: 142.712830\n",
            "100.23555755615234 9.730852127075195\n",
            "Train Epoch: 1 [51200/737279 (7%)]\tLoss: 139.158966\n",
            "96.66670989990234 10.55672836303711\n",
            "Train Epoch: 1 [64000/737279 (9%)]\tLoss: 138.893616\n",
            "95.35292053222656 9.700704574584961\n",
            "Train Epoch: 1 [76800/737279 (10%)]\tLoss: 134.155731\n",
            "94.7297134399414 9.440376281738281\n",
            "Train Epoch: 1 [89600/737279 (12%)]\tLoss: 132.491211\n",
            "99.0999755859375 10.047674179077148\n",
            "Train Epoch: 1 [102400/737279 (14%)]\tLoss: 139.290680\n",
            "102.83796691894531 9.636886596679688\n",
            "Train Epoch: 1 [115200/737279 (16%)]\tLoss: 141.385513\n",
            "95.81649780273438 9.888944625854492\n",
            "Train Epoch: 1 [128000/737279 (17%)]\tLoss: 135.372284\n",
            "93.73805236816406 9.415581703186035\n",
            "Train Epoch: 1 [140800/737279 (19%)]\tLoss: 131.400375\n",
            "95.33111572265625 9.594558715820312\n",
            "Train Epoch: 1 [153600/737279 (21%)]\tLoss: 133.709351\n",
            "103.23567199707031 9.790971755981445\n",
            "Train Epoch: 1 [166400/737279 (23%)]\tLoss: 142.399567\n",
            "95.54872131347656 9.524831771850586\n",
            "Train Epoch: 1 [179200/737279 (24%)]\tLoss: 133.648041\n",
            "82.93232727050781 9.759737014770508\n",
            "Train Epoch: 1 [192000/737279 (26%)]\tLoss: 121.971275\n",
            "93.25926971435547 9.679320335388184\n",
            "Train Epoch: 1 [204800/737279 (28%)]\tLoss: 131.976547\n",
            "97.18696594238281 9.794820785522461\n",
            "Train Epoch: 1 [217600/737279 (30%)]\tLoss: 136.366241\n",
            "95.40225982666016 9.580207824707031\n",
            "Train Epoch: 1 [230400/737279 (31%)]\tLoss: 133.723083\n",
            "96.18395233154297 9.736345291137695\n",
            "Train Epoch: 1 [243200/737279 (33%)]\tLoss: 135.129333\n",
            "97.49478149414062 9.830735206604004\n",
            "Train Epoch: 1 [256000/737279 (35%)]\tLoss: 136.817719\n",
            "97.00443267822266 9.5804443359375\n",
            "Train Epoch: 1 [268800/737279 (36%)]\tLoss: 135.326202\n",
            "86.97209167480469 9.67269515991211\n",
            "Train Epoch: 1 [281600/737279 (38%)]\tLoss: 125.662872\n",
            "98.11204528808594 9.893224716186523\n",
            "Train Epoch: 1 [294400/737279 (40%)]\tLoss: 137.684937\n",
            "96.03024291992188 9.439611434936523\n",
            "Train Epoch: 1 [307200/737279 (42%)]\tLoss: 133.788696\n",
            "96.78486633300781 9.922554969787598\n",
            "Train Epoch: 1 [320000/737279 (43%)]\tLoss: 136.475082\n",
            "94.81432342529297 9.803325653076172\n",
            "Train Epoch: 1 [332800/737279 (45%)]\tLoss: 134.027618\n",
            "90.50997924804688 9.362015724182129\n",
            "Train Epoch: 1 [345600/737279 (47%)]\tLoss: 127.958038\n",
            "91.11763000488281 9.523552894592285\n",
            "Train Epoch: 1 [358400/737279 (49%)]\tLoss: 129.211838\n",
            "91.05497741699219 9.799518585205078\n",
            "Train Epoch: 1 [371200/737279 (50%)]\tLoss: 130.253052\n",
            "87.3414535522461 9.55173110961914\n",
            "Train Epoch: 1 [384000/737279 (52%)]\tLoss: 125.548378\n",
            "100.701171875 9.762829780578613\n",
            "Train Epoch: 1 [396800/737279 (54%)]\tLoss: 139.752487\n",
            "95.5118637084961 9.812318801879883\n",
            "Train Epoch: 1 [409600/737279 (56%)]\tLoss: 134.761139\n",
            "96.49209594726562 9.534235000610352\n",
            "Train Epoch: 1 [422400/737279 (57%)]\tLoss: 134.629028\n",
            "88.55783081054688 9.449016571044922\n",
            "Train Epoch: 1 [435200/737279 (59%)]\tLoss: 126.353897\n",
            "88.598876953125 9.843631744384766\n",
            "Train Epoch: 1 [448000/737279 (61%)]\tLoss: 127.973404\n",
            "95.00186157226562 9.445652961730957\n",
            "Train Epoch: 1 [460800/737279 (62%)]\tLoss: 132.784470\n",
            "86.35679626464844 9.839316368103027\n",
            "Train Epoch: 1 [473600/737279 (64%)]\tLoss: 125.714066\n",
            "85.38116455078125 9.589254379272461\n",
            "Train Epoch: 1 [486400/737279 (66%)]\tLoss: 123.738182\n",
            "97.90638732910156 9.714130401611328\n",
            "Train Epoch: 1 [499200/737279 (68%)]\tLoss: 136.762909\n",
            "101.08155822753906 9.724580764770508\n",
            "Train Epoch: 1 [512000/737279 (69%)]\tLoss: 139.979889\n",
            "92.90665435791016 9.834236145019531\n",
            "Train Epoch: 1 [524800/737279 (71%)]\tLoss: 132.243591\n",
            "96.72566223144531 9.802667617797852\n",
            "Train Epoch: 1 [537600/737279 (73%)]\tLoss: 135.936340\n",
            "97.04322814941406 9.59811019897461\n",
            "Train Epoch: 1 [550400/737279 (75%)]\tLoss: 135.435669\n",
            "89.20033264160156 9.589459419250488\n",
            "Train Epoch: 1 [563200/737279 (76%)]\tLoss: 127.558167\n",
            "83.90088653564453 9.886462211608887\n",
            "Train Epoch: 1 [576000/737279 (78%)]\tLoss: 123.446732\n",
            "95.02455139160156 9.354116439819336\n",
            "Train Epoch: 1 [588800/737279 (80%)]\tLoss: 132.441010\n",
            "89.49136352539062 9.459672927856445\n",
            "Train Epoch: 1 [601600/737279 (82%)]\tLoss: 127.330055\n",
            "96.47669982910156 9.737552642822266\n",
            "Train Epoch: 1 [614400/737279 (83%)]\tLoss: 135.426910\n",
            "89.34183502197266 9.514078140258789\n",
            "Train Epoch: 1 [627200/737279 (85%)]\tLoss: 127.398148\n",
            "93.56985473632812 9.55080795288086\n",
            "Train Epoch: 1 [640000/737279 (87%)]\tLoss: 131.773087\n",
            "96.18470764160156 9.84182357788086\n",
            "Train Epoch: 1 [652800/737279 (89%)]\tLoss: 135.552002\n",
            "92.15727996826172 9.514142990112305\n",
            "Train Epoch: 1 [665600/737279 (90%)]\tLoss: 130.213852\n",
            "91.54766845703125 9.475786209106445\n",
            "Train Epoch: 1 [678400/737279 (92%)]\tLoss: 129.450806\n",
            "95.14832305908203 9.635498046875\n",
            "Train Epoch: 1 [691200/737279 (94%)]\tLoss: 133.690308\n",
            "86.73826599121094 9.556071281433105\n",
            "Train Epoch: 1 [704000/737279 (95%)]\tLoss: 124.962555\n",
            "87.42814636230469 9.74452018737793\n",
            "Train Epoch: 1 [716800/737279 (97%)]\tLoss: 126.406227\n",
            "90.13764190673828 9.727807998657227\n",
            "Train Epoch: 1 [729600/737279 (99%)]\tLoss: 129.048874\n",
            "====> Epoch: 1 Average loss: 134.1292 \tRecon Loss: 95.2439\n",
            "23040\n",
            "96.71278381347656 9.158496856689453\n",
            "Train Epoch: 2 [0/737279 (0%)]\tLoss: 133.346771\n",
            "89.63842010498047 9.59292221069336\n",
            "Train Epoch: 2 [12800/737279 (2%)]\tLoss: 128.010101\n",
            "95.72527313232422 9.862773895263672\n",
            "Train Epoch: 2 [25600/737279 (3%)]\tLoss: 135.176361\n",
            "88.07550048828125 10.048254013061523\n",
            "Train Epoch: 2 [38400/737279 (5%)]\tLoss: 128.268524\n",
            "100.06919860839844 9.635411262512207\n",
            "Train Epoch: 2 [51200/737279 (7%)]\tLoss: 138.610840\n",
            "85.75958251953125 9.968451499938965\n",
            "Train Epoch: 2 [64000/737279 (9%)]\tLoss: 125.633392\n",
            "94.37004089355469 9.52099609375\n",
            "Train Epoch: 2 [76800/737279 (10%)]\tLoss: 132.454025\n",
            "88.96022033691406 9.800433158874512\n",
            "Train Epoch: 2 [89600/737279 (12%)]\tLoss: 128.161957\n",
            "91.60624694824219 9.617860794067383\n",
            "Train Epoch: 2 [102400/737279 (14%)]\tLoss: 130.077698\n",
            "101.38814544677734 9.933743476867676\n",
            "Train Epoch: 2 [115200/737279 (16%)]\tLoss: 141.123123\n",
            "98.59294128417969 9.627823829650879\n",
            "Train Epoch: 2 [128000/737279 (17%)]\tLoss: 137.104233\n",
            "99.39440155029297 10.030329704284668\n",
            "Train Epoch: 2 [140800/737279 (19%)]\tLoss: 139.515717\n",
            "82.94786834716797 9.644295692443848\n",
            "Train Epoch: 2 [153600/737279 (21%)]\tLoss: 121.525055\n",
            "94.62478637695312 9.656322479248047\n",
            "Train Epoch: 2 [166400/737279 (23%)]\tLoss: 133.250076\n",
            "91.26307678222656 9.87154769897461\n",
            "Train Epoch: 2 [179200/737279 (24%)]\tLoss: 130.749268\n",
            "93.39187622070312 9.617081642150879\n",
            "Train Epoch: 2 [192000/737279 (26%)]\tLoss: 131.860199\n",
            "100.9278564453125 9.801056861877441\n",
            "Train Epoch: 2 [204800/737279 (28%)]\tLoss: 140.132080\n",
            "89.6585693359375 9.667160034179688\n",
            "Train Epoch: 2 [217600/737279 (30%)]\tLoss: 128.327209\n",
            "90.15238952636719 9.843879699707031\n",
            "Train Epoch: 2 [230400/737279 (31%)]\tLoss: 129.527908\n",
            "93.93476867675781 9.535125732421875\n",
            "Train Epoch: 2 [243200/737279 (33%)]\tLoss: 132.075272\n",
            "104.25144958496094 10.063360214233398\n",
            "Train Epoch: 2 [256000/737279 (35%)]\tLoss: 144.504883\n",
            "92.48527526855469 9.81025218963623\n",
            "Train Epoch: 2 [268800/737279 (36%)]\tLoss: 131.726288\n",
            "87.98918151855469 9.72215747833252\n",
            "Train Epoch: 2 [281600/737279 (38%)]\tLoss: 126.877808\n",
            "89.33242797851562 9.472932815551758\n",
            "Train Epoch: 2 [294400/737279 (40%)]\tLoss: 127.224159\n",
            "101.5283203125 9.35052490234375\n",
            "Train Epoch: 2 [307200/737279 (42%)]\tLoss: 138.930420\n",
            "93.77064514160156 9.918209075927734\n",
            "Train Epoch: 2 [320000/737279 (43%)]\tLoss: 133.443481\n",
            "98.08970642089844 9.844955444335938\n",
            "Train Epoch: 2 [332800/737279 (45%)]\tLoss: 137.469528\n",
            "90.26559448242188 9.996273040771484\n",
            "Train Epoch: 2 [345600/737279 (47%)]\tLoss: 130.250687\n",
            "95.87171936035156 9.76162338256836\n",
            "Train Epoch: 2 [358400/737279 (49%)]\tLoss: 134.918213\n",
            "97.02727508544922 9.65445327758789\n",
            "Train Epoch: 2 [371200/737279 (50%)]\tLoss: 135.645081\n",
            "85.00980377197266 9.641304969787598\n",
            "Train Epoch: 2 [384000/737279 (52%)]\tLoss: 123.575027\n",
            "97.32881927490234 9.983186721801758\n",
            "Train Epoch: 2 [396800/737279 (54%)]\tLoss: 137.261566\n",
            "90.75213623046875 9.710336685180664\n",
            "Train Epoch: 2 [409600/737279 (56%)]\tLoss: 129.593475\n",
            "86.2327880859375 9.957003593444824\n",
            "Train Epoch: 2 [422400/737279 (57%)]\tLoss: 126.060806\n",
            "94.75334930419922 9.868759155273438\n",
            "Train Epoch: 2 [435200/737279 (59%)]\tLoss: 134.228394\n",
            "91.70353698730469 10.11819076538086\n",
            "Train Epoch: 2 [448000/737279 (61%)]\tLoss: 132.176300\n",
            "98.62130737304688 9.736639976501465\n",
            "Train Epoch: 2 [460800/737279 (62%)]\tLoss: 137.567871\n",
            "90.31039428710938 9.452396392822266\n",
            "Train Epoch: 2 [473600/737279 (64%)]\tLoss: 128.119980\n",
            "86.896240234375 9.590456008911133\n",
            "Train Epoch: 2 [486400/737279 (66%)]\tLoss: 125.258064\n",
            "84.76150512695312 9.694700241088867\n",
            "Train Epoch: 2 [499200/737279 (68%)]\tLoss: 123.540306\n",
            "86.57190704345703 9.960042953491211\n",
            "Train Epoch: 2 [512000/737279 (69%)]\tLoss: 126.412079\n",
            "99.06708526611328 10.16051197052002\n",
            "Train Epoch: 2 [524800/737279 (71%)]\tLoss: 139.709137\n",
            "95.64134216308594 9.441017150878906\n",
            "Train Epoch: 2 [537600/737279 (73%)]\tLoss: 133.405411\n",
            "92.33418273925781 9.866325378417969\n",
            "Train Epoch: 2 [550400/737279 (75%)]\tLoss: 131.799484\n",
            "87.00314331054688 9.684444427490234\n",
            "Train Epoch: 2 [563200/737279 (76%)]\tLoss: 125.740921\n",
            "100.60675048828125 10.033835411071777\n",
            "Train Epoch: 2 [576000/737279 (78%)]\tLoss: 140.742096\n",
            "88.9610366821289 9.920089721679688\n",
            "Train Epoch: 2 [588800/737279 (80%)]\tLoss: 128.641388\n",
            "92.66494750976562 9.4882230758667\n",
            "Train Epoch: 2 [601600/737279 (82%)]\tLoss: 130.617844\n",
            "99.30024719238281 9.785776138305664\n",
            "Train Epoch: 2 [614400/737279 (83%)]\tLoss: 138.443359\n",
            "88.52571105957031 9.986258506774902\n",
            "Train Epoch: 2 [627200/737279 (85%)]\tLoss: 128.470749\n",
            "91.13397216796875 9.94618034362793\n",
            "Train Epoch: 2 [640000/737279 (87%)]\tLoss: 130.918701\n",
            "92.88119506835938 10.005279541015625\n",
            "Train Epoch: 2 [652800/737279 (89%)]\tLoss: 132.902313\n",
            "94.01060485839844 9.930387496948242\n",
            "Train Epoch: 2 [665600/737279 (90%)]\tLoss: 133.732147\n",
            "83.68128967285156 9.462209701538086\n",
            "Train Epoch: 2 [678400/737279 (92%)]\tLoss: 121.530128\n",
            "89.67594909667969 9.7897367477417\n",
            "Train Epoch: 2 [691200/737279 (94%)]\tLoss: 128.834900\n",
            "81.12867736816406 9.767434120178223\n",
            "Train Epoch: 2 [704000/737279 (95%)]\tLoss: 120.198410\n",
            "93.14376831054688 9.769824981689453\n",
            "Train Epoch: 2 [716800/737279 (97%)]\tLoss: 132.223068\n",
            "88.751953125 9.908259391784668\n",
            "Train Epoch: 2 [729600/737279 (99%)]\tLoss: 128.384995\n",
            "====> Epoch: 2 Average loss: 131.3440 \tRecon Loss: 92.3786\n",
            "34560\n",
            "92.83335876464844 9.828814506530762\n",
            "Train Epoch: 3 [0/737279 (0%)]\tLoss: 132.148621\n",
            "82.214111328125 10.03797721862793\n",
            "Train Epoch: 3 [12800/737279 (2%)]\tLoss: 122.366020\n",
            "101.87833404541016 9.479635238647461\n",
            "Train Epoch: 3 [25600/737279 (3%)]\tLoss: 139.796875\n",
            "85.26408386230469 9.68801212310791\n",
            "Train Epoch: 3 [38400/737279 (5%)]\tLoss: 124.016129\n",
            "93.46833801269531 9.72138786315918\n",
            "Train Epoch: 3 [51200/737279 (7%)]\tLoss: 132.353882\n",
            "94.99870300292969 9.181164741516113\n",
            "Train Epoch: 3 [64000/737279 (9%)]\tLoss: 131.723358\n",
            "83.36249542236328 9.4205961227417\n",
            "Train Epoch: 3 [76800/737279 (10%)]\tLoss: 121.044876\n",
            "86.42381286621094 9.879887580871582\n",
            "Train Epoch: 3 [89600/737279 (12%)]\tLoss: 125.943359\n",
            "91.60542297363281 9.624794960021973\n",
            "Train Epoch: 3 [102400/737279 (14%)]\tLoss: 130.104599\n",
            "85.58772277832031 9.562936782836914\n",
            "Train Epoch: 3 [115200/737279 (16%)]\tLoss: 123.839470\n",
            "85.59121704101562 9.786405563354492\n",
            "Train Epoch: 3 [128000/737279 (17%)]\tLoss: 124.736839\n",
            "86.48399353027344 9.84318733215332\n",
            "Train Epoch: 3 [140800/737279 (19%)]\tLoss: 125.856743\n",
            "92.88422393798828 10.25029468536377\n",
            "Train Epoch: 3 [153600/737279 (21%)]\tLoss: 133.885406\n",
            "85.21627807617188 9.931673049926758\n",
            "Train Epoch: 3 [166400/737279 (23%)]\tLoss: 124.942970\n",
            "84.64688110351562 9.735099792480469\n",
            "Train Epoch: 3 [179200/737279 (24%)]\tLoss: 123.587280\n",
            "95.59446716308594 9.786643028259277\n",
            "Train Epoch: 3 [192000/737279 (26%)]\tLoss: 134.741043\n",
            "90.55851745605469 9.856815338134766\n",
            "Train Epoch: 3 [204800/737279 (28%)]\tLoss: 129.985779\n",
            "89.6881332397461 9.711151123046875\n",
            "Train Epoch: 3 [217600/737279 (30%)]\tLoss: 128.532745\n",
            "86.70271301269531 9.875158309936523\n",
            "Train Epoch: 3 [230400/737279 (31%)]\tLoss: 126.203346\n",
            "76.88092041015625 9.706022262573242\n",
            "Train Epoch: 3 [243200/737279 (33%)]\tLoss: 115.705009\n",
            "98.70160675048828 9.881038665771484\n",
            "Train Epoch: 3 [256000/737279 (35%)]\tLoss: 138.225769\n",
            "87.8805923461914 9.578569412231445\n",
            "Train Epoch: 3 [268800/737279 (36%)]\tLoss: 126.194870\n",
            "89.68840026855469 9.695513725280762\n",
            "Train Epoch: 3 [281600/737279 (38%)]\tLoss: 128.470459\n",
            "104.67777252197266 9.83514404296875\n",
            "Train Epoch: 3 [294400/737279 (40%)]\tLoss: 144.018341\n",
            "96.94577026367188 9.421745300292969\n",
            "Train Epoch: 3 [307200/737279 (42%)]\tLoss: 134.632751\n",
            "90.98792266845703 9.61401081085205\n",
            "Train Epoch: 3 [320000/737279 (43%)]\tLoss: 129.443970\n",
            "92.5145263671875 9.574443817138672\n",
            "Train Epoch: 3 [332800/737279 (45%)]\tLoss: 130.812302\n",
            "85.52143859863281 9.846454620361328\n",
            "Train Epoch: 3 [345600/737279 (47%)]\tLoss: 124.907257\n",
            "83.07915496826172 10.193517684936523\n",
            "Train Epoch: 3 [358400/737279 (49%)]\tLoss: 123.853226\n",
            "89.48269653320312 9.889727592468262\n",
            "Train Epoch: 3 [371200/737279 (50%)]\tLoss: 129.041611\n",
            "90.01182556152344 9.877009391784668\n",
            "Train Epoch: 3 [384000/737279 (52%)]\tLoss: 129.519867\n",
            "90.88738250732422 9.987828254699707\n",
            "Train Epoch: 3 [396800/737279 (54%)]\tLoss: 130.838699\n",
            "94.41554260253906 9.792304992675781\n",
            "Train Epoch: 3 [409600/737279 (56%)]\tLoss: 133.584763\n",
            "90.0018310546875 10.225381851196289\n",
            "Train Epoch: 3 [422400/737279 (57%)]\tLoss: 130.903351\n",
            "91.78086853027344 9.742389678955078\n",
            "Train Epoch: 3 [435200/737279 (59%)]\tLoss: 130.750427\n",
            "90.42826843261719 9.629034996032715\n",
            "Train Epoch: 3 [448000/737279 (61%)]\tLoss: 128.944412\n",
            "96.53326416015625 9.621712684631348\n",
            "Train Epoch: 3 [460800/737279 (62%)]\tLoss: 135.020111\n",
            "92.45075988769531 9.81320571899414\n",
            "Train Epoch: 3 [473600/737279 (64%)]\tLoss: 131.703583\n",
            "89.88959503173828 9.744370460510254\n",
            "Train Epoch: 3 [486400/737279 (66%)]\tLoss: 128.867081\n",
            "98.77291870117188 9.987127304077148\n",
            "Train Epoch: 3 [499200/737279 (68%)]\tLoss: 138.721436\n",
            "81.682861328125 9.862009048461914\n",
            "Train Epoch: 3 [512000/737279 (69%)]\tLoss: 121.130898\n",
            "92.16912841796875 9.620498657226562\n",
            "Train Epoch: 3 [524800/737279 (71%)]\tLoss: 130.651123\n",
            "91.05845642089844 9.934869766235352\n",
            "Train Epoch: 3 [537600/737279 (73%)]\tLoss: 130.797943\n",
            "83.58570098876953 10.022605895996094\n",
            "Train Epoch: 3 [550400/737279 (75%)]\tLoss: 123.676125\n",
            "86.68527221679688 9.532610893249512\n",
            "Train Epoch: 3 [563200/737279 (76%)]\tLoss: 124.815720\n",
            "92.54351806640625 9.993529319763184\n",
            "Train Epoch: 3 [576000/737279 (78%)]\tLoss: 132.517639\n",
            "84.3822021484375 9.675291061401367\n",
            "Train Epoch: 3 [588800/737279 (80%)]\tLoss: 123.083366\n",
            "90.0404052734375 9.925275802612305\n",
            "Train Epoch: 3 [601600/737279 (82%)]\tLoss: 129.741516\n",
            "85.99560546875 10.152645111083984\n",
            "Train Epoch: 3 [614400/737279 (83%)]\tLoss: 126.606186\n",
            "82.16529846191406 9.805617332458496\n",
            "Train Epoch: 3 [627200/737279 (85%)]\tLoss: 121.387772\n",
            "88.56088256835938 9.876102447509766\n",
            "Train Epoch: 3 [640000/737279 (87%)]\tLoss: 128.065292\n",
            "84.13549041748047 9.451471328735352\n",
            "Train Epoch: 3 [652800/737279 (89%)]\tLoss: 121.941376\n",
            "92.84751892089844 9.68055248260498\n",
            "Train Epoch: 3 [665600/737279 (90%)]\tLoss: 131.569733\n",
            "85.70968627929688 10.167594909667969\n",
            "Train Epoch: 3 [678400/737279 (92%)]\tLoss: 126.380066\n",
            "92.91380310058594 9.942533493041992\n",
            "Train Epoch: 3 [691200/737279 (94%)]\tLoss: 132.683929\n",
            "93.54867553710938 10.12018871307373\n",
            "Train Epoch: 3 [704000/737279 (95%)]\tLoss: 134.029434\n",
            "85.11061096191406 9.733048439025879\n",
            "Train Epoch: 3 [716800/737279 (97%)]\tLoss: 124.042801\n",
            "89.18216705322266 10.154045104980469\n",
            "Train Epoch: 3 [729600/737279 (99%)]\tLoss: 129.798340\n",
            "====> Epoch: 3 Average loss: 129.3485 \tRecon Loss: 90.1006\n",
            "46080\n",
            "89.4832763671875 9.936586380004883\n",
            "Train Epoch: 4 [0/737279 (0%)]\tLoss: 129.229614\n",
            "86.68528747558594 10.19904899597168\n",
            "Train Epoch: 4 [12800/737279 (2%)]\tLoss: 127.481483\n",
            "89.67398071289062 9.541292190551758\n",
            "Train Epoch: 4 [25600/737279 (3%)]\tLoss: 127.839149\n",
            "84.5169906616211 9.826118469238281\n",
            "Train Epoch: 4 [38400/737279 (5%)]\tLoss: 123.821465\n",
            "87.33198547363281 9.861150741577148\n",
            "Train Epoch: 4 [51200/737279 (7%)]\tLoss: 126.776588\n",
            "85.32322692871094 10.168903350830078\n",
            "Train Epoch: 4 [64000/737279 (9%)]\tLoss: 125.998840\n",
            "99.22168731689453 9.91884994506836\n",
            "Train Epoch: 4 [76800/737279 (10%)]\tLoss: 138.897095\n",
            "96.57162475585938 9.964850425720215\n",
            "Train Epoch: 4 [89600/737279 (12%)]\tLoss: 136.431030\n",
            "93.69326782226562 9.668437957763672\n",
            "Train Epoch: 4 [102400/737279 (14%)]\tLoss: 132.367020\n",
            "85.3614501953125 9.87692928314209\n",
            "Train Epoch: 4 [115200/737279 (16%)]\tLoss: 124.869171\n",
            "83.65632629394531 10.075675964355469\n",
            "Train Epoch: 4 [128000/737279 (17%)]\tLoss: 123.959030\n",
            "91.4345703125 10.158470153808594\n",
            "Train Epoch: 4 [140800/737279 (19%)]\tLoss: 132.068451\n",
            "84.27127075195312 9.922574043273926\n",
            "Train Epoch: 4 [153600/737279 (21%)]\tLoss: 123.961563\n",
            "87.5966567993164 10.199420928955078\n",
            "Train Epoch: 4 [166400/737279 (23%)]\tLoss: 128.394348\n",
            "85.6142578125 9.767253875732422\n",
            "Train Epoch: 4 [179200/737279 (24%)]\tLoss: 124.683273\n",
            "96.34965515136719 9.865671157836914\n",
            "Train Epoch: 4 [192000/737279 (26%)]\tLoss: 135.812347\n",
            "86.82283020019531 9.492021560668945\n",
            "Train Epoch: 4 [204800/737279 (28%)]\tLoss: 124.790916\n",
            "86.12896728515625 9.881158828735352\n",
            "Train Epoch: 4 [217600/737279 (30%)]\tLoss: 125.653603\n",
            "86.27494049072266 9.779474258422852\n",
            "Train Epoch: 4 [230400/737279 (31%)]\tLoss: 125.392838\n",
            "86.59927368164062 9.842032432556152\n",
            "Train Epoch: 4 [243200/737279 (33%)]\tLoss: 125.967407\n",
            "87.92742919921875 10.109651565551758\n",
            "Train Epoch: 4 [256000/737279 (35%)]\tLoss: 128.366028\n",
            "82.00309753417969 10.090694427490234\n",
            "Train Epoch: 4 [268800/737279 (36%)]\tLoss: 122.365875\n",
            "82.75956726074219 9.956184387207031\n",
            "Train Epoch: 4 [281600/737279 (38%)]\tLoss: 122.584305\n",
            "90.6650619506836 10.014791488647461\n",
            "Train Epoch: 4 [294400/737279 (40%)]\tLoss: 130.724228\n",
            "91.5998764038086 9.981008529663086\n",
            "Train Epoch: 4 [307200/737279 (42%)]\tLoss: 131.523911\n",
            "84.00724792480469 10.040254592895508\n",
            "Train Epoch: 4 [320000/737279 (43%)]\tLoss: 124.168266\n",
            "94.5814208984375 9.911376953125\n",
            "Train Epoch: 4 [332800/737279 (45%)]\tLoss: 134.226929\n",
            "83.19287872314453 10.518959045410156\n",
            "Train Epoch: 4 [345600/737279 (47%)]\tLoss: 125.268715\n",
            "87.05422973632812 9.887073516845703\n",
            "Train Epoch: 4 [358400/737279 (49%)]\tLoss: 126.602524\n",
            "85.77906799316406 9.921957015991211\n",
            "Train Epoch: 4 [371200/737279 (50%)]\tLoss: 125.466896\n",
            "81.11331939697266 10.103645324707031\n",
            "Train Epoch: 4 [384000/737279 (52%)]\tLoss: 121.527901\n",
            "82.3592529296875 9.808526992797852\n",
            "Train Epoch: 4 [396800/737279 (54%)]\tLoss: 121.593361\n",
            "82.91526794433594 9.619029998779297\n",
            "Train Epoch: 4 [409600/737279 (56%)]\tLoss: 121.391388\n",
            "89.02749633789062 9.805998802185059\n",
            "Train Epoch: 4 [422400/737279 (57%)]\tLoss: 128.251495\n",
            "82.96627807617188 9.816960334777832\n",
            "Train Epoch: 4 [435200/737279 (59%)]\tLoss: 122.234116\n",
            "86.97299194335938 9.842117309570312\n",
            "Train Epoch: 4 [448000/737279 (61%)]\tLoss: 126.341461\n",
            "86.2428207397461 10.123836517333984\n",
            "Train Epoch: 4 [460800/737279 (62%)]\tLoss: 126.738167\n",
            "85.3900146484375 10.194547653198242\n",
            "Train Epoch: 4 [473600/737279 (64%)]\tLoss: 126.168205\n",
            "89.35955810546875 10.102090835571289\n",
            "Train Epoch: 4 [486400/737279 (66%)]\tLoss: 129.767914\n",
            "85.21731567382812 10.624011993408203\n",
            "Train Epoch: 4 [499200/737279 (68%)]\tLoss: 127.713364\n",
            "89.53057861328125 9.836353302001953\n",
            "Train Epoch: 4 [512000/737279 (69%)]\tLoss: 128.875992\n",
            "93.3768081665039 10.201693534851074\n",
            "Train Epoch: 4 [524800/737279 (71%)]\tLoss: 134.183578\n",
            "83.64603424072266 9.95516586303711\n",
            "Train Epoch: 4 [537600/737279 (73%)]\tLoss: 123.466698\n",
            "91.1048583984375 10.143571853637695\n",
            "Train Epoch: 4 [550400/737279 (75%)]\tLoss: 131.679138\n",
            "84.89553833007812 9.859588623046875\n",
            "Train Epoch: 4 [563200/737279 (76%)]\tLoss: 124.333893\n",
            "90.01378631591797 9.648967742919922\n",
            "Train Epoch: 4 [576000/737279 (78%)]\tLoss: 128.609650\n",
            "85.85216522216797 10.604612350463867\n",
            "Train Epoch: 4 [588800/737279 (80%)]\tLoss: 128.270615\n",
            "81.97395324707031 10.239387512207031\n",
            "Train Epoch: 4 [601600/737279 (82%)]\tLoss: 122.931503\n",
            "81.61016845703125 10.102655410766602\n",
            "Train Epoch: 4 [614400/737279 (83%)]\tLoss: 122.020790\n",
            "86.3179702758789 9.806356430053711\n",
            "Train Epoch: 4 [627200/737279 (85%)]\tLoss: 125.543396\n",
            "83.76397705078125 10.327042579650879\n",
            "Train Epoch: 4 [640000/737279 (87%)]\tLoss: 125.072144\n",
            "82.67820739746094 10.177034378051758\n",
            "Train Epoch: 4 [652800/737279 (89%)]\tLoss: 123.386345\n",
            "87.72228240966797 9.909622192382812\n",
            "Train Epoch: 4 [665600/737279 (90%)]\tLoss: 127.360771\n",
            "82.41903686523438 10.318625450134277\n",
            "Train Epoch: 4 [678400/737279 (92%)]\tLoss: 123.693542\n",
            "88.02055358886719 10.073332786560059\n",
            "Train Epoch: 4 [691200/737279 (94%)]\tLoss: 128.313889\n",
            "87.11227416992188 10.276778221130371\n",
            "Train Epoch: 4 [704000/737279 (95%)]\tLoss: 128.219391\n",
            "78.71630859375 10.089425086975098\n",
            "Train Epoch: 4 [716800/737279 (97%)]\tLoss: 119.074005\n",
            "76.16763305664062 9.852066993713379\n",
            "Train Epoch: 4 [729600/737279 (99%)]\tLoss: 115.575897\n",
            "====> Epoch: 4 Average loss: 127.0112 \tRecon Loss: 87.0584\n",
            "57600\n",
            "75.57301330566406 10.096946716308594\n",
            "Train Epoch: 5 [0/737279 (0%)]\tLoss: 115.960800\n",
            "83.89266967773438 9.826355934143066\n",
            "Train Epoch: 5 [12800/737279 (2%)]\tLoss: 123.198090\n",
            "88.65554809570312 10.174297332763672\n",
            "Train Epoch: 5 [25600/737279 (3%)]\tLoss: 129.352737\n",
            "83.07405090332031 10.062833786010742\n",
            "Train Epoch: 5 [38400/737279 (5%)]\tLoss: 123.325386\n",
            "78.42890930175781 10.158178329467773\n",
            "Train Epoch: 5 [51200/737279 (7%)]\tLoss: 119.061623\n",
            "77.00790405273438 10.2845458984375\n",
            "Train Epoch: 5 [64000/737279 (9%)]\tLoss: 118.146088\n",
            "79.65535736083984 10.108846664428711\n",
            "Train Epoch: 5 [76800/737279 (10%)]\tLoss: 120.090744\n",
            "84.09695434570312 10.264899253845215\n",
            "Train Epoch: 5 [89600/737279 (12%)]\tLoss: 125.156555\n",
            "80.91387939453125 10.095888137817383\n",
            "Train Epoch: 5 [102400/737279 (14%)]\tLoss: 121.297432\n",
            "82.24314880371094 10.330909729003906\n",
            "Train Epoch: 5 [115200/737279 (16%)]\tLoss: 123.566788\n",
            "84.83052825927734 10.076934814453125\n",
            "Train Epoch: 5 [128000/737279 (17%)]\tLoss: 125.138268\n",
            "87.65135955810547 10.161227226257324\n",
            "Train Epoch: 5 [140800/737279 (19%)]\tLoss: 128.296265\n",
            "82.65180969238281 10.42766284942627\n",
            "Train Epoch: 5 [153600/737279 (21%)]\tLoss: 124.362457\n",
            "81.89439392089844 10.337339401245117\n",
            "Train Epoch: 5 [166400/737279 (23%)]\tLoss: 123.243752\n",
            "75.87794494628906 10.056310653686523\n",
            "Train Epoch: 5 [179200/737279 (24%)]\tLoss: 116.103188\n",
            "80.45136260986328 10.501594543457031\n",
            "Train Epoch: 5 [192000/737279 (26%)]\tLoss: 122.457741\n",
            "85.15614318847656 10.337581634521484\n",
            "Train Epoch: 5 [204800/737279 (28%)]\tLoss: 126.506470\n",
            "84.89349365234375 10.180158615112305\n",
            "Train Epoch: 5 [217600/737279 (30%)]\tLoss: 125.614128\n",
            "82.30247497558594 10.114263534545898\n",
            "Train Epoch: 5 [230400/737279 (31%)]\tLoss: 122.759529\n",
            "82.68293762207031 9.752145767211914\n",
            "Train Epoch: 5 [243200/737279 (33%)]\tLoss: 121.691521\n",
            "95.39816284179688 10.171321868896484\n",
            "Train Epoch: 5 [256000/737279 (35%)]\tLoss: 136.083450\n",
            "86.447265625 10.159719467163086\n",
            "Train Epoch: 5 [268800/737279 (36%)]\tLoss: 127.086143\n",
            "83.80000305175781 10.18551254272461\n",
            "Train Epoch: 5 [281600/737279 (38%)]\tLoss: 124.542053\n",
            "84.47449493408203 10.751321792602539\n",
            "Train Epoch: 5 [294400/737279 (40%)]\tLoss: 127.479782\n",
            "81.59857177734375 10.650690078735352\n",
            "Train Epoch: 5 [307200/737279 (42%)]\tLoss: 124.201332\n",
            "82.63264465332031 10.127504348754883\n",
            "Train Epoch: 5 [320000/737279 (43%)]\tLoss: 123.142662\n",
            "88.58180236816406 10.318107604980469\n",
            "Train Epoch: 5 [332800/737279 (45%)]\tLoss: 129.854233\n",
            "79.24554443359375 10.356541633605957\n",
            "Train Epoch: 5 [345600/737279 (47%)]\tLoss: 120.671707\n",
            "86.55517578125 10.224723815917969\n",
            "Train Epoch: 5 [358400/737279 (49%)]\tLoss: 127.454071\n",
            "73.4005126953125 9.914146423339844\n",
            "Train Epoch: 5 [371200/737279 (50%)]\tLoss: 113.057098\n",
            "84.20755767822266 10.320956230163574\n",
            "Train Epoch: 5 [384000/737279 (52%)]\tLoss: 125.491379\n",
            "80.67925262451172 10.073213577270508\n",
            "Train Epoch: 5 [396800/737279 (54%)]\tLoss: 120.972107\n",
            "77.56314086914062 10.737077713012695\n",
            "Train Epoch: 5 [409600/737279 (56%)]\tLoss: 120.511452\n",
            "94.29447937011719 10.431587219238281\n",
            "Train Epoch: 5 [422400/737279 (57%)]\tLoss: 136.020828\n",
            "82.42472839355469 10.32804012298584\n",
            "Train Epoch: 5 [435200/737279 (59%)]\tLoss: 123.736893\n",
            "79.76617431640625 10.278289794921875\n",
            "Train Epoch: 5 [448000/737279 (61%)]\tLoss: 120.879333\n",
            "78.86878204345703 10.636792182922363\n",
            "Train Epoch: 5 [460800/737279 (62%)]\tLoss: 121.415955\n",
            "81.96403503417969 10.175415992736816\n",
            "Train Epoch: 5 [473600/737279 (64%)]\tLoss: 122.665695\n",
            "79.24858856201172 10.056863784790039\n",
            "Train Epoch: 5 [486400/737279 (66%)]\tLoss: 119.476044\n",
            "71.20460510253906 10.212242126464844\n",
            "Train Epoch: 5 [499200/737279 (68%)]\tLoss: 112.053574\n",
            "76.95529174804688 10.604476928710938\n",
            "Train Epoch: 5 [512000/737279 (69%)]\tLoss: 119.373199\n",
            "88.81546783447266 10.391876220703125\n",
            "Train Epoch: 5 [524800/737279 (71%)]\tLoss: 130.382965\n",
            "77.9806900024414 10.124641418457031\n",
            "Train Epoch: 5 [537600/737279 (73%)]\tLoss: 118.479256\n",
            "76.52601623535156 10.34649658203125\n",
            "Train Epoch: 5 [550400/737279 (75%)]\tLoss: 117.912003\n",
            "72.91218566894531 10.741085052490234\n",
            "Train Epoch: 5 [563200/737279 (76%)]\tLoss: 115.876526\n",
            "78.6458740234375 10.465177536010742\n",
            "Train Epoch: 5 [576000/737279 (78%)]\tLoss: 120.506584\n",
            "83.09561157226562 10.383308410644531\n",
            "Train Epoch: 5 [588800/737279 (80%)]\tLoss: 124.628845\n",
            "86.19347381591797 10.872349739074707\n",
            "Train Epoch: 5 [601600/737279 (82%)]\tLoss: 129.682877\n",
            "79.80115509033203 10.336337089538574\n",
            "Train Epoch: 5 [614400/737279 (83%)]\tLoss: 121.146500\n",
            "81.0194320678711 11.090947151184082\n",
            "Train Epoch: 5 [627200/737279 (85%)]\tLoss: 125.383224\n",
            "86.92182159423828 10.813941955566406\n",
            "Train Epoch: 5 [640000/737279 (87%)]\tLoss: 130.177582\n",
            "93.97693634033203 10.44786262512207\n",
            "Train Epoch: 5 [652800/737279 (89%)]\tLoss: 135.768387\n",
            "79.39906311035156 10.312074661254883\n",
            "Train Epoch: 5 [665600/737279 (90%)]\tLoss: 120.647362\n",
            "82.650390625 10.242740631103516\n",
            "Train Epoch: 5 [678400/737279 (92%)]\tLoss: 123.621353\n",
            "71.38826751708984 10.820039749145508\n",
            "Train Epoch: 5 [691200/737279 (94%)]\tLoss: 114.668427\n",
            "80.43577575683594 10.432470321655273\n",
            "Train Epoch: 5 [704000/737279 (95%)]\tLoss: 122.165657\n",
            "72.49541473388672 10.461755752563477\n",
            "Train Epoch: 5 [716800/737279 (97%)]\tLoss: 114.342438\n",
            "77.92648315429688 10.33945083618164\n",
            "Train Epoch: 5 [729600/737279 (99%)]\tLoss: 119.284286\n",
            "====> Epoch: 5 Average loss: 123.1067 \tRecon Loss: 81.7864\n",
            "69120\n",
            "83.58287048339844 10.384871482849121\n",
            "Train Epoch: 6 [0/737279 (0%)]\tLoss: 125.122360\n",
            "74.58619689941406 10.817302703857422\n",
            "Train Epoch: 6 [12800/737279 (2%)]\tLoss: 117.855408\n",
            "76.849365234375 10.609392166137695\n",
            "Train Epoch: 6 [25600/737279 (3%)]\tLoss: 119.286934\n",
            "76.42863464355469 10.325067520141602\n",
            "Train Epoch: 6 [38400/737279 (5%)]\tLoss: 117.728905\n",
            "83.43423461914062 10.4577054977417\n",
            "Train Epoch: 6 [51200/737279 (7%)]\tLoss: 125.265060\n",
            "78.45941162109375 9.998592376708984\n",
            "Train Epoch: 6 [64000/737279 (9%)]\tLoss: 118.453781\n",
            "65.55921936035156 10.416487693786621\n",
            "Train Epoch: 6 [76800/737279 (10%)]\tLoss: 107.225174\n",
            "87.04354095458984 10.228124618530273\n",
            "Train Epoch: 6 [89600/737279 (12%)]\tLoss: 127.956039\n",
            "76.98246765136719 10.186660766601562\n",
            "Train Epoch: 6 [102400/737279 (14%)]\tLoss: 117.729111\n",
            "88.05441284179688 10.237922668457031\n",
            "Train Epoch: 6 [115200/737279 (16%)]\tLoss: 129.006104\n",
            "70.91654968261719 10.770378112792969\n",
            "Train Epoch: 6 [128000/737279 (17%)]\tLoss: 113.998062\n",
            "86.27542114257812 10.267204284667969\n",
            "Train Epoch: 6 [140800/737279 (19%)]\tLoss: 127.344238\n",
            "85.39883422851562 10.577791213989258\n",
            "Train Epoch: 6 [153600/737279 (21%)]\tLoss: 127.709999\n",
            "79.12019348144531 10.61627197265625\n",
            "Train Epoch: 6 [166400/737279 (23%)]\tLoss: 121.585281\n",
            "79.53743743896484 10.369898796081543\n",
            "Train Epoch: 6 [179200/737279 (24%)]\tLoss: 121.017029\n",
            "81.61628723144531 10.595789909362793\n",
            "Train Epoch: 6 [192000/737279 (26%)]\tLoss: 123.999451\n",
            "73.24171447753906 10.54252815246582\n",
            "Train Epoch: 6 [204800/737279 (28%)]\tLoss: 115.411827\n",
            "75.33314514160156 10.134214401245117\n",
            "Train Epoch: 6 [217600/737279 (30%)]\tLoss: 115.870003\n",
            "77.6771240234375 10.160306930541992\n",
            "Train Epoch: 6 [230400/737279 (31%)]\tLoss: 118.318352\n",
            "76.45713806152344 10.8865966796875\n",
            "Train Epoch: 6 [243200/737279 (33%)]\tLoss: 120.003525\n",
            "75.46575164794922 10.957290649414062\n",
            "Train Epoch: 6 [256000/737279 (35%)]\tLoss: 119.294914\n",
            "81.20896911621094 10.568166732788086\n",
            "Train Epoch: 6 [268800/737279 (36%)]\tLoss: 123.481636\n",
            "76.83076477050781 10.398571014404297\n",
            "Train Epoch: 6 [281600/737279 (38%)]\tLoss: 118.425049\n",
            "71.0436019897461 10.798690795898438\n",
            "Train Epoch: 6 [294400/737279 (40%)]\tLoss: 114.238365\n",
            "69.40171813964844 10.745926856994629\n",
            "Train Epoch: 6 [307200/737279 (42%)]\tLoss: 112.385422\n",
            "80.9583740234375 10.417595863342285\n",
            "Train Epoch: 6 [320000/737279 (43%)]\tLoss: 122.628754\n",
            "78.16361236572266 10.351390838623047\n",
            "Train Epoch: 6 [332800/737279 (45%)]\tLoss: 119.569176\n",
            "79.16944122314453 10.572696685791016\n",
            "Train Epoch: 6 [345600/737279 (47%)]\tLoss: 121.460228\n",
            "74.79578399658203 10.262938499450684\n",
            "Train Epoch: 6 [358400/737279 (49%)]\tLoss: 115.847534\n",
            "78.08341217041016 10.57019329071045\n",
            "Train Epoch: 6 [371200/737279 (50%)]\tLoss: 120.364182\n",
            "69.765625 10.499409675598145\n",
            "Train Epoch: 6 [384000/737279 (52%)]\tLoss: 111.763260\n",
            "78.51050567626953 10.831482887268066\n",
            "Train Epoch: 6 [396800/737279 (54%)]\tLoss: 121.836441\n",
            "77.61337280273438 11.138446807861328\n",
            "Train Epoch: 6 [409600/737279 (56%)]\tLoss: 122.167160\n",
            "72.96070098876953 10.347124099731445\n",
            "Train Epoch: 6 [422400/737279 (57%)]\tLoss: 114.349197\n",
            "68.60964965820312 10.593810081481934\n",
            "Train Epoch: 6 [435200/737279 (59%)]\tLoss: 110.984894\n",
            "79.66534423828125 10.843450546264648\n",
            "Train Epoch: 6 [448000/737279 (61%)]\tLoss: 123.039146\n",
            "69.41584777832031 10.579143524169922\n",
            "Train Epoch: 6 [460800/737279 (62%)]\tLoss: 111.732422\n",
            "79.05718994140625 10.88852596282959\n",
            "Train Epoch: 6 [473600/737279 (64%)]\tLoss: 122.611298\n",
            "74.54611206054688 10.721198081970215\n",
            "Train Epoch: 6 [486400/737279 (66%)]\tLoss: 117.430908\n",
            "72.27368927001953 10.427255630493164\n",
            "Train Epoch: 6 [499200/737279 (68%)]\tLoss: 113.982712\n",
            "75.05469512939453 10.380735397338867\n",
            "Train Epoch: 6 [512000/737279 (69%)]\tLoss: 116.577637\n",
            "76.0064697265625 10.343832015991211\n",
            "Train Epoch: 6 [524800/737279 (71%)]\tLoss: 117.381798\n",
            "89.25379943847656 10.614006996154785\n",
            "Train Epoch: 6 [537600/737279 (73%)]\tLoss: 131.709824\n",
            "68.71357727050781 10.887866973876953\n",
            "Train Epoch: 6 [550400/737279 (75%)]\tLoss: 112.265045\n",
            "71.14845275878906 10.835699081420898\n",
            "Train Epoch: 6 [563200/737279 (76%)]\tLoss: 114.491249\n",
            "78.06524658203125 10.666072845458984\n",
            "Train Epoch: 6 [576000/737279 (78%)]\tLoss: 120.729538\n",
            "70.02315521240234 10.80697250366211\n",
            "Train Epoch: 6 [588800/737279 (80%)]\tLoss: 113.251045\n",
            "63.838722229003906 10.943565368652344\n",
            "Train Epoch: 6 [601600/737279 (82%)]\tLoss: 107.612984\n",
            "74.33380889892578 10.726278305053711\n",
            "Train Epoch: 6 [614400/737279 (83%)]\tLoss: 117.238922\n",
            "75.69039916992188 10.940533638000488\n",
            "Train Epoch: 6 [627200/737279 (85%)]\tLoss: 119.452530\n",
            "74.06401062011719 11.012248992919922\n",
            "Train Epoch: 6 [640000/737279 (87%)]\tLoss: 118.113007\n",
            "77.80693817138672 10.595005989074707\n",
            "Train Epoch: 6 [652800/737279 (89%)]\tLoss: 120.186966\n",
            "75.81446838378906 10.67819595336914\n",
            "Train Epoch: 6 [665600/737279 (90%)]\tLoss: 118.527252\n",
            "68.9560317993164 10.578330993652344\n",
            "Train Epoch: 6 [678400/737279 (92%)]\tLoss: 111.269356\n",
            "76.05335998535156 10.534997940063477\n",
            "Train Epoch: 6 [691200/737279 (94%)]\tLoss: 118.193352\n",
            "68.93653869628906 10.570680618286133\n",
            "Train Epoch: 6 [704000/737279 (95%)]\tLoss: 111.219261\n",
            "71.66600036621094 11.159431457519531\n",
            "Train Epoch: 6 [716800/737279 (97%)]\tLoss: 116.303726\n",
            "81.12734985351562 10.643072128295898\n",
            "Train Epoch: 6 [729600/737279 (99%)]\tLoss: 123.699638\n",
            "====> Epoch: 6 Average loss: 119.0675 \tRecon Loss: 76.5809\n",
            "80640\n",
            "76.9599838256836 10.89898681640625\n",
            "Train Epoch: 7 [0/737279 (0%)]\tLoss: 120.555931\n",
            "73.0417251586914 10.474566459655762\n",
            "Train Epoch: 7 [12800/737279 (2%)]\tLoss: 114.939987\n",
            "75.91999816894531 11.256397247314453\n",
            "Train Epoch: 7 [25600/737279 (3%)]\tLoss: 120.945587\n",
            "71.64611053466797 10.777568817138672\n",
            "Train Epoch: 7 [38400/737279 (5%)]\tLoss: 114.756386\n",
            "79.9726791381836 10.351326942443848\n",
            "Train Epoch: 7 [51200/737279 (7%)]\tLoss: 121.377991\n",
            "74.38627624511719 10.565802574157715\n",
            "Train Epoch: 7 [64000/737279 (9%)]\tLoss: 116.649490\n",
            "77.41926574707031 10.69748306274414\n",
            "Train Epoch: 7 [76800/737279 (10%)]\tLoss: 120.209198\n",
            "70.94270324707031 10.548871994018555\n",
            "Train Epoch: 7 [89600/737279 (12%)]\tLoss: 113.138191\n",
            "64.24195098876953 11.259699821472168\n",
            "Train Epoch: 7 [102400/737279 (14%)]\tLoss: 109.280746\n",
            "79.37422180175781 10.426942825317383\n",
            "Train Epoch: 7 [115200/737279 (16%)]\tLoss: 121.081993\n",
            "78.89501953125 10.56241226196289\n",
            "Train Epoch: 7 [128000/737279 (17%)]\tLoss: 121.144669\n",
            "70.06289672851562 10.890815734863281\n",
            "Train Epoch: 7 [140800/737279 (19%)]\tLoss: 113.626160\n",
            "77.54844665527344 11.191648483276367\n",
            "Train Epoch: 7 [153600/737279 (21%)]\tLoss: 122.315041\n",
            "74.17780303955078 10.430631637573242\n",
            "Train Epoch: 7 [166400/737279 (23%)]\tLoss: 115.900330\n",
            "72.99667358398438 10.587207794189453\n",
            "Train Epoch: 7 [179200/737279 (24%)]\tLoss: 115.345505\n",
            "77.4234619140625 11.233650207519531\n",
            "Train Epoch: 7 [192000/737279 (26%)]\tLoss: 122.358063\n",
            "76.45187377929688 10.628886222839355\n",
            "Train Epoch: 7 [204800/737279 (28%)]\tLoss: 118.967422\n",
            "76.86544799804688 11.00388240814209\n",
            "Train Epoch: 7 [217600/737279 (30%)]\tLoss: 120.880981\n",
            "74.20845031738281 10.475837707519531\n",
            "Train Epoch: 7 [230400/737279 (31%)]\tLoss: 116.111801\n",
            "74.69617462158203 10.610180854797363\n",
            "Train Epoch: 7 [243200/737279 (33%)]\tLoss: 117.136902\n",
            "74.80467224121094 11.259913444519043\n",
            "Train Epoch: 7 [256000/737279 (35%)]\tLoss: 119.844330\n",
            "63.98739242553711 10.814184188842773\n",
            "Train Epoch: 7 [268800/737279 (36%)]\tLoss: 107.244125\n",
            "74.60070037841797 10.744598388671875\n",
            "Train Epoch: 7 [281600/737279 (38%)]\tLoss: 117.579094\n",
            "73.75720977783203 11.295551300048828\n",
            "Train Epoch: 7 [294400/737279 (40%)]\tLoss: 118.939415\n",
            "75.07279968261719 10.596315383911133\n",
            "Train Epoch: 7 [307200/737279 (42%)]\tLoss: 117.458061\n",
            "72.51728057861328 10.840469360351562\n",
            "Train Epoch: 7 [320000/737279 (43%)]\tLoss: 115.879158\n",
            "68.04916381835938 10.864374160766602\n",
            "Train Epoch: 7 [332800/737279 (45%)]\tLoss: 111.506660\n",
            "79.09407806396484 10.891876220703125\n",
            "Train Epoch: 7 [345600/737279 (47%)]\tLoss: 122.661583\n",
            "82.19415283203125 10.808695793151855\n",
            "Train Epoch: 7 [358400/737279 (49%)]\tLoss: 125.428940\n",
            "72.48472595214844 10.146124839782715\n",
            "Train Epoch: 7 [371200/737279 (50%)]\tLoss: 113.069229\n",
            "78.48200988769531 10.559326171875\n",
            "Train Epoch: 7 [384000/737279 (52%)]\tLoss: 120.719315\n",
            "70.51213836669922 10.887066841125488\n",
            "Train Epoch: 7 [396800/737279 (54%)]\tLoss: 114.060410\n",
            "75.26123809814453 11.274154663085938\n",
            "Train Epoch: 7 [409600/737279 (56%)]\tLoss: 120.357857\n",
            "78.4083251953125 10.87495231628418\n",
            "Train Epoch: 7 [422400/737279 (57%)]\tLoss: 121.908134\n",
            "78.38614654541016 10.570241928100586\n",
            "Train Epoch: 7 [435200/737279 (59%)]\tLoss: 120.667114\n",
            "71.92991638183594 10.907503128051758\n",
            "Train Epoch: 7 [448000/737279 (61%)]\tLoss: 115.559929\n",
            "73.5658187866211 10.95564079284668\n",
            "Train Epoch: 7 [460800/737279 (62%)]\tLoss: 117.388382\n",
            "74.91624450683594 11.038729667663574\n",
            "Train Epoch: 7 [473600/737279 (64%)]\tLoss: 119.071167\n",
            "80.61302185058594 10.599748611450195\n",
            "Train Epoch: 7 [486400/737279 (66%)]\tLoss: 123.012016\n",
            "83.01255798339844 10.688344955444336\n",
            "Train Epoch: 7 [499200/737279 (68%)]\tLoss: 125.765938\n",
            "67.52677917480469 10.68842887878418\n",
            "Train Epoch: 7 [512000/737279 (69%)]\tLoss: 110.280495\n",
            "69.43965148925781 11.156550407409668\n",
            "Train Epoch: 7 [524800/737279 (71%)]\tLoss: 114.065857\n",
            "69.63790893554688 10.821455955505371\n",
            "Train Epoch: 7 [537600/737279 (73%)]\tLoss: 112.923737\n",
            "67.26783752441406 11.44163990020752\n",
            "Train Epoch: 7 [550400/737279 (75%)]\tLoss: 113.034393\n",
            "74.3614730834961 11.015722274780273\n",
            "Train Epoch: 7 [563200/737279 (76%)]\tLoss: 118.424362\n",
            "70.03677368164062 11.207873344421387\n",
            "Train Epoch: 7 [576000/737279 (78%)]\tLoss: 114.868271\n",
            "77.57086181640625 10.907439231872559\n",
            "Train Epoch: 7 [588800/737279 (80%)]\tLoss: 121.200623\n",
            "66.08767700195312 11.316707611083984\n",
            "Train Epoch: 7 [601600/737279 (82%)]\tLoss: 111.354507\n",
            "67.39836120605469 11.19925308227539\n",
            "Train Epoch: 7 [614400/737279 (83%)]\tLoss: 112.195374\n",
            "67.90541076660156 10.912593841552734\n",
            "Train Epoch: 7 [627200/737279 (85%)]\tLoss: 111.555786\n",
            "69.91948699951172 11.005224227905273\n",
            "Train Epoch: 7 [640000/737279 (87%)]\tLoss: 113.940384\n",
            "70.72930908203125 11.211008071899414\n",
            "Train Epoch: 7 [652800/737279 (89%)]\tLoss: 115.573341\n",
            "78.4448471069336 11.038198471069336\n",
            "Train Epoch: 7 [665600/737279 (90%)]\tLoss: 122.597641\n",
            "72.99564361572266 10.527883529663086\n",
            "Train Epoch: 7 [678400/737279 (92%)]\tLoss: 115.107178\n",
            "73.57608032226562 11.134902954101562\n",
            "Train Epoch: 7 [691200/737279 (94%)]\tLoss: 118.115692\n",
            "74.1522445678711 10.565109252929688\n",
            "Train Epoch: 7 [704000/737279 (95%)]\tLoss: 116.412682\n",
            "73.36410522460938 10.853560447692871\n",
            "Train Epoch: 7 [716800/737279 (97%)]\tLoss: 116.778351\n",
            "73.21290588378906 10.63637924194336\n",
            "Train Epoch: 7 [729600/737279 (99%)]\tLoss: 115.758423\n",
            "====> Epoch: 7 Average loss: 115.5386 \tRecon Loss: 72.0561\n",
            "92160\n",
            "69.54495239257812 10.662332534790039\n",
            "Train Epoch: 8 [0/737279 (0%)]\tLoss: 112.194283\n",
            "63.47361755371094 10.885433197021484\n",
            "Train Epoch: 8 [12800/737279 (2%)]\tLoss: 107.015350\n",
            "80.00559997558594 10.669221878051758\n",
            "Train Epoch: 8 [25600/737279 (3%)]\tLoss: 122.682487\n",
            "75.64644622802734 10.882562637329102\n",
            "Train Epoch: 8 [38400/737279 (5%)]\tLoss: 119.176697\n",
            "81.91204833984375 11.151491165161133\n",
            "Train Epoch: 8 [51200/737279 (7%)]\tLoss: 126.518013\n",
            "71.0068130493164 10.769094467163086\n",
            "Train Epoch: 8 [64000/737279 (9%)]\tLoss: 114.083191\n",
            "72.63780975341797 11.090503692626953\n",
            "Train Epoch: 8 [76800/737279 (10%)]\tLoss: 116.999825\n",
            "75.81987762451172 10.97504997253418\n",
            "Train Epoch: 8 [89600/737279 (12%)]\tLoss: 119.720078\n",
            "62.116966247558594 11.010040283203125\n",
            "Train Epoch: 8 [102400/737279 (14%)]\tLoss: 106.157127\n",
            "70.45986938476562 10.973030090332031\n",
            "Train Epoch: 8 [115200/737279 (16%)]\tLoss: 114.351990\n",
            "63.21141815185547 11.177067756652832\n",
            "Train Epoch: 8 [128000/737279 (17%)]\tLoss: 107.919693\n",
            "68.90907287597656 10.307684898376465\n",
            "Train Epoch: 8 [140800/737279 (19%)]\tLoss: 110.139816\n",
            "67.64106750488281 11.068571090698242\n",
            "Train Epoch: 8 [153600/737279 (21%)]\tLoss: 111.915352\n",
            "64.82656860351562 10.615026473999023\n",
            "Train Epoch: 8 [166400/737279 (23%)]\tLoss: 107.286674\n",
            "64.30624389648438 10.704086303710938\n",
            "Train Epoch: 8 [179200/737279 (24%)]\tLoss: 107.122589\n",
            "74.05255126953125 10.928274154663086\n",
            "Train Epoch: 8 [192000/737279 (26%)]\tLoss: 117.765648\n",
            "67.75213623046875 11.161836624145508\n",
            "Train Epoch: 8 [204800/737279 (28%)]\tLoss: 112.399483\n",
            "68.97308349609375 10.82308578491211\n",
            "Train Epoch: 8 [217600/737279 (30%)]\tLoss: 112.265427\n",
            "63.18305969238281 11.299300193786621\n",
            "Train Epoch: 8 [230400/737279 (31%)]\tLoss: 108.380264\n",
            "69.35150146484375 10.814369201660156\n",
            "Train Epoch: 8 [243200/737279 (33%)]\tLoss: 112.608978\n",
            "65.76951599121094 10.927358627319336\n",
            "Train Epoch: 8 [256000/737279 (35%)]\tLoss: 109.478951\n",
            "68.40800476074219 11.377050399780273\n",
            "Train Epoch: 8 [268800/737279 (36%)]\tLoss: 113.916206\n",
            "83.61520385742188 10.63259506225586\n",
            "Train Epoch: 8 [281600/737279 (38%)]\tLoss: 126.145584\n",
            "63.92732620239258 10.382875442504883\n",
            "Train Epoch: 8 [294400/737279 (40%)]\tLoss: 105.458832\n",
            "64.0194091796875 11.017430305480957\n",
            "Train Epoch: 8 [307200/737279 (42%)]\tLoss: 108.089127\n",
            "66.71902465820312 11.102535247802734\n",
            "Train Epoch: 8 [320000/737279 (43%)]\tLoss: 111.129166\n",
            "72.96916198730469 11.037750244140625\n",
            "Train Epoch: 8 [332800/737279 (45%)]\tLoss: 117.120163\n",
            "69.87590026855469 11.402144432067871\n",
            "Train Epoch: 8 [345600/737279 (47%)]\tLoss: 115.484482\n",
            "69.3524398803711 10.760982513427734\n",
            "Train Epoch: 8 [358400/737279 (49%)]\tLoss: 112.396370\n",
            "72.3155746459961 11.156259536743164\n",
            "Train Epoch: 8 [371200/737279 (50%)]\tLoss: 116.940613\n",
            "65.20159149169922 11.65833854675293\n",
            "Train Epoch: 8 [384000/737279 (52%)]\tLoss: 111.834946\n",
            "55.258235931396484 11.48741340637207\n",
            "Train Epoch: 8 [396800/737279 (54%)]\tLoss: 101.207886\n",
            "82.13154602050781 10.976037979125977\n",
            "Train Epoch: 8 [409600/737279 (56%)]\tLoss: 126.035698\n",
            "72.3074722290039 10.920032501220703\n",
            "Train Epoch: 8 [422400/737279 (57%)]\tLoss: 115.987602\n",
            "69.41859436035156 11.287338256835938\n",
            "Train Epoch: 8 [435200/737279 (59%)]\tLoss: 114.567947\n",
            "72.8197021484375 10.692256927490234\n",
            "Train Epoch: 8 [448000/737279 (61%)]\tLoss: 115.588730\n",
            "61.77162170410156 10.965022087097168\n",
            "Train Epoch: 8 [460800/737279 (62%)]\tLoss: 105.631714\n",
            "62.4390983581543 10.921488761901855\n",
            "Train Epoch: 8 [473600/737279 (64%)]\tLoss: 106.125053\n",
            "63.40852737426758 11.356391906738281\n",
            "Train Epoch: 8 [486400/737279 (66%)]\tLoss: 108.834091\n",
            "71.8736801147461 10.902511596679688\n",
            "Train Epoch: 8 [499200/737279 (68%)]\tLoss: 115.483727\n",
            "73.8871841430664 10.945460319519043\n",
            "Train Epoch: 8 [512000/737279 (69%)]\tLoss: 117.669022\n",
            "62.20343017578125 11.235877990722656\n",
            "Train Epoch: 8 [524800/737279 (71%)]\tLoss: 107.146942\n",
            "67.9161148071289 11.231321334838867\n",
            "Train Epoch: 8 [537600/737279 (73%)]\tLoss: 112.841400\n",
            "66.6193618774414 11.59211540222168\n",
            "Train Epoch: 8 [550400/737279 (75%)]\tLoss: 112.987823\n",
            "68.30203247070312 11.050472259521484\n",
            "Train Epoch: 8 [563200/737279 (76%)]\tLoss: 112.503922\n",
            "73.42610931396484 10.967442512512207\n",
            "Train Epoch: 8 [576000/737279 (78%)]\tLoss: 117.295883\n",
            "76.14236450195312 11.222965240478516\n",
            "Train Epoch: 8 [588800/737279 (80%)]\tLoss: 121.034225\n",
            "67.81137084960938 11.278715133666992\n",
            "Train Epoch: 8 [601600/737279 (82%)]\tLoss: 112.926231\n",
            "64.87105560302734 10.850944519042969\n",
            "Train Epoch: 8 [614400/737279 (83%)]\tLoss: 108.274834\n",
            "67.54524230957031 11.361970901489258\n",
            "Train Epoch: 8 [627200/737279 (85%)]\tLoss: 112.993126\n",
            "67.00094604492188 11.025649070739746\n",
            "Train Epoch: 8 [640000/737279 (87%)]\tLoss: 111.103546\n",
            "73.92879486083984 10.784698486328125\n",
            "Train Epoch: 8 [652800/737279 (89%)]\tLoss: 117.067589\n",
            "76.57349395751953 10.741260528564453\n",
            "Train Epoch: 8 [665600/737279 (90%)]\tLoss: 119.538536\n",
            "65.617431640625 11.050009727478027\n",
            "Train Epoch: 8 [678400/737279 (92%)]\tLoss: 109.817474\n",
            "69.68341827392578 11.083575248718262\n",
            "Train Epoch: 8 [691200/737279 (94%)]\tLoss: 114.017715\n",
            "67.61991119384766 11.746881484985352\n",
            "Train Epoch: 8 [704000/737279 (95%)]\tLoss: 114.607437\n",
            "76.19009399414062 10.80651569366455\n",
            "Train Epoch: 8 [716800/737279 (97%)]\tLoss: 119.416153\n",
            "80.84255981445312 11.300628662109375\n",
            "Train Epoch: 8 [729600/737279 (99%)]\tLoss: 126.045074\n",
            "====> Epoch: 8 Average loss: 113.6277 \tRecon Loss: 69.4531\n",
            "103680\n",
            "67.15772247314453 10.952235221862793\n",
            "Train Epoch: 9 [0/737279 (0%)]\tLoss: 110.966660\n",
            "73.42265319824219 10.827247619628906\n",
            "Train Epoch: 9 [12800/737279 (2%)]\tLoss: 116.731644\n",
            "70.65168762207031 11.064467430114746\n",
            "Train Epoch: 9 [25600/737279 (3%)]\tLoss: 114.909561\n",
            "70.29820251464844 10.610879898071289\n",
            "Train Epoch: 9 [38400/737279 (5%)]\tLoss: 112.741722\n",
            "70.85005187988281 11.505640029907227\n",
            "Train Epoch: 9 [51200/737279 (7%)]\tLoss: 116.872612\n",
            "66.36102294921875 10.966363906860352\n",
            "Train Epoch: 9 [64000/737279 (9%)]\tLoss: 110.226479\n",
            "79.03480529785156 11.403772354125977\n",
            "Train Epoch: 9 [76800/737279 (10%)]\tLoss: 124.649895\n",
            "69.02233123779297 11.151390075683594\n",
            "Train Epoch: 9 [89600/737279 (12%)]\tLoss: 113.627892\n",
            "80.36830139160156 11.080619812011719\n",
            "Train Epoch: 9 [102400/737279 (14%)]\tLoss: 124.690781\n",
            "59.45360565185547 11.375907897949219\n",
            "Train Epoch: 9 [115200/737279 (16%)]\tLoss: 104.957237\n",
            "65.4410629272461 11.157368659973145\n",
            "Train Epoch: 9 [128000/737279 (17%)]\tLoss: 110.070541\n",
            "62.84282684326172 11.711662292480469\n",
            "Train Epoch: 9 [140800/737279 (19%)]\tLoss: 109.689476\n",
            "72.20474243164062 11.205066680908203\n",
            "Train Epoch: 9 [153600/737279 (21%)]\tLoss: 117.025009\n",
            "73.31280517578125 11.034120559692383\n",
            "Train Epoch: 9 [166400/737279 (23%)]\tLoss: 117.449287\n",
            "62.273834228515625 10.707358360290527\n",
            "Train Epoch: 9 [179200/737279 (24%)]\tLoss: 105.103271\n",
            "69.04673767089844 10.815469741821289\n",
            "Train Epoch: 9 [192000/737279 (26%)]\tLoss: 112.308617\n",
            "69.69342041015625 11.062565803527832\n",
            "Train Epoch: 9 [204800/737279 (28%)]\tLoss: 113.943680\n",
            "70.63624572753906 11.015800476074219\n",
            "Train Epoch: 9 [217600/737279 (30%)]\tLoss: 114.699448\n",
            "72.26908111572266 11.321121215820312\n",
            "Train Epoch: 9 [230400/737279 (31%)]\tLoss: 117.553566\n",
            "67.9122543334961 11.53290843963623\n",
            "Train Epoch: 9 [243200/737279 (33%)]\tLoss: 114.043884\n",
            "69.32323455810547 10.772756576538086\n",
            "Train Epoch: 9 [256000/737279 (35%)]\tLoss: 112.414261\n",
            "70.53520202636719 11.063394546508789\n",
            "Train Epoch: 9 [268800/737279 (36%)]\tLoss: 114.788780\n",
            "72.3005142211914 10.975566864013672\n",
            "Train Epoch: 9 [281600/737279 (38%)]\tLoss: 116.202782\n",
            "65.62649536132812 11.08319091796875\n",
            "Train Epoch: 9 [294400/737279 (40%)]\tLoss: 109.959259\n",
            "70.77327728271484 11.191170692443848\n",
            "Train Epoch: 9 [307200/737279 (42%)]\tLoss: 115.537964\n",
            "71.509765625 11.18559455871582\n",
            "Train Epoch: 9 [320000/737279 (43%)]\tLoss: 116.252144\n",
            "65.80204772949219 10.905757904052734\n",
            "Train Epoch: 9 [332800/737279 (45%)]\tLoss: 109.425079\n",
            "65.12809753417969 10.838665008544922\n",
            "Train Epoch: 9 [345600/737279 (47%)]\tLoss: 108.482758\n",
            "64.96420288085938 11.461292266845703\n",
            "Train Epoch: 9 [358400/737279 (49%)]\tLoss: 110.809372\n",
            "63.69327163696289 11.307209014892578\n",
            "Train Epoch: 9 [371200/737279 (50%)]\tLoss: 108.922104\n",
            "64.04024505615234 11.325298309326172\n",
            "Train Epoch: 9 [384000/737279 (52%)]\tLoss: 109.341438\n",
            "65.28204345703125 11.596024513244629\n",
            "Train Epoch: 9 [396800/737279 (54%)]\tLoss: 111.666138\n",
            "58.82621765136719 11.211357116699219\n",
            "Train Epoch: 9 [409600/737279 (56%)]\tLoss: 103.671646\n",
            "71.6544189453125 11.053319931030273\n",
            "Train Epoch: 9 [422400/737279 (57%)]\tLoss: 115.867699\n",
            "70.95722198486328 11.328699111938477\n",
            "Train Epoch: 9 [435200/737279 (59%)]\tLoss: 116.272018\n",
            "70.09083557128906 11.047795295715332\n",
            "Train Epoch: 9 [448000/737279 (61%)]\tLoss: 114.282013\n",
            "62.132896423339844 11.20345401763916\n",
            "Train Epoch: 9 [460800/737279 (62%)]\tLoss: 106.946716\n",
            "67.25904846191406 11.203052520751953\n",
            "Train Epoch: 9 [473600/737279 (64%)]\tLoss: 112.071259\n",
            "71.52760314941406 11.198413848876953\n",
            "Train Epoch: 9 [486400/737279 (66%)]\tLoss: 116.321259\n",
            "63.35581588745117 11.220401763916016\n",
            "Train Epoch: 9 [499200/737279 (68%)]\tLoss: 108.237427\n",
            "68.52888488769531 10.94235610961914\n",
            "Train Epoch: 9 [512000/737279 (69%)]\tLoss: 112.298309\n",
            "67.72289276123047 11.506694793701172\n",
            "Train Epoch: 9 [524800/737279 (71%)]\tLoss: 113.749672\n",
            "74.71744537353516 10.882865905761719\n",
            "Train Epoch: 9 [537600/737279 (73%)]\tLoss: 118.248909\n",
            "79.0491943359375 10.492701530456543\n",
            "Train Epoch: 9 [550400/737279 (75%)]\tLoss: 121.020004\n",
            "72.07695770263672 10.653593063354492\n",
            "Train Epoch: 9 [563200/737279 (76%)]\tLoss: 114.691330\n",
            "69.06316375732422 10.720329284667969\n",
            "Train Epoch: 9 [576000/737279 (78%)]\tLoss: 111.944481\n",
            "68.72984313964844 11.190332412719727\n",
            "Train Epoch: 9 [588800/737279 (80%)]\tLoss: 113.491173\n",
            "61.53007507324219 11.522249221801758\n",
            "Train Epoch: 9 [601600/737279 (82%)]\tLoss: 107.619072\n",
            "64.85266876220703 11.536678314208984\n",
            "Train Epoch: 9 [614400/737279 (83%)]\tLoss: 110.999382\n",
            "61.26953125 11.041049003601074\n",
            "Train Epoch: 9 [627200/737279 (85%)]\tLoss: 105.433731\n",
            "72.67755126953125 11.444697380065918\n",
            "Train Epoch: 9 [640000/737279 (87%)]\tLoss: 118.456345\n",
            "64.70625305175781 11.725519180297852\n",
            "Train Epoch: 9 [652800/737279 (89%)]\tLoss: 111.608330\n",
            "70.16104125976562 11.37067985534668\n",
            "Train Epoch: 9 [665600/737279 (90%)]\tLoss: 115.643761\n",
            "61.47671127319336 11.389593124389648\n",
            "Train Epoch: 9 [678400/737279 (92%)]\tLoss: 107.035080\n",
            "63.84618377685547 11.028197288513184\n",
            "Train Epoch: 9 [691200/737279 (94%)]\tLoss: 107.958969\n",
            "82.32041931152344 11.28376579284668\n",
            "Train Epoch: 9 [704000/737279 (95%)]\tLoss: 127.455482\n",
            "71.5223617553711 10.905686378479004\n",
            "Train Epoch: 9 [716800/737279 (97%)]\tLoss: 115.145111\n",
            "66.9100341796875 11.160913467407227\n",
            "Train Epoch: 9 [729600/737279 (99%)]\tLoss: 111.553688\n",
            "====> Epoch: 9 Average loss: 112.8668 \tRecon Loss: 68.3830\n",
            "115200\n",
            "57.15645980834961 11.201791763305664\n",
            "Train Epoch: 10 [0/737279 (0%)]\tLoss: 101.963623\n",
            "68.91439056396484 11.243853569030762\n",
            "Train Epoch: 10 [12800/737279 (2%)]\tLoss: 113.889801\n",
            "68.520263671875 11.409509658813477\n",
            "Train Epoch: 10 [25600/737279 (3%)]\tLoss: 114.158302\n",
            "79.60450744628906 10.724388122558594\n",
            "Train Epoch: 10 [38400/737279 (5%)]\tLoss: 122.502060\n",
            "74.29356384277344 11.402687072753906\n",
            "Train Epoch: 10 [51200/737279 (7%)]\tLoss: 119.904312\n",
            "62.245887756347656 11.358196258544922\n",
            "Train Epoch: 10 [64000/737279 (9%)]\tLoss: 107.678673\n",
            "70.99066925048828 10.91324520111084\n",
            "Train Epoch: 10 [76800/737279 (10%)]\tLoss: 114.643646\n",
            "65.62324523925781 10.648646354675293\n",
            "Train Epoch: 10 [89600/737279 (12%)]\tLoss: 108.217834\n",
            "67.95574951171875 11.15814208984375\n",
            "Train Epoch: 10 [102400/737279 (14%)]\tLoss: 112.588318\n",
            "64.21790313720703 11.593360900878906\n",
            "Train Epoch: 10 [115200/737279 (16%)]\tLoss: 110.591347\n",
            "65.00534057617188 11.123380661010742\n",
            "Train Epoch: 10 [128000/737279 (17%)]\tLoss: 109.498863\n",
            "69.8576889038086 11.434835433959961\n",
            "Train Epoch: 10 [140800/737279 (19%)]\tLoss: 115.597031\n",
            "72.80707550048828 10.864870071411133\n",
            "Train Epoch: 10 [153600/737279 (21%)]\tLoss: 116.266556\n",
            "61.95964813232422 11.126381874084473\n",
            "Train Epoch: 10 [166400/737279 (23%)]\tLoss: 106.465179\n",
            "70.05394744873047 11.197381973266602\n",
            "Train Epoch: 10 [179200/737279 (24%)]\tLoss: 114.843475\n",
            "63.64575958251953 10.465916633605957\n",
            "Train Epoch: 10 [192000/737279 (26%)]\tLoss: 105.509430\n",
            "62.58992004394531 11.164499282836914\n",
            "Train Epoch: 10 [204800/737279 (28%)]\tLoss: 107.247917\n",
            "55.50135040283203 11.572729110717773\n",
            "Train Epoch: 10 [217600/737279 (30%)]\tLoss: 101.792267\n",
            "70.80702209472656 11.137580871582031\n",
            "Train Epoch: 10 [230400/737279 (31%)]\tLoss: 115.357346\n",
            "59.254730224609375 11.323149681091309\n",
            "Train Epoch: 10 [243200/737279 (33%)]\tLoss: 104.547333\n",
            "65.72335052490234 11.090547561645508\n",
            "Train Epoch: 10 [256000/737279 (35%)]\tLoss: 110.085541\n",
            "70.88257598876953 11.10338306427002\n",
            "Train Epoch: 10 [268800/737279 (36%)]\tLoss: 115.296112\n",
            "78.22525024414062 10.888256072998047\n",
            "Train Epoch: 10 [281600/737279 (38%)]\tLoss: 121.778275\n",
            "66.17083740234375 11.004646301269531\n",
            "Train Epoch: 10 [294400/737279 (40%)]\tLoss: 110.189423\n",
            "64.57095336914062 11.028947830200195\n",
            "Train Epoch: 10 [307200/737279 (42%)]\tLoss: 108.686745\n",
            "51.536102294921875 12.028572082519531\n",
            "Train Epoch: 10 [320000/737279 (43%)]\tLoss: 99.650391\n",
            "68.20736694335938 11.442756652832031\n",
            "Train Epoch: 10 [332800/737279 (45%)]\tLoss: 113.978394\n",
            "70.43583679199219 11.285406112670898\n",
            "Train Epoch: 10 [345600/737279 (47%)]\tLoss: 115.577461\n",
            "64.91889953613281 11.668257713317871\n",
            "Train Epoch: 10 [358400/737279 (49%)]\tLoss: 111.591934\n",
            "74.41700744628906 10.662361145019531\n",
            "Train Epoch: 10 [371200/737279 (50%)]\tLoss: 117.066452\n",
            "75.71073913574219 11.241908073425293\n",
            "Train Epoch: 10 [384000/737279 (52%)]\tLoss: 120.678375\n",
            "72.46336364746094 11.449273109436035\n",
            "Train Epoch: 10 [396800/737279 (54%)]\tLoss: 118.260452\n",
            "65.9293441772461 10.965895652770996\n",
            "Train Epoch: 10 [409600/737279 (56%)]\tLoss: 109.792923\n",
            "66.53800964355469 10.691844940185547\n",
            "Train Epoch: 10 [422400/737279 (57%)]\tLoss: 109.305389\n",
            "63.193965911865234 11.632072448730469\n",
            "Train Epoch: 10 [435200/737279 (59%)]\tLoss: 109.722260\n",
            "64.61153411865234 11.313493728637695\n",
            "Train Epoch: 10 [448000/737279 (61%)]\tLoss: 109.865509\n",
            "68.16817474365234 10.93777847290039\n",
            "Train Epoch: 10 [460800/737279 (62%)]\tLoss: 111.919289\n",
            "71.07249450683594 11.383874893188477\n",
            "Train Epoch: 10 [473600/737279 (64%)]\tLoss: 116.607994\n",
            "79.55853271484375 11.108613967895508\n",
            "Train Epoch: 10 [486400/737279 (66%)]\tLoss: 123.992989\n",
            "64.17152404785156 11.120654106140137\n",
            "Train Epoch: 10 [499200/737279 (68%)]\tLoss: 108.654144\n",
            "60.394309997558594 11.445568084716797\n",
            "Train Epoch: 10 [512000/737279 (69%)]\tLoss: 106.176582\n",
            "62.98104476928711 11.536044120788574\n",
            "Train Epoch: 10 [524800/737279 (71%)]\tLoss: 109.125221\n",
            "66.5740966796875 11.320384979248047\n",
            "Train Epoch: 10 [537600/737279 (73%)]\tLoss: 111.855637\n",
            "67.27979278564453 11.397104263305664\n",
            "Train Epoch: 10 [550400/737279 (75%)]\tLoss: 112.868210\n",
            "54.477054595947266 11.346071243286133\n",
            "Train Epoch: 10 [563200/737279 (76%)]\tLoss: 99.861343\n",
            "68.67778015136719 10.995656967163086\n",
            "Train Epoch: 10 [576000/737279 (78%)]\tLoss: 112.660408\n",
            "67.7862319946289 11.263933181762695\n",
            "Train Epoch: 10 [588800/737279 (80%)]\tLoss: 112.841965\n",
            "60.70299530029297 11.342901229858398\n",
            "Train Epoch: 10 [601600/737279 (82%)]\tLoss: 106.074600\n",
            "62.76553726196289 11.34593391418457\n",
            "Train Epoch: 10 [614400/737279 (83%)]\tLoss: 108.149277\n",
            "72.28599548339844 11.478836059570312\n",
            "Train Epoch: 10 [627200/737279 (85%)]\tLoss: 118.201340\n",
            "57.47888946533203 11.083921432495117\n",
            "Train Epoch: 10 [640000/737279 (87%)]\tLoss: 101.814575\n",
            "63.752098083496094 11.976312637329102\n",
            "Train Epoch: 10 [652800/737279 (89%)]\tLoss: 111.657349\n",
            "62.038551330566406 11.806159973144531\n",
            "Train Epoch: 10 [665600/737279 (90%)]\tLoss: 109.263191\n",
            "64.87482452392578 11.840038299560547\n",
            "Train Epoch: 10 [678400/737279 (92%)]\tLoss: 112.234978\n",
            "64.81741333007812 10.631933212280273\n",
            "Train Epoch: 10 [691200/737279 (94%)]\tLoss: 107.345146\n",
            "63.628753662109375 11.532236099243164\n",
            "Train Epoch: 10 [704000/737279 (95%)]\tLoss: 109.757698\n",
            "65.07632446289062 11.592854499816895\n",
            "Train Epoch: 10 [716800/737279 (97%)]\tLoss: 111.447739\n",
            "62.15699005126953 11.360861778259277\n",
            "Train Epoch: 10 [729600/737279 (99%)]\tLoss: 107.600433\n",
            "====> Epoch: 10 Average loss: 111.5276 \tRecon Loss: 66.5934\n",
            "126720\n",
            "74.12625885009766 11.197349548339844\n",
            "Train Epoch: 11 [0/737279 (0%)]\tLoss: 118.915657\n",
            "64.70011138916016 11.237380981445312\n",
            "Train Epoch: 11 [12800/737279 (2%)]\tLoss: 109.649635\n",
            "75.24954223632812 11.32224178314209\n",
            "Train Epoch: 11 [25600/737279 (3%)]\tLoss: 120.538513\n",
            "68.59716796875 11.238505363464355\n",
            "Train Epoch: 11 [38400/737279 (5%)]\tLoss: 113.551193\n",
            "69.08067321777344 11.62261962890625\n",
            "Train Epoch: 11 [51200/737279 (7%)]\tLoss: 115.571152\n",
            "67.83216857910156 11.02196216583252\n",
            "Train Epoch: 11 [64000/737279 (9%)]\tLoss: 111.920013\n",
            "71.23989868164062 10.676809310913086\n",
            "Train Epoch: 11 [76800/737279 (10%)]\tLoss: 113.947136\n",
            "70.44694519042969 11.302101135253906\n",
            "Train Epoch: 11 [89600/737279 (12%)]\tLoss: 115.655350\n",
            "77.94903564453125 11.210386276245117\n",
            "Train Epoch: 11 [102400/737279 (14%)]\tLoss: 122.790581\n",
            "68.13511657714844 11.023031234741211\n",
            "Train Epoch: 11 [115200/737279 (16%)]\tLoss: 112.227242\n",
            "65.67948913574219 11.153358459472656\n",
            "Train Epoch: 11 [128000/737279 (17%)]\tLoss: 110.292923\n",
            "68.77928161621094 11.451923370361328\n",
            "Train Epoch: 11 [140800/737279 (19%)]\tLoss: 114.586975\n",
            "63.04621124267578 11.01950454711914\n",
            "Train Epoch: 11 [153600/737279 (21%)]\tLoss: 107.124229\n",
            "62.09700012207031 11.213068008422852\n",
            "Train Epoch: 11 [166400/737279 (23%)]\tLoss: 106.949272\n",
            "62.638736724853516 10.736738204956055\n",
            "Train Epoch: 11 [179200/737279 (24%)]\tLoss: 105.585693\n",
            "66.45331573486328 11.884397506713867\n",
            "Train Epoch: 11 [192000/737279 (26%)]\tLoss: 113.990906\n",
            "64.16385650634766 11.284530639648438\n",
            "Train Epoch: 11 [204800/737279 (28%)]\tLoss: 109.301979\n",
            "60.90763854980469 12.297544479370117\n",
            "Train Epoch: 11 [217600/737279 (30%)]\tLoss: 110.097816\n",
            "64.71147918701172 11.243507385253906\n",
            "Train Epoch: 11 [230400/737279 (31%)]\tLoss: 109.685509\n",
            "63.69685363769531 11.064926147460938\n",
            "Train Epoch: 11 [243200/737279 (33%)]\tLoss: 107.956558\n",
            "68.60812377929688 11.346220016479492\n",
            "Train Epoch: 11 [256000/737279 (35%)]\tLoss: 113.993004\n",
            "65.29835510253906 10.92438793182373\n",
            "Train Epoch: 11 [268800/737279 (36%)]\tLoss: 108.995911\n",
            "61.68379211425781 11.138113021850586\n",
            "Train Epoch: 11 [281600/737279 (38%)]\tLoss: 106.236244\n",
            "61.42982482910156 10.818487167358398\n",
            "Train Epoch: 11 [294400/737279 (40%)]\tLoss: 104.703773\n",
            "62.187408447265625 11.328584671020508\n",
            "Train Epoch: 11 [307200/737279 (42%)]\tLoss: 107.501747\n",
            "62.09604263305664 11.39846420288086\n",
            "Train Epoch: 11 [320000/737279 (43%)]\tLoss: 107.689896\n",
            "67.30238342285156 10.813969612121582\n",
            "Train Epoch: 11 [332800/737279 (45%)]\tLoss: 110.558258\n",
            "62.444679260253906 11.19265079498291\n",
            "Train Epoch: 11 [345600/737279 (47%)]\tLoss: 107.215286\n",
            "70.07839965820312 11.307632446289062\n",
            "Train Epoch: 11 [358400/737279 (49%)]\tLoss: 115.308929\n",
            "69.37944030761719 11.306198120117188\n",
            "Train Epoch: 11 [371200/737279 (50%)]\tLoss: 114.604233\n",
            "65.14509582519531 11.78230094909668\n",
            "Train Epoch: 11 [384000/737279 (52%)]\tLoss: 112.274300\n",
            "58.50202560424805 11.32848834991455\n",
            "Train Epoch: 11 [396800/737279 (54%)]\tLoss: 103.815979\n",
            "55.750144958496094 11.118154525756836\n",
            "Train Epoch: 11 [409600/737279 (56%)]\tLoss: 100.222763\n",
            "63.9129524230957 11.13671875\n",
            "Train Epoch: 11 [422400/737279 (57%)]\tLoss: 108.459824\n",
            "65.48641967773438 11.539588928222656\n",
            "Train Epoch: 11 [435200/737279 (59%)]\tLoss: 111.644775\n",
            "68.07188415527344 10.659814834594727\n",
            "Train Epoch: 11 [448000/737279 (61%)]\tLoss: 110.711143\n",
            "65.26402282714844 10.782709121704102\n",
            "Train Epoch: 11 [460800/737279 (62%)]\tLoss: 108.394859\n",
            "64.77323913574219 11.376897811889648\n",
            "Train Epoch: 11 [473600/737279 (64%)]\tLoss: 110.280830\n",
            "60.7546501159668 10.995342254638672\n",
            "Train Epoch: 11 [486400/737279 (66%)]\tLoss: 104.736023\n",
            "68.44119262695312 11.132586479187012\n",
            "Train Epoch: 11 [499200/737279 (68%)]\tLoss: 112.971542\n",
            "61.501678466796875 10.962616920471191\n",
            "Train Epoch: 11 [512000/737279 (69%)]\tLoss: 105.352142\n",
            "53.29024887084961 11.444744110107422\n",
            "Train Epoch: 11 [524800/737279 (71%)]\tLoss: 99.069229\n",
            "64.24028015136719 11.366458892822266\n",
            "Train Epoch: 11 [537600/737279 (73%)]\tLoss: 109.706116\n",
            "62.6031494140625 11.235374450683594\n",
            "Train Epoch: 11 [550400/737279 (75%)]\tLoss: 107.544647\n",
            "64.69078826904297 11.733009338378906\n",
            "Train Epoch: 11 [563200/737279 (76%)]\tLoss: 111.622826\n",
            "80.32044982910156 11.268446922302246\n",
            "Train Epoch: 11 [576000/737279 (78%)]\tLoss: 125.394241\n",
            "57.912174224853516 11.484604835510254\n",
            "Train Epoch: 11 [588800/737279 (80%)]\tLoss: 103.850594\n",
            "63.799156188964844 11.281264305114746\n",
            "Train Epoch: 11 [601600/737279 (82%)]\tLoss: 108.924210\n",
            "66.64470672607422 11.684125900268555\n",
            "Train Epoch: 11 [614400/737279 (83%)]\tLoss: 113.381210\n",
            "70.00855255126953 11.44998550415039\n",
            "Train Epoch: 11 [627200/737279 (85%)]\tLoss: 115.808495\n",
            "58.91863250732422 12.100168228149414\n",
            "Train Epoch: 11 [640000/737279 (87%)]\tLoss: 107.319305\n",
            "68.77706909179688 11.185188293457031\n",
            "Train Epoch: 11 [652800/737279 (89%)]\tLoss: 113.517822\n",
            "61.62901306152344 11.334832191467285\n",
            "Train Epoch: 11 [665600/737279 (90%)]\tLoss: 106.968338\n",
            "66.13160705566406 11.767541885375977\n",
            "Train Epoch: 11 [678400/737279 (92%)]\tLoss: 113.201775\n",
            "63.66419982910156 11.527345657348633\n",
            "Train Epoch: 11 [691200/737279 (94%)]\tLoss: 109.773582\n",
            "64.33183288574219 11.147262573242188\n",
            "Train Epoch: 11 [704000/737279 (95%)]\tLoss: 108.920883\n",
            "62.70512390136719 11.53642749786377\n",
            "Train Epoch: 11 [716800/737279 (97%)]\tLoss: 108.850830\n",
            "60.717594146728516 11.204665184020996\n",
            "Train Epoch: 11 [729600/737279 (99%)]\tLoss: 105.536255\n",
            "====> Epoch: 11 Average loss: 110.4378 \tRecon Loss: 65.1846\n",
            "138240\n",
            "60.02213668823242 11.680355072021484\n",
            "Train Epoch: 12 [0/737279 (0%)]\tLoss: 106.743561\n",
            "64.7305679321289 11.332389831542969\n",
            "Train Epoch: 12 [12800/737279 (2%)]\tLoss: 110.060127\n",
            "60.44561767578125 11.169164657592773\n",
            "Train Epoch: 12 [25600/737279 (3%)]\tLoss: 105.122276\n",
            "57.67536926269531 11.173553466796875\n",
            "Train Epoch: 12 [38400/737279 (5%)]\tLoss: 102.369583\n",
            "60.76300048828125 11.384876251220703\n",
            "Train Epoch: 12 [51200/737279 (7%)]\tLoss: 106.302505\n",
            "61.24608612060547 11.551641464233398\n",
            "Train Epoch: 12 [64000/737279 (9%)]\tLoss: 107.452652\n",
            "60.98716735839844 11.01533317565918\n",
            "Train Epoch: 12 [76800/737279 (10%)]\tLoss: 105.048500\n",
            "53.7769775390625 11.509073257446289\n",
            "Train Epoch: 12 [89600/737279 (12%)]\tLoss: 99.813271\n",
            "65.77760314941406 11.165460586547852\n",
            "Train Epoch: 12 [102400/737279 (14%)]\tLoss: 110.439445\n",
            "59.49077606201172 11.267518997192383\n",
            "Train Epoch: 12 [115200/737279 (16%)]\tLoss: 104.560852\n",
            "57.3558349609375 11.289959907531738\n",
            "Train Epoch: 12 [128000/737279 (17%)]\tLoss: 102.515671\n",
            "73.97991943359375 10.875069618225098\n",
            "Train Epoch: 12 [140800/737279 (19%)]\tLoss: 117.480194\n",
            "61.337791442871094 11.263105392456055\n",
            "Train Epoch: 12 [153600/737279 (21%)]\tLoss: 106.390213\n",
            "60.20709991455078 11.128894805908203\n",
            "Train Epoch: 12 [166400/737279 (23%)]\tLoss: 104.722679\n",
            "69.71224975585938 11.28567123413086\n",
            "Train Epoch: 12 [179200/737279 (24%)]\tLoss: 114.854935\n",
            "69.27198791503906 11.249113082885742\n",
            "Train Epoch: 12 [192000/737279 (26%)]\tLoss: 114.268440\n",
            "63.63243103027344 11.431756019592285\n",
            "Train Epoch: 12 [204800/737279 (28%)]\tLoss: 109.359451\n",
            "66.62490844726562 11.375231742858887\n",
            "Train Epoch: 12 [217600/737279 (30%)]\tLoss: 112.125839\n",
            "68.85481262207031 11.312688827514648\n",
            "Train Epoch: 12 [230400/737279 (31%)]\tLoss: 114.105568\n",
            "55.17877197265625 11.413382530212402\n",
            "Train Epoch: 12 [243200/737279 (33%)]\tLoss: 100.832306\n",
            "60.78388214111328 11.097414016723633\n",
            "Train Epoch: 12 [256000/737279 (35%)]\tLoss: 105.173538\n",
            "59.97559356689453 11.045012474060059\n",
            "Train Epoch: 12 [268800/737279 (36%)]\tLoss: 104.155640\n",
            "62.35489273071289 11.255203247070312\n",
            "Train Epoch: 12 [281600/737279 (38%)]\tLoss: 107.375702\n",
            "75.3909683227539 10.995556831359863\n",
            "Train Epoch: 12 [294400/737279 (40%)]\tLoss: 119.373199\n",
            "62.822669982910156 11.669349670410156\n",
            "Train Epoch: 12 [307200/737279 (42%)]\tLoss: 109.500069\n",
            "64.34603881835938 11.271928787231445\n",
            "Train Epoch: 12 [320000/737279 (43%)]\tLoss: 109.433754\n",
            "64.3192138671875 11.840746879577637\n",
            "Train Epoch: 12 [332800/737279 (45%)]\tLoss: 111.682205\n",
            "61.5606689453125 11.269363403320312\n",
            "Train Epoch: 12 [345600/737279 (47%)]\tLoss: 106.638123\n",
            "68.74409484863281 11.1851224899292\n",
            "Train Epoch: 12 [358400/737279 (49%)]\tLoss: 113.484589\n",
            "68.13670349121094 11.028801918029785\n",
            "Train Epoch: 12 [371200/737279 (50%)]\tLoss: 112.251907\n",
            "62.3868408203125 11.66053581237793\n",
            "Train Epoch: 12 [384000/737279 (52%)]\tLoss: 109.028984\n",
            "67.96565246582031 11.278858184814453\n",
            "Train Epoch: 12 [396800/737279 (54%)]\tLoss: 113.081085\n",
            "60.171630859375 11.40873908996582\n",
            "Train Epoch: 12 [409600/737279 (56%)]\tLoss: 105.806587\n",
            "63.35993576049805 11.252555847167969\n",
            "Train Epoch: 12 [422400/737279 (57%)]\tLoss: 108.370163\n",
            "66.97737884521484 10.971529006958008\n",
            "Train Epoch: 12 [435200/737279 (59%)]\tLoss: 110.863495\n",
            "60.365821838378906 11.265218734741211\n",
            "Train Epoch: 12 [448000/737279 (61%)]\tLoss: 105.426697\n",
            "73.85389709472656 11.389933586120605\n",
            "Train Epoch: 12 [460800/737279 (62%)]\tLoss: 119.413635\n",
            "64.53893280029297 11.720539093017578\n",
            "Train Epoch: 12 [473600/737279 (64%)]\tLoss: 111.421089\n",
            "60.82283401489258 11.29309368133545\n",
            "Train Epoch: 12 [486400/737279 (66%)]\tLoss: 105.995209\n",
            "68.56803894042969 11.15158462524414\n",
            "Train Epoch: 12 [499200/737279 (68%)]\tLoss: 113.174377\n",
            "58.89833068847656 11.356693267822266\n",
            "Train Epoch: 12 [512000/737279 (69%)]\tLoss: 104.325104\n",
            "57.439971923828125 11.108798027038574\n",
            "Train Epoch: 12 [524800/737279 (71%)]\tLoss: 101.875168\n",
            "86.98451232910156 10.624537467956543\n",
            "Train Epoch: 12 [537600/737279 (73%)]\tLoss: 129.482666\n",
            "65.72254943847656 11.083295822143555\n",
            "Train Epoch: 12 [550400/737279 (75%)]\tLoss: 110.055733\n",
            "68.28170776367188 10.971553802490234\n",
            "Train Epoch: 12 [563200/737279 (76%)]\tLoss: 112.167923\n",
            "62.625823974609375 11.627493858337402\n",
            "Train Epoch: 12 [576000/737279 (78%)]\tLoss: 109.135803\n",
            "68.84126281738281 11.256307601928711\n",
            "Train Epoch: 12 [588800/737279 (80%)]\tLoss: 113.866493\n",
            "70.86713409423828 11.366819381713867\n",
            "Train Epoch: 12 [601600/737279 (82%)]\tLoss: 116.334412\n",
            "63.838035583496094 11.259134292602539\n",
            "Train Epoch: 12 [614400/737279 (83%)]\tLoss: 108.874573\n",
            "56.020477294921875 12.112411499023438\n",
            "Train Epoch: 12 [627200/737279 (85%)]\tLoss: 104.470123\n",
            "67.48155212402344 11.531733512878418\n",
            "Train Epoch: 12 [640000/737279 (87%)]\tLoss: 113.608490\n",
            "67.62315368652344 10.985383987426758\n",
            "Train Epoch: 12 [652800/737279 (89%)]\tLoss: 111.564690\n",
            "69.18949890136719 11.193414688110352\n",
            "Train Epoch: 12 [665600/737279 (90%)]\tLoss: 113.963158\n",
            "70.09678649902344 11.157705307006836\n",
            "Train Epoch: 12 [678400/737279 (92%)]\tLoss: 114.727608\n",
            "67.14157104492188 11.562081336975098\n",
            "Train Epoch: 12 [691200/737279 (94%)]\tLoss: 113.389893\n",
            "59.53428268432617 11.233438491821289\n",
            "Train Epoch: 12 [704000/737279 (95%)]\tLoss: 104.468033\n",
            "72.17513275146484 11.574507713317871\n",
            "Train Epoch: 12 [716800/737279 (97%)]\tLoss: 118.473160\n",
            "57.73473358154297 11.631523132324219\n",
            "Train Epoch: 12 [729600/737279 (99%)]\tLoss: 104.260826\n",
            "====> Epoch: 12 Average loss: 110.7789 \tRecon Loss: 65.4860\n",
            "149760\n",
            "67.69837951660156 11.408615112304688\n",
            "Train Epoch: 13 [0/737279 (0%)]\tLoss: 113.332840\n",
            "57.80790710449219 11.228689193725586\n",
            "Train Epoch: 13 [12800/737279 (2%)]\tLoss: 102.722664\n",
            "65.70572662353516 11.502063751220703\n",
            "Train Epoch: 13 [25600/737279 (3%)]\tLoss: 111.713982\n",
            "65.99488830566406 11.212631225585938\n",
            "Train Epoch: 13 [38400/737279 (5%)]\tLoss: 110.845413\n",
            "59.89299011230469 10.977666854858398\n",
            "Train Epoch: 13 [51200/737279 (7%)]\tLoss: 103.803658\n",
            "57.17939758300781 12.037961959838867\n",
            "Train Epoch: 13 [64000/737279 (9%)]\tLoss: 105.331245\n",
            "54.482234954833984 11.414932250976562\n",
            "Train Epoch: 13 [76800/737279 (10%)]\tLoss: 100.141968\n",
            "62.73748779296875 11.759441375732422\n",
            "Train Epoch: 13 [89600/737279 (12%)]\tLoss: 109.775253\n",
            "63.12213897705078 11.198247909545898\n",
            "Train Epoch: 13 [102400/737279 (14%)]\tLoss: 107.915131\n",
            "61.667320251464844 11.788769721984863\n",
            "Train Epoch: 13 [115200/737279 (16%)]\tLoss: 108.822403\n",
            "66.05941772460938 11.282678604125977\n",
            "Train Epoch: 13 [128000/737279 (17%)]\tLoss: 111.190132\n",
            "61.384525299072266 11.417734146118164\n",
            "Train Epoch: 13 [140800/737279 (19%)]\tLoss: 107.055466\n",
            "60.05510711669922 11.511507987976074\n",
            "Train Epoch: 13 [153600/737279 (21%)]\tLoss: 106.101135\n",
            "66.12037658691406 11.382139205932617\n",
            "Train Epoch: 13 [166400/737279 (23%)]\tLoss: 111.648933\n",
            "71.95829772949219 11.670127868652344\n",
            "Train Epoch: 13 [179200/737279 (24%)]\tLoss: 118.638809\n",
            "71.14533996582031 11.221721649169922\n",
            "Train Epoch: 13 [192000/737279 (26%)]\tLoss: 116.032227\n",
            "63.47075653076172 11.241284370422363\n",
            "Train Epoch: 13 [204800/737279 (28%)]\tLoss: 108.435898\n",
            "67.82684326171875 11.203519821166992\n",
            "Train Epoch: 13 [217600/737279 (30%)]\tLoss: 112.640923\n",
            "62.98338317871094 11.367217063903809\n",
            "Train Epoch: 13 [230400/737279 (31%)]\tLoss: 108.452255\n",
            "61.83930969238281 11.567106246948242\n",
            "Train Epoch: 13 [243200/737279 (33%)]\tLoss: 108.107735\n",
            "59.522430419921875 11.563244819641113\n",
            "Train Epoch: 13 [256000/737279 (35%)]\tLoss: 105.775406\n",
            "63.760215759277344 11.705827713012695\n",
            "Train Epoch: 13 [268800/737279 (36%)]\tLoss: 110.583527\n",
            "59.393104553222656 11.582146644592285\n",
            "Train Epoch: 13 [281600/737279 (38%)]\tLoss: 105.721695\n",
            "70.63542175292969 10.91683578491211\n",
            "Train Epoch: 13 [294400/737279 (40%)]\tLoss: 114.302765\n",
            "86.99293518066406 10.635310173034668\n",
            "Train Epoch: 13 [307200/737279 (42%)]\tLoss: 129.534180\n",
            "73.17948913574219 10.65645694732666\n",
            "Train Epoch: 13 [320000/737279 (43%)]\tLoss: 115.805313\n",
            "59.730613708496094 10.99263858795166\n",
            "Train Epoch: 13 [332800/737279 (45%)]\tLoss: 103.701172\n",
            "66.64422607421875 11.284442901611328\n",
            "Train Epoch: 13 [345600/737279 (47%)]\tLoss: 111.781998\n",
            "57.95532989501953 11.880851745605469\n",
            "Train Epoch: 13 [358400/737279 (49%)]\tLoss: 105.478737\n",
            "58.82268524169922 11.539176940917969\n",
            "Train Epoch: 13 [371200/737279 (50%)]\tLoss: 104.979393\n",
            "57.27976608276367 11.6693754196167\n",
            "Train Epoch: 13 [384000/737279 (52%)]\tLoss: 103.957268\n",
            "60.936946868896484 11.75568675994873\n",
            "Train Epoch: 13 [396800/737279 (54%)]\tLoss: 107.959694\n",
            "68.68148803710938 11.283143043518066\n",
            "Train Epoch: 13 [409600/737279 (56%)]\tLoss: 113.814056\n",
            "61.128822326660156 11.375178337097168\n",
            "Train Epoch: 13 [422400/737279 (57%)]\tLoss: 106.629532\n",
            "56.45001983642578 11.585753440856934\n",
            "Train Epoch: 13 [435200/737279 (59%)]\tLoss: 102.793030\n",
            "67.10517883300781 11.855137825012207\n",
            "Train Epoch: 13 [448000/737279 (61%)]\tLoss: 114.525726\n",
            "59.62589645385742 11.427874565124512\n",
            "Train Epoch: 13 [460800/737279 (62%)]\tLoss: 105.337395\n",
            "64.8769302368164 11.223833084106445\n",
            "Train Epoch: 13 [473600/737279 (64%)]\tLoss: 109.772263\n",
            "70.53489685058594 11.40479850769043\n",
            "Train Epoch: 13 [486400/737279 (66%)]\tLoss: 116.154091\n",
            "59.943603515625 11.463260650634766\n",
            "Train Epoch: 13 [499200/737279 (68%)]\tLoss: 105.796646\n",
            "63.167213439941406 11.527484893798828\n",
            "Train Epoch: 13 [512000/737279 (69%)]\tLoss: 109.277153\n",
            "59.28653335571289 11.715007781982422\n",
            "Train Epoch: 13 [524800/737279 (71%)]\tLoss: 106.146561\n",
            "58.6429443359375 11.534217834472656\n",
            "Train Epoch: 13 [537600/737279 (73%)]\tLoss: 104.779816\n",
            "63.13733673095703 11.565431594848633\n",
            "Train Epoch: 13 [550400/737279 (75%)]\tLoss: 109.399063\n",
            "66.6151351928711 11.156243324279785\n",
            "Train Epoch: 13 [563200/737279 (76%)]\tLoss: 111.240112\n",
            "60.83135223388672 11.009607315063477\n",
            "Train Epoch: 13 [576000/737279 (78%)]\tLoss: 104.869781\n",
            "59.87138366699219 11.438279151916504\n",
            "Train Epoch: 13 [588800/737279 (80%)]\tLoss: 105.624496\n",
            "61.931663513183594 11.219671249389648\n",
            "Train Epoch: 13 [601600/737279 (82%)]\tLoss: 106.810349\n",
            "56.29988098144531 11.265334129333496\n",
            "Train Epoch: 13 [614400/737279 (83%)]\tLoss: 101.361221\n",
            "77.69729614257812 11.032609939575195\n",
            "Train Epoch: 13 [627200/737279 (85%)]\tLoss: 121.827736\n",
            "60.295631408691406 11.314098358154297\n",
            "Train Epoch: 13 [640000/737279 (87%)]\tLoss: 105.552025\n",
            "66.04019927978516 11.261483192443848\n",
            "Train Epoch: 13 [652800/737279 (89%)]\tLoss: 111.086136\n",
            "59.58641052246094 11.286925315856934\n",
            "Train Epoch: 13 [665600/737279 (90%)]\tLoss: 104.734116\n",
            "63.405338287353516 10.972755432128906\n",
            "Train Epoch: 13 [678400/737279 (92%)]\tLoss: 107.296356\n",
            "72.41754150390625 10.77645206451416\n",
            "Train Epoch: 13 [691200/737279 (94%)]\tLoss: 115.523346\n",
            "64.6421127319336 11.559532165527344\n",
            "Train Epoch: 13 [704000/737279 (95%)]\tLoss: 110.880241\n",
            "67.19696044921875 11.313262939453125\n",
            "Train Epoch: 13 [716800/737279 (97%)]\tLoss: 112.450012\n",
            "60.26597595214844 11.929788589477539\n",
            "Train Epoch: 13 [729600/737279 (99%)]\tLoss: 107.985130\n",
            "====> Epoch: 13 Average loss: 109.5299 \tRecon Loss: 63.9070\n",
            "161280\n",
            "54.991371154785156 11.567099571228027\n",
            "Train Epoch: 14 [0/737279 (0%)]\tLoss: 101.259766\n",
            "65.05313110351562 11.263856887817383\n",
            "Train Epoch: 14 [12800/737279 (2%)]\tLoss: 110.108559\n",
            "62.11736297607422 11.568349838256836\n",
            "Train Epoch: 14 [25600/737279 (3%)]\tLoss: 108.390762\n",
            "62.533103942871094 11.773700714111328\n",
            "Train Epoch: 14 [38400/737279 (5%)]\tLoss: 109.627907\n",
            "62.054054260253906 11.40781021118164\n",
            "Train Epoch: 14 [51200/737279 (7%)]\tLoss: 107.685295\n",
            "64.18143463134766 11.310173034667969\n",
            "Train Epoch: 14 [64000/737279 (9%)]\tLoss: 109.422127\n",
            "59.683692932128906 11.587949752807617\n",
            "Train Epoch: 14 [76800/737279 (10%)]\tLoss: 106.035492\n",
            "58.53715133666992 11.979279518127441\n",
            "Train Epoch: 14 [89600/737279 (12%)]\tLoss: 106.454269\n",
            "69.13302612304688 11.509393692016602\n",
            "Train Epoch: 14 [102400/737279 (14%)]\tLoss: 115.170601\n",
            "65.0741958618164 11.440250396728516\n",
            "Train Epoch: 14 [115200/737279 (16%)]\tLoss: 110.835197\n",
            "63.86741638183594 11.599393844604492\n",
            "Train Epoch: 14 [128000/737279 (17%)]\tLoss: 110.264992\n",
            "62.30004119873047 11.641207695007324\n",
            "Train Epoch: 14 [140800/737279 (19%)]\tLoss: 108.864868\n",
            "60.125545501708984 11.440813064575195\n",
            "Train Epoch: 14 [153600/737279 (21%)]\tLoss: 105.888794\n",
            "65.82223510742188 11.458588600158691\n",
            "Train Epoch: 14 [166400/737279 (23%)]\tLoss: 111.656586\n",
            "57.878692626953125 11.547990798950195\n",
            "Train Epoch: 14 [179200/737279 (24%)]\tLoss: 104.070656\n",
            "60.97410583496094 12.417776107788086\n",
            "Train Epoch: 14 [192000/737279 (26%)]\tLoss: 110.645210\n",
            "72.00971984863281 11.017841339111328\n",
            "Train Epoch: 14 [204800/737279 (28%)]\tLoss: 116.081085\n",
            "71.22773742675781 11.250959396362305\n",
            "Train Epoch: 14 [217600/737279 (30%)]\tLoss: 116.231575\n",
            "69.88656616210938 11.412378311157227\n",
            "Train Epoch: 14 [230400/737279 (31%)]\tLoss: 115.536079\n",
            "64.60693359375 11.803112983703613\n",
            "Train Epoch: 14 [243200/737279 (33%)]\tLoss: 111.819382\n",
            "64.25238800048828 11.195357322692871\n",
            "Train Epoch: 14 [256000/737279 (35%)]\tLoss: 109.033813\n",
            "64.31143951416016 11.664380073547363\n",
            "Train Epoch: 14 [268800/737279 (36%)]\tLoss: 110.968964\n",
            "59.220314025878906 11.724931716918945\n",
            "Train Epoch: 14 [281600/737279 (38%)]\tLoss: 106.120041\n",
            "66.24079895019531 11.403562545776367\n",
            "Train Epoch: 14 [294400/737279 (40%)]\tLoss: 111.855049\n",
            "68.6241455078125 11.518655776977539\n",
            "Train Epoch: 14 [307200/737279 (42%)]\tLoss: 114.698769\n",
            "65.60235595703125 11.635992050170898\n",
            "Train Epoch: 14 [320000/737279 (43%)]\tLoss: 112.146324\n",
            "62.52294921875 11.494539260864258\n",
            "Train Epoch: 14 [332800/737279 (45%)]\tLoss: 108.501106\n",
            "61.72871398925781 12.159934043884277\n",
            "Train Epoch: 14 [345600/737279 (47%)]\tLoss: 110.368454\n",
            "61.26850128173828 11.749225616455078\n",
            "Train Epoch: 14 [358400/737279 (49%)]\tLoss: 108.265404\n",
            "56.19718933105469 11.211862564086914\n",
            "Train Epoch: 14 [371200/737279 (50%)]\tLoss: 101.044640\n",
            "82.94169616699219 11.741522789001465\n",
            "Train Epoch: 14 [384000/737279 (52%)]\tLoss: 129.907791\n",
            "66.3282699584961 11.72334098815918\n",
            "Train Epoch: 14 [396800/737279 (54%)]\tLoss: 113.221634\n",
            "63.95148849487305 11.457731246948242\n",
            "Train Epoch: 14 [409600/737279 (56%)]\tLoss: 109.782410\n",
            "67.29510498046875 10.925640106201172\n",
            "Train Epoch: 14 [422400/737279 (57%)]\tLoss: 110.997665\n",
            "63.76242446899414 11.55160903930664\n",
            "Train Epoch: 14 [435200/737279 (59%)]\tLoss: 109.968857\n",
            "58.08112335205078 11.20145034790039\n",
            "Train Epoch: 14 [448000/737279 (61%)]\tLoss: 102.886925\n",
            "61.99522399902344 11.75611686706543\n",
            "Train Epoch: 14 [460800/737279 (62%)]\tLoss: 109.019691\n",
            "66.39378356933594 11.78848648071289\n",
            "Train Epoch: 14 [473600/737279 (64%)]\tLoss: 113.547729\n",
            "69.47401428222656 11.167207717895508\n",
            "Train Epoch: 14 [486400/737279 (66%)]\tLoss: 114.142845\n",
            "61.55059814453125 11.675006866455078\n",
            "Train Epoch: 14 [499200/737279 (68%)]\tLoss: 108.250626\n",
            "59.598079681396484 11.75338363647461\n",
            "Train Epoch: 14 [512000/737279 (69%)]\tLoss: 106.611618\n",
            "56.44670104980469 12.017108917236328\n",
            "Train Epoch: 14 [524800/737279 (71%)]\tLoss: 104.515137\n",
            "54.78874206542969 11.758337020874023\n",
            "Train Epoch: 14 [537600/737279 (73%)]\tLoss: 101.822090\n",
            "63.84532928466797 11.566286087036133\n",
            "Train Epoch: 14 [550400/737279 (75%)]\tLoss: 110.110474\n",
            "66.70449829101562 11.500436782836914\n",
            "Train Epoch: 14 [563200/737279 (76%)]\tLoss: 112.706245\n",
            "57.519474029541016 11.737550735473633\n",
            "Train Epoch: 14 [576000/737279 (78%)]\tLoss: 104.469681\n",
            "59.946014404296875 12.092275619506836\n",
            "Train Epoch: 14 [588800/737279 (80%)]\tLoss: 108.315117\n",
            "58.9421272277832 12.057758331298828\n",
            "Train Epoch: 14 [601600/737279 (82%)]\tLoss: 107.173157\n",
            "74.64185333251953 10.422192573547363\n",
            "Train Epoch: 14 [614400/737279 (83%)]\tLoss: 116.330627\n",
            "84.03680419921875 10.746021270751953\n",
            "Train Epoch: 14 [627200/737279 (85%)]\tLoss: 127.020889\n",
            "76.78384399414062 10.730920791625977\n",
            "Train Epoch: 14 [640000/737279 (87%)]\tLoss: 119.707527\n",
            "62.43772888183594 11.316173553466797\n",
            "Train Epoch: 14 [652800/737279 (89%)]\tLoss: 107.702423\n",
            "70.00209045410156 11.493825912475586\n",
            "Train Epoch: 14 [665600/737279 (90%)]\tLoss: 115.977394\n",
            "65.58576202392578 11.170909881591797\n",
            "Train Epoch: 14 [678400/737279 (92%)]\tLoss: 110.269402\n",
            "68.86033630371094 11.264094352722168\n",
            "Train Epoch: 14 [691200/737279 (94%)]\tLoss: 113.916718\n",
            "71.39189147949219 10.900455474853516\n",
            "Train Epoch: 14 [704000/737279 (95%)]\tLoss: 114.993713\n",
            "74.4843521118164 10.39471435546875\n",
            "Train Epoch: 14 [716800/737279 (97%)]\tLoss: 116.063210\n",
            "71.66944885253906 11.096622467041016\n",
            "Train Epoch: 14 [729600/737279 (99%)]\tLoss: 116.055939\n",
            "====> Epoch: 14 Average loss: 110.0666 \tRecon Loss: 64.3085\n",
            "172800\n",
            "84.25267028808594 10.835477828979492\n",
            "Train Epoch: 15 [0/737279 (0%)]\tLoss: 127.594582\n",
            "57.73810577392578 11.029271125793457\n",
            "Train Epoch: 15 [12800/737279 (2%)]\tLoss: 101.855194\n",
            "68.38218688964844 11.601415634155273\n",
            "Train Epoch: 15 [25600/737279 (3%)]\tLoss: 114.787849\n",
            "68.52177429199219 11.325532913208008\n",
            "Train Epoch: 15 [38400/737279 (5%)]\tLoss: 113.823906\n",
            "75.0133285522461 11.46575927734375\n",
            "Train Epoch: 15 [51200/737279 (7%)]\tLoss: 120.876366\n",
            "63.51694107055664 11.031859397888184\n",
            "Train Epoch: 15 [64000/737279 (9%)]\tLoss: 107.644379\n",
            "69.6347885131836 11.608068466186523\n",
            "Train Epoch: 15 [76800/737279 (10%)]\tLoss: 116.067062\n",
            "66.54443359375 11.144233703613281\n",
            "Train Epoch: 15 [89600/737279 (12%)]\tLoss: 111.121368\n",
            "80.58689880371094 11.183942794799805\n",
            "Train Epoch: 15 [102400/737279 (14%)]\tLoss: 125.322670\n",
            "73.03451538085938 11.093255996704102\n",
            "Train Epoch: 15 [115200/737279 (16%)]\tLoss: 117.407539\n",
            "64.39317321777344 11.17981243133545\n",
            "Train Epoch: 15 [128000/737279 (17%)]\tLoss: 109.112427\n",
            "64.58367919921875 11.545656204223633\n",
            "Train Epoch: 15 [140800/737279 (19%)]\tLoss: 110.766304\n",
            "68.13045501708984 11.363653182983398\n",
            "Train Epoch: 15 [153600/737279 (21%)]\tLoss: 113.585068\n",
            "58.69524002075195 11.887639999389648\n",
            "Train Epoch: 15 [166400/737279 (23%)]\tLoss: 106.245804\n",
            "61.551082611083984 11.550777435302734\n",
            "Train Epoch: 15 [179200/737279 (24%)]\tLoss: 107.754196\n",
            "73.54492950439453 11.129768371582031\n",
            "Train Epoch: 15 [192000/737279 (26%)]\tLoss: 118.064003\n",
            "65.77690124511719 11.67536449432373\n",
            "Train Epoch: 15 [204800/737279 (28%)]\tLoss: 112.478363\n",
            "68.95245361328125 11.290365219116211\n",
            "Train Epoch: 15 [217600/737279 (30%)]\tLoss: 114.113914\n",
            "75.91889953613281 11.113509178161621\n",
            "Train Epoch: 15 [230400/737279 (31%)]\tLoss: 120.372940\n",
            "62.55425262451172 12.025199890136719\n",
            "Train Epoch: 15 [243200/737279 (33%)]\tLoss: 110.655052\n",
            "64.26679992675781 11.751450538635254\n",
            "Train Epoch: 15 [256000/737279 (35%)]\tLoss: 111.272598\n",
            "58.42820739746094 11.67650318145752\n",
            "Train Epoch: 15 [268800/737279 (36%)]\tLoss: 105.134216\n",
            "71.29196166992188 11.275089263916016\n",
            "Train Epoch: 15 [281600/737279 (38%)]\tLoss: 116.392319\n",
            "67.18199920654297 11.543810844421387\n",
            "Train Epoch: 15 [294400/737279 (40%)]\tLoss: 113.357239\n",
            "77.9815902709961 11.351293563842773\n",
            "Train Epoch: 15 [307200/737279 (42%)]\tLoss: 123.386765\n",
            "75.95832061767578 10.630661010742188\n",
            "Train Epoch: 15 [320000/737279 (43%)]\tLoss: 118.480965\n",
            "59.57046890258789 11.309505462646484\n",
            "Train Epoch: 15 [332800/737279 (45%)]\tLoss: 104.808487\n",
            "65.55796813964844 11.134332656860352\n",
            "Train Epoch: 15 [345600/737279 (47%)]\tLoss: 110.095299\n",
            "58.6274299621582 11.36055850982666\n",
            "Train Epoch: 15 [358400/737279 (49%)]\tLoss: 104.069664\n",
            "61.66370391845703 11.261505126953125\n",
            "Train Epoch: 15 [371200/737279 (50%)]\tLoss: 106.709724\n",
            "61.98294448852539 11.506606101989746\n",
            "Train Epoch: 15 [384000/737279 (52%)]\tLoss: 108.009369\n",
            "78.50592041015625 11.413211822509766\n",
            "Train Epoch: 15 [396800/737279 (54%)]\tLoss: 124.158768\n",
            "56.781150817871094 11.402016639709473\n",
            "Train Epoch: 15 [409600/737279 (56%)]\tLoss: 102.389221\n",
            "65.45709991455078 11.534764289855957\n",
            "Train Epoch: 15 [422400/737279 (57%)]\tLoss: 111.596161\n",
            "76.25807189941406 11.233650207519531\n",
            "Train Epoch: 15 [435200/737279 (59%)]\tLoss: 121.192673\n",
            "68.4385986328125 11.520349502563477\n",
            "Train Epoch: 15 [448000/737279 (61%)]\tLoss: 114.519997\n",
            "67.31494140625 11.46633529663086\n",
            "Train Epoch: 15 [460800/737279 (62%)]\tLoss: 113.180283\n",
            "76.37849426269531 11.737324714660645\n",
            "Train Epoch: 15 [473600/737279 (64%)]\tLoss: 123.327789\n",
            "62.83721923828125 11.547953605651855\n",
            "Train Epoch: 15 [486400/737279 (66%)]\tLoss: 109.029037\n",
            "60.901424407958984 11.846930503845215\n",
            "Train Epoch: 15 [499200/737279 (68%)]\tLoss: 108.289146\n",
            "60.45292663574219 11.292852401733398\n",
            "Train Epoch: 15 [512000/737279 (69%)]\tLoss: 105.624336\n",
            "63.08608627319336 11.04886245727539\n",
            "Train Epoch: 15 [524800/737279 (71%)]\tLoss: 107.281540\n",
            "64.15690612792969 12.109598159790039\n",
            "Train Epoch: 15 [537600/737279 (73%)]\tLoss: 112.595299\n",
            "67.10172271728516 11.427651405334473\n",
            "Train Epoch: 15 [550400/737279 (75%)]\tLoss: 112.812332\n",
            "63.585304260253906 11.71086311340332\n",
            "Train Epoch: 15 [563200/737279 (76%)]\tLoss: 110.428757\n",
            "56.19061279296875 11.875516891479492\n",
            "Train Epoch: 15 [576000/737279 (78%)]\tLoss: 103.692680\n",
            "65.3653793334961 11.473685264587402\n",
            "Train Epoch: 15 [588800/737279 (80%)]\tLoss: 111.260117\n",
            "70.26325225830078 11.257715225219727\n",
            "Train Epoch: 15 [601600/737279 (82%)]\tLoss: 115.294113\n",
            "63.811767578125 11.669480323791504\n",
            "Train Epoch: 15 [614400/737279 (83%)]\tLoss: 110.489685\n",
            "63.34888458251953 11.651248931884766\n",
            "Train Epoch: 15 [627200/737279 (85%)]\tLoss: 109.953880\n",
            "60.02525329589844 11.855301856994629\n",
            "Train Epoch: 15 [640000/737279 (87%)]\tLoss: 107.446457\n",
            "53.731727600097656 11.980323791503906\n",
            "Train Epoch: 15 [652800/737279 (89%)]\tLoss: 101.653023\n",
            "59.88751220703125 11.894840240478516\n",
            "Train Epoch: 15 [665600/737279 (90%)]\tLoss: 107.466873\n",
            "60.601463317871094 12.153940200805664\n",
            "Train Epoch: 15 [678400/737279 (92%)]\tLoss: 109.217224\n",
            "59.041419982910156 11.559713363647461\n",
            "Train Epoch: 15 [691200/737279 (94%)]\tLoss: 105.280273\n",
            "54.78955078125 12.084309577941895\n",
            "Train Epoch: 15 [704000/737279 (95%)]\tLoss: 103.126785\n",
            "62.53880310058594 11.108915328979492\n",
            "Train Epoch: 15 [716800/737279 (97%)]\tLoss: 106.974464\n",
            "71.67646789550781 11.717156410217285\n",
            "Train Epoch: 15 [729600/737279 (99%)]\tLoss: 118.545090\n",
            "====> Epoch: 15 Average loss: 110.8338 \tRecon Loss: 65.1800\n",
            "184320\n",
            "56.22332763671875 11.491013526916504\n",
            "Train Epoch: 16 [0/737279 (0%)]\tLoss: 102.187378\n",
            "58.741188049316406 11.815595626831055\n",
            "Train Epoch: 16 [12800/737279 (2%)]\tLoss: 106.003571\n",
            "60.00630187988281 11.313364028930664\n",
            "Train Epoch: 16 [25600/737279 (3%)]\tLoss: 105.259758\n",
            "67.92156982421875 10.943765640258789\n",
            "Train Epoch: 16 [38400/737279 (5%)]\tLoss: 111.696632\n",
            "59.54289245605469 11.480056762695312\n",
            "Train Epoch: 16 [51200/737279 (7%)]\tLoss: 105.463120\n",
            "67.48405456542969 11.758219718933105\n",
            "Train Epoch: 16 [64000/737279 (9%)]\tLoss: 114.516937\n",
            "59.49281311035156 11.600081443786621\n",
            "Train Epoch: 16 [76800/737279 (10%)]\tLoss: 105.893143\n",
            "58.50475311279297 11.773439407348633\n",
            "Train Epoch: 16 [89600/737279 (12%)]\tLoss: 105.598511\n",
            "58.24073791503906 11.614545822143555\n",
            "Train Epoch: 16 [102400/737279 (14%)]\tLoss: 104.698921\n",
            "61.75846862792969 11.390761375427246\n",
            "Train Epoch: 16 [115200/737279 (16%)]\tLoss: 107.321518\n",
            "56.210304260253906 11.61499309539795\n",
            "Train Epoch: 16 [128000/737279 (17%)]\tLoss: 102.670273\n",
            "69.80979919433594 12.613203048706055\n",
            "Train Epoch: 16 [140800/737279 (19%)]\tLoss: 120.262611\n",
            "62.51422882080078 11.249082565307617\n",
            "Train Epoch: 16 [153600/737279 (21%)]\tLoss: 107.510559\n",
            "58.63463592529297 12.322415351867676\n",
            "Train Epoch: 16 [166400/737279 (23%)]\tLoss: 107.924301\n",
            "55.55210876464844 11.887552261352539\n",
            "Train Epoch: 16 [179200/737279 (24%)]\tLoss: 103.102318\n",
            "53.79249572753906 11.525250434875488\n",
            "Train Epoch: 16 [192000/737279 (26%)]\tLoss: 99.893494\n",
            "61.562660217285156 10.854124069213867\n",
            "Train Epoch: 16 [204800/737279 (28%)]\tLoss: 104.979156\n",
            "62.263790130615234 11.578176498413086\n",
            "Train Epoch: 16 [217600/737279 (30%)]\tLoss: 108.576492\n",
            "56.24416732788086 11.972147941589355\n",
            "Train Epoch: 16 [230400/737279 (31%)]\tLoss: 104.132759\n",
            "58.459693908691406 11.457158088684082\n",
            "Train Epoch: 16 [243200/737279 (33%)]\tLoss: 104.288330\n",
            "65.24768829345703 11.397912979125977\n",
            "Train Epoch: 16 [256000/737279 (35%)]\tLoss: 110.839340\n",
            "51.08345031738281 11.942361831665039\n",
            "Train Epoch: 16 [268800/737279 (36%)]\tLoss: 98.852898\n",
            "58.48316192626953 11.951032638549805\n",
            "Train Epoch: 16 [281600/737279 (38%)]\tLoss: 106.287292\n",
            "58.90821075439453 11.867942810058594\n",
            "Train Epoch: 16 [294400/737279 (40%)]\tLoss: 106.379982\n",
            "51.66481018066406 12.251133918762207\n",
            "Train Epoch: 16 [307200/737279 (42%)]\tLoss: 100.669342\n",
            "56.99907302856445 11.905837059020996\n",
            "Train Epoch: 16 [320000/737279 (43%)]\tLoss: 104.622421\n",
            "79.6607666015625 11.57880973815918\n",
            "Train Epoch: 16 [332800/737279 (45%)]\tLoss: 125.976006\n",
            "57.01727294921875 11.48532485961914\n",
            "Train Epoch: 16 [345600/737279 (47%)]\tLoss: 102.958572\n",
            "57.237449645996094 11.558204650878906\n",
            "Train Epoch: 16 [358400/737279 (49%)]\tLoss: 103.470268\n",
            "56.452701568603516 11.641664505004883\n",
            "Train Epoch: 16 [371200/737279 (50%)]\tLoss: 103.019363\n",
            "56.674049377441406 12.149177551269531\n",
            "Train Epoch: 16 [384000/737279 (52%)]\tLoss: 105.270760\n",
            "52.383914947509766 11.75710391998291\n",
            "Train Epoch: 16 [396800/737279 (54%)]\tLoss: 99.412331\n",
            "60.73443603515625 11.79783821105957\n",
            "Train Epoch: 16 [409600/737279 (56%)]\tLoss: 107.925789\n",
            "56.83058166503906 12.182222366333008\n",
            "Train Epoch: 16 [422400/737279 (57%)]\tLoss: 105.559471\n",
            "54.92655563354492 11.310617446899414\n",
            "Train Epoch: 16 [435200/737279 (59%)]\tLoss: 100.169022\n",
            "57.05238342285156 12.388823509216309\n",
            "Train Epoch: 16 [448000/737279 (61%)]\tLoss: 106.607681\n",
            "56.87483596801758 11.624794006347656\n",
            "Train Epoch: 16 [460800/737279 (62%)]\tLoss: 103.374008\n",
            "61.78443145751953 11.397125244140625\n",
            "Train Epoch: 16 [473600/737279 (64%)]\tLoss: 107.372932\n",
            "59.24669647216797 12.22426986694336\n",
            "Train Epoch: 16 [486400/737279 (66%)]\tLoss: 108.143776\n",
            "52.727447509765625 12.121489524841309\n",
            "Train Epoch: 16 [499200/737279 (68%)]\tLoss: 101.213409\n",
            "58.986331939697266 12.108892440795898\n",
            "Train Epoch: 16 [512000/737279 (69%)]\tLoss: 107.421906\n",
            "60.86931228637695 11.726140975952148\n",
            "Train Epoch: 16 [524800/737279 (71%)]\tLoss: 107.773880\n",
            "55.615821838378906 11.50965404510498\n",
            "Train Epoch: 16 [537600/737279 (73%)]\tLoss: 101.654434\n",
            "68.04289245605469 11.691537857055664\n",
            "Train Epoch: 16 [550400/737279 (75%)]\tLoss: 114.809044\n",
            "54.25233459472656 11.874560356140137\n",
            "Train Epoch: 16 [563200/737279 (76%)]\tLoss: 101.750580\n",
            "55.289249420166016 12.410865783691406\n",
            "Train Epoch: 16 [576000/737279 (78%)]\tLoss: 104.932709\n",
            "57.13056945800781 11.915284156799316\n",
            "Train Epoch: 16 [588800/737279 (80%)]\tLoss: 104.791702\n",
            "54.44849395751953 11.780350685119629\n",
            "Train Epoch: 16 [601600/737279 (82%)]\tLoss: 101.569901\n",
            "56.359527587890625 11.743270874023438\n",
            "Train Epoch: 16 [614400/737279 (83%)]\tLoss: 103.332611\n",
            "56.97030258178711 11.185517311096191\n",
            "Train Epoch: 16 [627200/737279 (85%)]\tLoss: 101.712372\n",
            "58.806251525878906 11.802940368652344\n",
            "Train Epoch: 16 [640000/737279 (87%)]\tLoss: 106.018013\n",
            "53.989952087402344 12.040057182312012\n",
            "Train Epoch: 16 [652800/737279 (89%)]\tLoss: 102.150177\n",
            "56.74668502807617 11.283292770385742\n",
            "Train Epoch: 16 [665600/737279 (90%)]\tLoss: 101.879852\n",
            "55.119327545166016 11.709476470947266\n",
            "Train Epoch: 16 [678400/737279 (92%)]\tLoss: 101.957230\n",
            "80.63459014892578 11.97812271118164\n",
            "Train Epoch: 16 [691200/737279 (94%)]\tLoss: 128.547089\n",
            "70.79830932617188 11.255319595336914\n",
            "Train Epoch: 16 [704000/737279 (95%)]\tLoss: 115.819588\n",
            "61.57820129394531 11.602947235107422\n",
            "Train Epoch: 16 [716800/737279 (97%)]\tLoss: 107.989990\n",
            "56.69905090332031 11.422062873840332\n",
            "Train Epoch: 16 [729600/737279 (99%)]\tLoss: 102.387299\n",
            "====> Epoch: 16 Average loss: 107.0342 \tRecon Loss: 60.1472\n",
            "195840\n",
            "56.82179260253906 11.29407024383545\n",
            "Train Epoch: 17 [0/737279 (0%)]\tLoss: 101.998077\n",
            "55.25971221923828 11.856276512145996\n",
            "Train Epoch: 17 [12800/737279 (2%)]\tLoss: 102.684814\n",
            "57.553977966308594 12.259026527404785\n",
            "Train Epoch: 17 [25600/737279 (3%)]\tLoss: 106.590088\n",
            "57.37565612792969 11.794281959533691\n",
            "Train Epoch: 17 [38400/737279 (5%)]\tLoss: 104.552780\n",
            "57.835853576660156 11.661436080932617\n",
            "Train Epoch: 17 [51200/737279 (7%)]\tLoss: 104.481598\n",
            "60.333099365234375 12.043285369873047\n",
            "Train Epoch: 17 [64000/737279 (9%)]\tLoss: 108.506241\n",
            "54.42758560180664 11.827877044677734\n",
            "Train Epoch: 17 [76800/737279 (10%)]\tLoss: 101.739090\n",
            "58.243309020996094 11.665423393249512\n",
            "Train Epoch: 17 [89600/737279 (12%)]\tLoss: 104.904999\n",
            "66.14740753173828 11.888871192932129\n",
            "Train Epoch: 17 [102400/737279 (14%)]\tLoss: 113.702896\n",
            "48.77960968017578 12.176506996154785\n",
            "Train Epoch: 17 [115200/737279 (16%)]\tLoss: 97.485641\n",
            "55.594635009765625 12.360698699951172\n",
            "Train Epoch: 17 [128000/737279 (17%)]\tLoss: 105.037430\n",
            "55.12809753417969 11.917862892150879\n",
            "Train Epoch: 17 [140800/737279 (19%)]\tLoss: 102.799545\n",
            "65.92469787597656 11.634650230407715\n",
            "Train Epoch: 17 [153600/737279 (21%)]\tLoss: 112.463303\n",
            "59.70775604248047 11.55589485168457\n",
            "Train Epoch: 17 [166400/737279 (23%)]\tLoss: 105.931335\n",
            "51.98221969604492 12.283671379089355\n",
            "Train Epoch: 17 [179200/737279 (24%)]\tLoss: 101.116905\n",
            "60.344749450683594 11.75798225402832\n",
            "Train Epoch: 17 [192000/737279 (26%)]\tLoss: 107.376678\n",
            "63.6203727722168 11.524042129516602\n",
            "Train Epoch: 17 [204800/737279 (28%)]\tLoss: 109.716537\n",
            "54.99985885620117 11.757017135620117\n",
            "Train Epoch: 17 [217600/737279 (30%)]\tLoss: 102.027924\n",
            "50.52210235595703 11.713305473327637\n",
            "Train Epoch: 17 [230400/737279 (31%)]\tLoss: 97.375320\n",
            "57.307373046875 11.732988357543945\n",
            "Train Epoch: 17 [243200/737279 (33%)]\tLoss: 104.239326\n",
            "54.334251403808594 11.898563385009766\n",
            "Train Epoch: 17 [256000/737279 (35%)]\tLoss: 101.928505\n",
            "56.90219497680664 12.308818817138672\n",
            "Train Epoch: 17 [268800/737279 (36%)]\tLoss: 106.137466\n",
            "51.068275451660156 12.294328689575195\n",
            "Train Epoch: 17 [281600/737279 (38%)]\tLoss: 100.245590\n",
            "53.545291900634766 11.808697700500488\n",
            "Train Epoch: 17 [294400/737279 (40%)]\tLoss: 100.780083\n",
            "65.85435485839844 12.237110137939453\n",
            "Train Epoch: 17 [307200/737279 (42%)]\tLoss: 114.802795\n",
            "63.30746841430664 11.781731605529785\n",
            "Train Epoch: 17 [320000/737279 (43%)]\tLoss: 110.434395\n",
            "52.75528335571289 12.39993667602539\n",
            "Train Epoch: 17 [332800/737279 (45%)]\tLoss: 102.355026\n",
            "61.3934326171875 11.805063247680664\n",
            "Train Epoch: 17 [345600/737279 (47%)]\tLoss: 108.613686\n",
            "68.30338287353516 11.890933990478516\n",
            "Train Epoch: 17 [358400/737279 (49%)]\tLoss: 115.867119\n",
            "49.709861755371094 12.202338218688965\n",
            "Train Epoch: 17 [371200/737279 (50%)]\tLoss: 98.519211\n",
            "52.867576599121094 11.533466339111328\n",
            "Train Epoch: 17 [384000/737279 (52%)]\tLoss: 99.001442\n",
            "54.283714294433594 11.675580978393555\n",
            "Train Epoch: 17 [396800/737279 (54%)]\tLoss: 100.986038\n",
            "56.491539001464844 12.029601097106934\n",
            "Train Epoch: 17 [409600/737279 (56%)]\tLoss: 104.609940\n",
            "61.06072235107422 12.160257339477539\n",
            "Train Epoch: 17 [422400/737279 (57%)]\tLoss: 109.701752\n",
            "59.975929260253906 11.717281341552734\n",
            "Train Epoch: 17 [435200/737279 (59%)]\tLoss: 106.845055\n",
            "52.16645050048828 11.782486915588379\n",
            "Train Epoch: 17 [448000/737279 (61%)]\tLoss: 99.296402\n",
            "54.67481994628906 11.667920112609863\n",
            "Train Epoch: 17 [460800/737279 (62%)]\tLoss: 101.346497\n",
            "62.150611877441406 11.337160110473633\n",
            "Train Epoch: 17 [473600/737279 (64%)]\tLoss: 107.499252\n",
            "64.20585632324219 11.65757942199707\n",
            "Train Epoch: 17 [486400/737279 (66%)]\tLoss: 110.836174\n",
            "56.35870361328125 11.689447402954102\n",
            "Train Epoch: 17 [499200/737279 (68%)]\tLoss: 103.116493\n",
            "63.77294921875 11.7225923538208\n",
            "Train Epoch: 17 [512000/737279 (69%)]\tLoss: 110.663315\n",
            "64.63188171386719 11.452619552612305\n",
            "Train Epoch: 17 [524800/737279 (71%)]\tLoss: 110.442360\n",
            "58.06849670410156 12.008285522460938\n",
            "Train Epoch: 17 [537600/737279 (73%)]\tLoss: 106.101639\n",
            "55.73491668701172 11.851789474487305\n",
            "Train Epoch: 17 [550400/737279 (75%)]\tLoss: 103.142075\n",
            "51.24037551879883 12.313451766967773\n",
            "Train Epoch: 17 [563200/737279 (76%)]\tLoss: 100.494186\n",
            "53.75019073486328 11.712270736694336\n",
            "Train Epoch: 17 [576000/737279 (78%)]\tLoss: 100.599274\n",
            "59.57074737548828 12.254983901977539\n",
            "Train Epoch: 17 [588800/737279 (80%)]\tLoss: 108.590683\n",
            "59.38096618652344 12.010315895080566\n",
            "Train Epoch: 17 [601600/737279 (82%)]\tLoss: 107.422226\n",
            "58.517112731933594 11.597726821899414\n",
            "Train Epoch: 17 [614400/737279 (83%)]\tLoss: 104.908020\n",
            "60.289886474609375 11.98703384399414\n",
            "Train Epoch: 17 [627200/737279 (85%)]\tLoss: 108.238022\n",
            "59.22828674316406 11.895549774169922\n",
            "Train Epoch: 17 [640000/737279 (87%)]\tLoss: 106.810486\n",
            "61.6705322265625 11.230060577392578\n",
            "Train Epoch: 17 [652800/737279 (89%)]\tLoss: 106.590775\n",
            "51.27973175048828 12.011743545532227\n",
            "Train Epoch: 17 [665600/737279 (90%)]\tLoss: 99.326706\n",
            "72.66045379638672 12.24576473236084\n",
            "Train Epoch: 17 [678400/737279 (92%)]\tLoss: 121.643509\n",
            "53.73487091064453 12.282062530517578\n",
            "Train Epoch: 17 [691200/737279 (94%)]\tLoss: 102.863121\n",
            "55.689064025878906 11.23246955871582\n",
            "Train Epoch: 17 [704000/737279 (95%)]\tLoss: 100.618942\n",
            "49.05730438232422 12.552749633789062\n",
            "Train Epoch: 17 [716800/737279 (97%)]\tLoss: 99.268303\n",
            "55.44220733642578 12.865644454956055\n",
            "Train Epoch: 17 [729600/737279 (99%)]\tLoss: 106.904785\n",
            "====> Epoch: 17 Average loss: 105.0963 \tRecon Loss: 57.4490\n",
            "207360\n",
            "61.00691223144531 12.019736289978027\n",
            "Train Epoch: 18 [0/737279 (0%)]\tLoss: 109.085861\n",
            "60.88325500488281 12.230596542358398\n",
            "Train Epoch: 18 [12800/737279 (2%)]\tLoss: 109.805641\n",
            "47.3407096862793 12.311737060546875\n",
            "Train Epoch: 18 [25600/737279 (3%)]\tLoss: 96.587662\n",
            "47.04704284667969 12.40925407409668\n",
            "Train Epoch: 18 [38400/737279 (5%)]\tLoss: 96.684059\n",
            "54.75460433959961 11.615443229675293\n",
            "Train Epoch: 18 [51200/737279 (7%)]\tLoss: 101.216377\n",
            "62.132843017578125 11.671133041381836\n",
            "Train Epoch: 18 [64000/737279 (9%)]\tLoss: 108.817375\n",
            "58.73283386230469 11.868948936462402\n",
            "Train Epoch: 18 [76800/737279 (10%)]\tLoss: 106.208633\n",
            "65.62060546875 11.385318756103516\n",
            "Train Epoch: 18 [89600/737279 (12%)]\tLoss: 111.161880\n",
            "61.46234893798828 11.440866470336914\n",
            "Train Epoch: 18 [102400/737279 (14%)]\tLoss: 107.225815\n",
            "61.0945930480957 11.855704307556152\n",
            "Train Epoch: 18 [115200/737279 (16%)]\tLoss: 108.517410\n",
            "61.61360549926758 11.520952224731445\n",
            "Train Epoch: 18 [128000/737279 (17%)]\tLoss: 107.697418\n",
            "48.02360534667969 12.022431373596191\n",
            "Train Epoch: 18 [140800/737279 (19%)]\tLoss: 96.113327\n",
            "56.98161697387695 11.857484817504883\n",
            "Train Epoch: 18 [153600/737279 (21%)]\tLoss: 104.411560\n",
            "69.59181213378906 11.474881172180176\n",
            "Train Epoch: 18 [166400/737279 (23%)]\tLoss: 115.491333\n",
            "55.47625732421875 12.154438018798828\n",
            "Train Epoch: 18 [179200/737279 (24%)]\tLoss: 104.094009\n",
            "56.21696853637695 12.066144943237305\n",
            "Train Epoch: 18 [192000/737279 (26%)]\tLoss: 104.481552\n",
            "56.58452606201172 12.228214263916016\n",
            "Train Epoch: 18 [204800/737279 (28%)]\tLoss: 105.497383\n",
            "55.200584411621094 11.888422966003418\n",
            "Train Epoch: 18 [217600/737279 (30%)]\tLoss: 102.754272\n",
            "53.72064971923828 12.372206687927246\n",
            "Train Epoch: 18 [230400/737279 (31%)]\tLoss: 103.209473\n",
            "55.99995040893555 12.330121994018555\n",
            "Train Epoch: 18 [243200/737279 (33%)]\tLoss: 105.320435\n",
            "59.20880889892578 12.20256233215332\n",
            "Train Epoch: 18 [256000/737279 (35%)]\tLoss: 108.019058\n",
            "63.38222885131836 11.527830123901367\n",
            "Train Epoch: 18 [268800/737279 (36%)]\tLoss: 109.493546\n",
            "57.377418518066406 11.991243362426758\n",
            "Train Epoch: 18 [281600/737279 (38%)]\tLoss: 105.342392\n",
            "55.45774841308594 11.986356735229492\n",
            "Train Epoch: 18 [294400/737279 (40%)]\tLoss: 103.403175\n",
            "62.57477951049805 11.8419189453125\n",
            "Train Epoch: 18 [307200/737279 (42%)]\tLoss: 109.942459\n",
            "57.91490173339844 12.117847442626953\n",
            "Train Epoch: 18 [320000/737279 (43%)]\tLoss: 106.386292\n",
            "59.669578552246094 12.091974258422852\n",
            "Train Epoch: 18 [332800/737279 (45%)]\tLoss: 108.037476\n",
            "56.808349609375 11.57339859008789\n",
            "Train Epoch: 18 [345600/737279 (47%)]\tLoss: 103.101944\n",
            "55.752864837646484 11.654083251953125\n",
            "Train Epoch: 18 [358400/737279 (49%)]\tLoss: 102.369202\n",
            "54.114471435546875 11.457500457763672\n",
            "Train Epoch: 18 [371200/737279 (50%)]\tLoss: 99.944473\n",
            "50.975276947021484 12.22693157196045\n",
            "Train Epoch: 18 [384000/737279 (52%)]\tLoss: 99.883003\n",
            "56.170494079589844 12.326517105102539\n",
            "Train Epoch: 18 [396800/737279 (54%)]\tLoss: 105.476562\n",
            "55.736549377441406 11.641829490661621\n",
            "Train Epoch: 18 [409600/737279 (56%)]\tLoss: 102.303864\n",
            "57.504859924316406 11.667226791381836\n",
            "Train Epoch: 18 [422400/737279 (57%)]\tLoss: 104.173767\n",
            "56.628509521484375 12.188934326171875\n",
            "Train Epoch: 18 [435200/737279 (59%)]\tLoss: 105.384247\n",
            "55.94550323486328 12.544116973876953\n",
            "Train Epoch: 18 [448000/737279 (61%)]\tLoss: 106.121971\n",
            "69.6788101196289 11.196972846984863\n",
            "Train Epoch: 18 [460800/737279 (62%)]\tLoss: 114.466705\n",
            "58.1337890625 11.286966323852539\n",
            "Train Epoch: 18 [473600/737279 (64%)]\tLoss: 103.281654\n",
            "61.802330017089844 12.130852699279785\n",
            "Train Epoch: 18 [486400/737279 (66%)]\tLoss: 110.325745\n",
            "53.170799255371094 11.87724494934082\n",
            "Train Epoch: 18 [499200/737279 (68%)]\tLoss: 100.679779\n",
            "52.709232330322266 11.649138450622559\n",
            "Train Epoch: 18 [512000/737279 (69%)]\tLoss: 99.305786\n",
            "52.591392517089844 12.207573890686035\n",
            "Train Epoch: 18 [524800/737279 (71%)]\tLoss: 101.421692\n",
            "59.51384353637695 11.749922752380371\n",
            "Train Epoch: 18 [537600/737279 (73%)]\tLoss: 106.513535\n",
            "53.625038146972656 11.901653289794922\n",
            "Train Epoch: 18 [550400/737279 (75%)]\tLoss: 101.231651\n",
            "56.68718719482422 12.321090698242188\n",
            "Train Epoch: 18 [563200/737279 (76%)]\tLoss: 105.971550\n",
            "53.72673034667969 11.500968933105469\n",
            "Train Epoch: 18 [576000/737279 (78%)]\tLoss: 99.730606\n",
            "63.39278030395508 11.657831192016602\n",
            "Train Epoch: 18 [588800/737279 (80%)]\tLoss: 110.024109\n",
            "50.980926513671875 12.065763473510742\n",
            "Train Epoch: 18 [601600/737279 (82%)]\tLoss: 99.243980\n",
            "55.695716857910156 11.7085599899292\n",
            "Train Epoch: 18 [614400/737279 (83%)]\tLoss: 102.529953\n",
            "57.443572998046875 11.868021011352539\n",
            "Train Epoch: 18 [627200/737279 (85%)]\tLoss: 104.915657\n",
            "68.14491271972656 11.590944290161133\n",
            "Train Epoch: 18 [640000/737279 (87%)]\tLoss: 114.508690\n",
            "58.02804183959961 11.489753723144531\n",
            "Train Epoch: 18 [652800/737279 (89%)]\tLoss: 103.987061\n",
            "54.371944427490234 12.151165008544922\n",
            "Train Epoch: 18 [665600/737279 (90%)]\tLoss: 102.976608\n",
            "58.46331024169922 12.292357444763184\n",
            "Train Epoch: 18 [678400/737279 (92%)]\tLoss: 107.632736\n",
            "51.4241943359375 11.901124954223633\n",
            "Train Epoch: 18 [691200/737279 (94%)]\tLoss: 99.028694\n",
            "57.92139434814453 11.953972816467285\n",
            "Train Epoch: 18 [704000/737279 (95%)]\tLoss: 105.737289\n",
            "60.74663543701172 11.79930591583252\n",
            "Train Epoch: 18 [716800/737279 (97%)]\tLoss: 107.943863\n",
            "66.44960021972656 11.4827299118042\n",
            "Train Epoch: 18 [729600/737279 (99%)]\tLoss: 112.380524\n",
            "====> Epoch: 18 Average loss: 105.1964 \tRecon Loss: 57.5998\n",
            "218880\n",
            "67.96752166748047 10.916088104248047\n",
            "Train Epoch: 19 [0/737279 (0%)]\tLoss: 111.631874\n",
            "68.57298278808594 10.969493865966797\n",
            "Train Epoch: 19 [12800/737279 (2%)]\tLoss: 112.450958\n",
            "78.94192504882812 11.282547950744629\n",
            "Train Epoch: 19 [25600/737279 (3%)]\tLoss: 124.072113\n",
            "70.04981994628906 10.94936752319336\n",
            "Train Epoch: 19 [38400/737279 (5%)]\tLoss: 113.847290\n",
            "75.30262756347656 11.090807914733887\n",
            "Train Epoch: 19 [51200/737279 (7%)]\tLoss: 119.665863\n",
            "66.82530212402344 11.88176155090332\n",
            "Train Epoch: 19 [64000/737279 (9%)]\tLoss: 114.352348\n",
            "66.00653076171875 11.954435348510742\n",
            "Train Epoch: 19 [76800/737279 (10%)]\tLoss: 113.824272\n",
            "68.58560180664062 11.142020225524902\n",
            "Train Epoch: 19 [89600/737279 (12%)]\tLoss: 113.153687\n",
            "57.82841491699219 11.251304626464844\n",
            "Train Epoch: 19 [102400/737279 (14%)]\tLoss: 102.833633\n",
            "62.177032470703125 11.813652992248535\n",
            "Train Epoch: 19 [115200/737279 (16%)]\tLoss: 109.431641\n",
            "63.96105194091797 11.695402145385742\n",
            "Train Epoch: 19 [128000/737279 (17%)]\tLoss: 110.742661\n",
            "60.911293029785156 11.66321849822998\n",
            "Train Epoch: 19 [140800/737279 (19%)]\tLoss: 107.564163\n",
            "66.34002685546875 11.074821472167969\n",
            "Train Epoch: 19 [153600/737279 (21%)]\tLoss: 110.639313\n",
            "60.882232666015625 11.470358848571777\n",
            "Train Epoch: 19 [166400/737279 (23%)]\tLoss: 106.763672\n",
            "57.98682403564453 12.33510684967041\n",
            "Train Epoch: 19 [179200/737279 (24%)]\tLoss: 107.327255\n",
            "54.452571868896484 12.31567668914795\n",
            "Train Epoch: 19 [192000/737279 (26%)]\tLoss: 103.715279\n",
            "50.530067443847656 11.999274253845215\n",
            "Train Epoch: 19 [204800/737279 (28%)]\tLoss: 98.527161\n",
            "54.36470031738281 11.653144836425781\n",
            "Train Epoch: 19 [217600/737279 (30%)]\tLoss: 100.977280\n",
            "53.688514709472656 12.138755798339844\n",
            "Train Epoch: 19 [230400/737279 (31%)]\tLoss: 102.243538\n",
            "51.999107360839844 11.808475494384766\n",
            "Train Epoch: 19 [243200/737279 (33%)]\tLoss: 99.233009\n",
            "53.691932678222656 12.426705360412598\n",
            "Train Epoch: 19 [256000/737279 (35%)]\tLoss: 103.398758\n",
            "54.0047721862793 11.733898162841797\n",
            "Train Epoch: 19 [268800/737279 (36%)]\tLoss: 100.940369\n",
            "54.98298645019531 12.067059516906738\n",
            "Train Epoch: 19 [281600/737279 (38%)]\tLoss: 103.251221\n",
            "55.145660400390625 11.835798263549805\n",
            "Train Epoch: 19 [294400/737279 (40%)]\tLoss: 102.488853\n",
            "62.04903030395508 11.341739654541016\n",
            "Train Epoch: 19 [307200/737279 (42%)]\tLoss: 107.415985\n",
            "54.70330810546875 11.614381790161133\n",
            "Train Epoch: 19 [320000/737279 (43%)]\tLoss: 101.160835\n",
            "55.31888961791992 12.061786651611328\n",
            "Train Epoch: 19 [332800/737279 (45%)]\tLoss: 103.566040\n",
            "54.17363739013672 11.972267150878906\n",
            "Train Epoch: 19 [345600/737279 (47%)]\tLoss: 102.062706\n",
            "48.51095199584961 12.133573532104492\n",
            "Train Epoch: 19 [358400/737279 (49%)]\tLoss: 97.045242\n",
            "55.61931228637695 12.53248405456543\n",
            "Train Epoch: 19 [371200/737279 (50%)]\tLoss: 105.749252\n",
            "46.08940887451172 12.354032516479492\n",
            "Train Epoch: 19 [384000/737279 (52%)]\tLoss: 95.505539\n",
            "53.17194747924805 12.229910850524902\n",
            "Train Epoch: 19 [396800/737279 (54%)]\tLoss: 102.091591\n",
            "51.55043029785156 12.032485008239746\n",
            "Train Epoch: 19 [409600/737279 (56%)]\tLoss: 99.680374\n",
            "71.79457092285156 12.510189056396484\n",
            "Train Epoch: 19 [422400/737279 (57%)]\tLoss: 121.835327\n",
            "54.863956451416016 12.196393966674805\n",
            "Train Epoch: 19 [435200/737279 (59%)]\tLoss: 103.649536\n",
            "53.22020721435547 12.044700622558594\n",
            "Train Epoch: 19 [448000/737279 (61%)]\tLoss: 101.399010\n",
            "50.316192626953125 11.949518203735352\n",
            "Train Epoch: 19 [460800/737279 (62%)]\tLoss: 98.114265\n",
            "56.46751403808594 11.952499389648438\n",
            "Train Epoch: 19 [473600/737279 (64%)]\tLoss: 104.277512\n",
            "53.442283630371094 12.177852630615234\n",
            "Train Epoch: 19 [486400/737279 (66%)]\tLoss: 102.153694\n",
            "50.13264846801758 12.440390586853027\n",
            "Train Epoch: 19 [499200/737279 (68%)]\tLoss: 99.894211\n",
            "54.52302551269531 11.864225387573242\n",
            "Train Epoch: 19 [512000/737279 (69%)]\tLoss: 101.979927\n",
            "60.695457458496094 11.229146957397461\n",
            "Train Epoch: 19 [524800/737279 (71%)]\tLoss: 105.612045\n",
            "52.94020080566406 11.841450691223145\n",
            "Train Epoch: 19 [537600/737279 (73%)]\tLoss: 100.306000\n",
            "53.9239387512207 12.342416763305664\n",
            "Train Epoch: 19 [550400/737279 (75%)]\tLoss: 103.293610\n",
            "51.59141159057617 12.056059837341309\n",
            "Train Epoch: 19 [563200/737279 (76%)]\tLoss: 99.815651\n",
            "50.64021682739258 11.925868034362793\n",
            "Train Epoch: 19 [576000/737279 (78%)]\tLoss: 98.343689\n",
            "54.36183166503906 11.844831466674805\n",
            "Train Epoch: 19 [588800/737279 (80%)]\tLoss: 101.741158\n",
            "54.238243103027344 12.419455528259277\n",
            "Train Epoch: 19 [601600/737279 (82%)]\tLoss: 103.916061\n",
            "51.00293731689453 12.196147918701172\n",
            "Train Epoch: 19 [614400/737279 (83%)]\tLoss: 99.787529\n",
            "53.7181282043457 11.992992401123047\n",
            "Train Epoch: 19 [627200/737279 (85%)]\tLoss: 101.690094\n",
            "53.21308135986328 12.021158218383789\n",
            "Train Epoch: 19 [640000/737279 (87%)]\tLoss: 101.297714\n",
            "52.68079376220703 11.578397750854492\n",
            "Train Epoch: 19 [652800/737279 (89%)]\tLoss: 98.994385\n",
            "59.241554260253906 11.705846786499023\n",
            "Train Epoch: 19 [665600/737279 (90%)]\tLoss: 106.064941\n",
            "54.313453674316406 11.877885818481445\n",
            "Train Epoch: 19 [678400/737279 (92%)]\tLoss: 101.824997\n",
            "55.70458221435547 12.11402702331543\n",
            "Train Epoch: 19 [691200/737279 (94%)]\tLoss: 104.160690\n",
            "52.03832244873047 11.892528533935547\n",
            "Train Epoch: 19 [704000/737279 (95%)]\tLoss: 99.608437\n",
            "52.823699951171875 12.143098831176758\n",
            "Train Epoch: 19 [716800/737279 (97%)]\tLoss: 101.396095\n",
            "52.747779846191406 12.108312606811523\n",
            "Train Epoch: 19 [729600/737279 (99%)]\tLoss: 101.181030\n",
            "====> Epoch: 19 Average loss: 105.2017 \tRecon Loss: 57.6611\n",
            "230400\n",
            "53.16012191772461 11.853595733642578\n",
            "Train Epoch: 20 [0/737279 (0%)]\tLoss: 100.574509\n",
            "50.82583236694336 12.197746276855469\n",
            "Train Epoch: 20 [12800/737279 (2%)]\tLoss: 99.616821\n",
            "52.22052764892578 11.923856735229492\n",
            "Train Epoch: 20 [25600/737279 (3%)]\tLoss: 99.915955\n",
            "56.51455307006836 11.998851776123047\n",
            "Train Epoch: 20 [38400/737279 (5%)]\tLoss: 104.509964\n",
            "53.97259521484375 11.647499084472656\n",
            "Train Epoch: 20 [51200/737279 (7%)]\tLoss: 100.562592\n",
            "58.78887939453125 12.465120315551758\n",
            "Train Epoch: 20 [64000/737279 (9%)]\tLoss: 108.649361\n",
            "50.89006423950195 12.93869400024414\n",
            "Train Epoch: 20 [76800/737279 (10%)]\tLoss: 102.644836\n",
            "53.37883758544922 12.17050552368164\n",
            "Train Epoch: 20 [89600/737279 (12%)]\tLoss: 102.060860\n",
            "55.602500915527344 11.955643653869629\n",
            "Train Epoch: 20 [102400/737279 (14%)]\tLoss: 103.425079\n",
            "58.80054473876953 11.614572525024414\n",
            "Train Epoch: 20 [115200/737279 (16%)]\tLoss: 105.258835\n",
            "53.070396423339844 11.86352252960205\n",
            "Train Epoch: 20 [128000/737279 (17%)]\tLoss: 100.524490\n",
            "51.44918441772461 12.01990032196045\n",
            "Train Epoch: 20 [140800/737279 (19%)]\tLoss: 99.528786\n",
            "47.11791229248047 12.06576919555664\n",
            "Train Epoch: 20 [153600/737279 (21%)]\tLoss: 95.380989\n",
            "54.30779266357422 11.784112930297852\n",
            "Train Epoch: 20 [166400/737279 (23%)]\tLoss: 101.444244\n",
            "59.362850189208984 12.052712440490723\n",
            "Train Epoch: 20 [179200/737279 (24%)]\tLoss: 107.573700\n",
            "52.769805908203125 11.96381950378418\n",
            "Train Epoch: 20 [192000/737279 (26%)]\tLoss: 100.625084\n",
            "47.674232482910156 11.844039916992188\n",
            "Train Epoch: 20 [204800/737279 (28%)]\tLoss: 95.050392\n",
            "51.812217712402344 11.983846664428711\n",
            "Train Epoch: 20 [217600/737279 (30%)]\tLoss: 99.747604\n",
            "50.559383392333984 12.138025283813477\n",
            "Train Epoch: 20 [230400/737279 (31%)]\tLoss: 99.111481\n",
            "50.41161346435547 12.379979133605957\n",
            "Train Epoch: 20 [243200/737279 (33%)]\tLoss: 99.931534\n",
            "54.99363327026367 12.148372650146484\n",
            "Train Epoch: 20 [256000/737279 (35%)]\tLoss: 103.587128\n",
            "47.68120574951172 12.2289400100708\n",
            "Train Epoch: 20 [268800/737279 (36%)]\tLoss: 96.596970\n",
            "49.33275604248047 11.939355850219727\n",
            "Train Epoch: 20 [281600/737279 (38%)]\tLoss: 97.090179\n",
            "51.864383697509766 12.786840438842773\n",
            "Train Epoch: 20 [294400/737279 (40%)]\tLoss: 103.011749\n",
            "51.933509826660156 12.260072708129883\n",
            "Train Epoch: 20 [307200/737279 (42%)]\tLoss: 100.973801\n",
            "45.26805877685547 12.415834426879883\n",
            "Train Epoch: 20 [320000/737279 (43%)]\tLoss: 94.931396\n",
            "47.51366424560547 12.890739440917969\n",
            "Train Epoch: 20 [332800/737279 (45%)]\tLoss: 99.076622\n",
            "49.96449279785156 12.2357177734375\n",
            "Train Epoch: 20 [345600/737279 (47%)]\tLoss: 98.907364\n",
            "48.68986511230469 12.10300350189209\n",
            "Train Epoch: 20 [358400/737279 (49%)]\tLoss: 97.101883\n",
            "50.02885055541992 12.238822937011719\n",
            "Train Epoch: 20 [371200/737279 (50%)]\tLoss: 98.984146\n",
            "52.97071075439453 12.33299446105957\n",
            "Train Epoch: 20 [384000/737279 (52%)]\tLoss: 102.302689\n",
            "48.11766052246094 12.247543334960938\n",
            "Train Epoch: 20 [396800/737279 (54%)]\tLoss: 97.107834\n",
            "52.11818313598633 12.354085922241211\n",
            "Train Epoch: 20 [409600/737279 (56%)]\tLoss: 101.534531\n",
            "52.1099739074707 12.049270629882812\n",
            "Train Epoch: 20 [422400/737279 (57%)]\tLoss: 100.307053\n",
            "52.6910285949707 12.25589370727539\n",
            "Train Epoch: 20 [435200/737279 (59%)]\tLoss: 101.714600\n",
            "51.30083465576172 12.288877487182617\n",
            "Train Epoch: 20 [448000/737279 (61%)]\tLoss: 100.456345\n",
            "48.733306884765625 12.436657905578613\n",
            "Train Epoch: 20 [460800/737279 (62%)]\tLoss: 98.479935\n",
            "51.985260009765625 12.65046501159668\n",
            "Train Epoch: 20 [473600/737279 (64%)]\tLoss: 102.587120\n",
            "55.47416687011719 11.806264877319336\n",
            "Train Epoch: 20 [486400/737279 (66%)]\tLoss: 102.699226\n",
            "53.407325744628906 11.779708862304688\n",
            "Train Epoch: 20 [499200/737279 (68%)]\tLoss: 100.526161\n",
            "50.176605224609375 11.964881896972656\n",
            "Train Epoch: 20 [512000/737279 (69%)]\tLoss: 98.036133\n",
            "48.57231521606445 12.434408187866211\n",
            "Train Epoch: 20 [524800/737279 (71%)]\tLoss: 98.309952\n",
            "51.69321823120117 12.193037033081055\n",
            "Train Epoch: 20 [537600/737279 (73%)]\tLoss: 100.465363\n",
            "48.524864196777344 11.975288391113281\n",
            "Train Epoch: 20 [550400/737279 (75%)]\tLoss: 96.426018\n",
            "48.649391174316406 11.717580795288086\n",
            "Train Epoch: 20 [563200/737279 (76%)]\tLoss: 95.519714\n",
            "48.887882232666016 12.150602340698242\n",
            "Train Epoch: 20 [576000/737279 (78%)]\tLoss: 97.490295\n",
            "55.54703903198242 12.277177810668945\n",
            "Train Epoch: 20 [588800/737279 (80%)]\tLoss: 104.655746\n",
            "51.37953186035156 11.967327117919922\n",
            "Train Epoch: 20 [601600/737279 (82%)]\tLoss: 99.248840\n",
            "51.273193359375 12.099071502685547\n",
            "Train Epoch: 20 [614400/737279 (83%)]\tLoss: 99.669479\n",
            "47.647193908691406 12.182293891906738\n",
            "Train Epoch: 20 [627200/737279 (85%)]\tLoss: 96.376373\n",
            "50.486846923828125 12.020444869995117\n",
            "Train Epoch: 20 [640000/737279 (87%)]\tLoss: 98.568626\n",
            "48.470611572265625 11.934946060180664\n",
            "Train Epoch: 20 [652800/737279 (89%)]\tLoss: 96.210396\n",
            "48.969459533691406 12.267383575439453\n",
            "Train Epoch: 20 [665600/737279 (90%)]\tLoss: 98.038994\n",
            "73.85856628417969 11.944478988647461\n",
            "Train Epoch: 20 [678400/737279 (92%)]\tLoss: 121.636482\n",
            "50.64048767089844 12.285697937011719\n",
            "Train Epoch: 20 [691200/737279 (94%)]\tLoss: 99.783279\n",
            "51.998023986816406 12.337021827697754\n",
            "Train Epoch: 20 [704000/737279 (95%)]\tLoss: 101.346115\n",
            "45.64374542236328 11.777987480163574\n",
            "Train Epoch: 20 [716800/737279 (97%)]\tLoss: 92.755692\n",
            "51.89314651489258 12.255573272705078\n",
            "Train Epoch: 20 [729600/737279 (99%)]\tLoss: 100.915436\n",
            "====> Epoch: 20 Average loss: 101.1148 \tRecon Loss: 52.4951\n",
            "241920\n",
            "53.230567932128906 11.723207473754883\n",
            "Train Epoch: 21 [0/737279 (0%)]\tLoss: 100.123398\n",
            "51.37224197387695 12.324088096618652\n",
            "Train Epoch: 21 [12800/737279 (2%)]\tLoss: 100.668594\n",
            "46.70365524291992 12.08456039428711\n",
            "Train Epoch: 21 [25600/737279 (3%)]\tLoss: 95.041901\n",
            "46.37890625 12.460145950317383\n",
            "Train Epoch: 21 [38400/737279 (5%)]\tLoss: 96.219490\n",
            "47.768218994140625 12.661935806274414\n",
            "Train Epoch: 21 [51200/737279 (7%)]\tLoss: 98.415962\n",
            "49.72319793701172 12.372544288635254\n",
            "Train Epoch: 21 [64000/737279 (9%)]\tLoss: 99.213379\n",
            "40.730228424072266 12.58884048461914\n",
            "Train Epoch: 21 [76800/737279 (10%)]\tLoss: 91.085587\n",
            "48.865867614746094 12.14123821258545\n",
            "Train Epoch: 21 [89600/737279 (12%)]\tLoss: 97.430817\n",
            "78.06012725830078 12.097488403320312\n",
            "Train Epoch: 21 [102400/737279 (14%)]\tLoss: 126.450081\n",
            "49.725337982177734 12.356315612792969\n",
            "Train Epoch: 21 [115200/737279 (16%)]\tLoss: 99.150604\n",
            "50.684486389160156 12.121106147766113\n",
            "Train Epoch: 21 [128000/737279 (17%)]\tLoss: 99.168915\n",
            "47.853851318359375 11.937128067016602\n",
            "Train Epoch: 21 [140800/737279 (19%)]\tLoss: 95.602364\n",
            "51.79137420654297 12.228592872619629\n",
            "Train Epoch: 21 [153600/737279 (21%)]\tLoss: 100.705750\n",
            "50.219573974609375 12.169357299804688\n",
            "Train Epoch: 21 [166400/737279 (23%)]\tLoss: 98.897003\n",
            "54.18162536621094 12.12204360961914\n",
            "Train Epoch: 21 [179200/737279 (24%)]\tLoss: 102.669800\n",
            "53.00767517089844 11.964832305908203\n",
            "Train Epoch: 21 [192000/737279 (26%)]\tLoss: 100.867004\n",
            "55.49131393432617 12.404495239257812\n",
            "Train Epoch: 21 [204800/737279 (28%)]\tLoss: 105.109299\n",
            "49.72377014160156 12.242456436157227\n",
            "Train Epoch: 21 [217600/737279 (30%)]\tLoss: 98.693596\n",
            "46.948097229003906 12.350472450256348\n",
            "Train Epoch: 21 [230400/737279 (31%)]\tLoss: 96.349991\n",
            "47.743831634521484 12.565510749816895\n",
            "Train Epoch: 21 [243200/737279 (33%)]\tLoss: 98.005875\n",
            "52.540283203125 12.51994800567627\n",
            "Train Epoch: 21 [256000/737279 (35%)]\tLoss: 102.620071\n",
            "49.77075958251953 12.08696460723877\n",
            "Train Epoch: 21 [268800/737279 (36%)]\tLoss: 98.118622\n",
            "47.97879409790039 12.508691787719727\n",
            "Train Epoch: 21 [281600/737279 (38%)]\tLoss: 98.013565\n",
            "55.509429931640625 12.361905097961426\n",
            "Train Epoch: 21 [294400/737279 (40%)]\tLoss: 104.957047\n",
            "47.161705017089844 12.199913024902344\n",
            "Train Epoch: 21 [307200/737279 (42%)]\tLoss: 95.961357\n",
            "57.18760681152344 12.536884307861328\n",
            "Train Epoch: 21 [320000/737279 (43%)]\tLoss: 107.335144\n",
            "54.57383346557617 12.788591384887695\n",
            "Train Epoch: 21 [332800/737279 (45%)]\tLoss: 105.728195\n",
            "51.64458084106445 12.735530853271484\n",
            "Train Epoch: 21 [345600/737279 (47%)]\tLoss: 102.586700\n",
            "49.61193084716797 12.419365882873535\n",
            "Train Epoch: 21 [358400/737279 (49%)]\tLoss: 99.289398\n",
            "51.54151153564453 11.627828598022461\n",
            "Train Epoch: 21 [371200/737279 (50%)]\tLoss: 98.052826\n",
            "51.48442077636719 11.950370788574219\n",
            "Train Epoch: 21 [384000/737279 (52%)]\tLoss: 99.285904\n",
            "51.89368438720703 12.070036888122559\n",
            "Train Epoch: 21 [396800/737279 (54%)]\tLoss: 100.173828\n",
            "48.88422775268555 12.425857543945312\n",
            "Train Epoch: 21 [409600/737279 (56%)]\tLoss: 98.587662\n",
            "65.07795715332031 11.892528533935547\n",
            "Train Epoch: 21 [422400/737279 (57%)]\tLoss: 112.648071\n",
            "56.32139205932617 11.621440887451172\n",
            "Train Epoch: 21 [435200/737279 (59%)]\tLoss: 102.807159\n",
            "68.91546630859375 12.013164520263672\n",
            "Train Epoch: 21 [448000/737279 (61%)]\tLoss: 116.968124\n",
            "64.05682373046875 12.020879745483398\n",
            "Train Epoch: 21 [460800/737279 (62%)]\tLoss: 112.140343\n",
            "52.52558898925781 12.106045722961426\n",
            "Train Epoch: 21 [473600/737279 (64%)]\tLoss: 100.949768\n",
            "48.37006378173828 12.412385940551758\n",
            "Train Epoch: 21 [486400/737279 (66%)]\tLoss: 98.019608\n",
            "49.734161376953125 12.467181205749512\n",
            "Train Epoch: 21 [499200/737279 (68%)]\tLoss: 99.602890\n",
            "51.351600646972656 12.63825798034668\n",
            "Train Epoch: 21 [512000/737279 (69%)]\tLoss: 101.904633\n",
            "52.29157638549805 12.307825088500977\n",
            "Train Epoch: 21 [524800/737279 (71%)]\tLoss: 101.522873\n",
            "49.36604690551758 12.12800407409668\n",
            "Train Epoch: 21 [537600/737279 (73%)]\tLoss: 97.878067\n",
            "56.030616760253906 11.77817153930664\n",
            "Train Epoch: 21 [550400/737279 (75%)]\tLoss: 103.143303\n",
            "50.95527267456055 12.352161407470703\n",
            "Train Epoch: 21 [563200/737279 (76%)]\tLoss: 100.363922\n",
            "52.82624816894531 11.761049270629883\n",
            "Train Epoch: 21 [576000/737279 (78%)]\tLoss: 99.870445\n",
            "70.25624084472656 11.219927787780762\n",
            "Train Epoch: 21 [588800/737279 (80%)]\tLoss: 115.135956\n",
            "52.75653076171875 12.276660919189453\n",
            "Train Epoch: 21 [601600/737279 (82%)]\tLoss: 101.863174\n",
            "42.525108337402344 12.286957740783691\n",
            "Train Epoch: 21 [614400/737279 (83%)]\tLoss: 91.672943\n",
            "61.48676300048828 12.10387897491455\n",
            "Train Epoch: 21 [627200/737279 (85%)]\tLoss: 109.902283\n",
            "63.17570877075195 11.866726875305176\n",
            "Train Epoch: 21 [640000/737279 (87%)]\tLoss: 110.642616\n",
            "49.75614929199219 12.286348342895508\n",
            "Train Epoch: 21 [652800/737279 (89%)]\tLoss: 98.901543\n",
            "49.3320426940918 12.405844688415527\n",
            "Train Epoch: 21 [665600/737279 (90%)]\tLoss: 98.955421\n",
            "57.83308410644531 11.999195098876953\n",
            "Train Epoch: 21 [678400/737279 (92%)]\tLoss: 105.829865\n",
            "53.10282516479492 12.149229049682617\n",
            "Train Epoch: 21 [691200/737279 (94%)]\tLoss: 101.699738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yBbtLum1NTe",
        "colab_type": "code",
        "outputId": "699b80b8-0621-4800-bef5-a874e8361edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "uploaded = drive.CreateFile({'title': \"model-epoch-50.pt\",\\\n",
        "                           \"parents\": [{\"kind\": \"drive#fileLink\",\"id\": '1wchfRZbfcdCQEHp7UJYNijVbnGOT1BU-'}]})\n",
        "torch.save(model, 'model.pt')\n",
        "uploaded.SetContentFile('model.pt')\n",
        "uploaded.Upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type VAE. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3LHPQme7TKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load('model.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpX3RPby-7Ac",
        "colab_type": "code",
        "outputId": "bbc8788f-bb60-4edb-c8ce-2a0fb89a4222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tmp = iter(dataloader)\n",
        "batch_x, batch_y  = tmp.next()\n",
        "\n",
        "output_dir = \"VAE_results/dsprites/add_label/beta_{}/latten_size_{}\".format(config.beta, config.latten_size)\n",
        "print(output_dir)\n",
        "\n",
        "def hidden_travel(images, label, neuron_id):\n",
        "    batch_y_one_hot = (label.reshape(-1, 1) == torch.arange(config.num_classes).reshape(1, config.num_classes)).float()\n",
        "    batch_y_one_hot = batch_y_one_hot.to(config.device)\n",
        "    \n",
        "    samples = images.reshape(-1, 1, config.image_size, config.image_size).to(config.device)\n",
        "    num_imgs = len(samples)\n",
        "    means, var, h = model.encode(samples)\n",
        "    result = torch.zeros((num_imgs, 22, 1, config.image_size, config.image_size))\n",
        "\n",
        "    result[:, 0] = samples\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, d in enumerate(np.linspace(-3, 3, 21)):\n",
        "            means_t = torch.clone(means)\n",
        "            means_t[:, neuron_id] = d\n",
        "            samples = model.decode(means_t, y=batch_y_one_hot).cpu()\n",
        "            samples = torch.sigmoid(samples)\n",
        "            result[:, i + 1] = samples\n",
        "    print(result.shape)\n",
        "    save_image(result.view(-1, 1, config.image_size, config.image_size), \n",
        "               '{}/travel_neuron_{}.png'.format(output_dir, neuron_id), \n",
        "               nrow=22, pad_value=255)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VAE_results/dsprites/add_label/beta_10/latten_size_10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aculBv5R-_20",
        "colab_type": "code",
        "outputId": "45cac8ae-ad12-4c43-ca1c-521d0e396800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "try:\n",
        "    os.makedirs(output_dir)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "model.eval()\n",
        "    \n",
        "# with torch.no_grad():\n",
        "#     samples = torch.randn(64, config.latten_size).to(config.device)\n",
        "#     samples = model2.decode(samples)\n",
        "#     samples = torch.sigmoid(samples).cpu()\n",
        "#     save_image(samples.view(64, 1, config.image_size, config.image_size),\n",
        "#                '{}/samples.png'.format(output_dir), pad_value=255)\n",
        "    \n",
        "    \n",
        "# with torch.no_grad():\n",
        "#     save_image(batch_x[0:32].view(-1, 1, config.image_size, config.image_size), '{}/orgin.png'.format(output_dir), pad_value=255)\n",
        "#     samples = batch_x[0:32].reshape(-1, 1, config.image_size, config.image_size).to(config.device)\n",
        "#     means, var = model2.encode(samples)\n",
        "    \n",
        "# #     mean, var, recon_x = model(samples, None)\n",
        "#     print(var)\n",
        "# #     recon_x_loss, KL_loss = loss_function(samples, mean, var, recon_x)\n",
        "# #     recon_x_loss /= len(samples)\n",
        "# #     KL_loss /= len(samples)\n",
        "# #     print(recon_x_loss.item(), KL_loss.item())\n",
        "    \n",
        "#     samples = model2.decode(means)\n",
        "#     samples = torch.sigmoid(samples).cpu()\n",
        "#     save_image(samples.view(-1, 1, config.image_size, config.image_size), '{}/reconstructed.png'.format(output_dir), pad_value=255)\n",
        "    \n",
        "    \n",
        "for neuron_id in range(0, config.latten_size):\n",
        "    hidden_travel(batch_x[0:20], batch_y[0:20], neuron_id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 17] File exists: 'VAE_results/dsprites/add_label/beta_10/latten_size_10'\n",
            "torch.Size([20, 22, 1, 64, 64])\n",
            "torch.Size([20, 22, 1, 64, 64])\n",
            "torch.Size([20, 22, 1, 64, 64])\n",
            "torch.Size([20, 22, 1, 64, 64])\n",
            "torch.Size([20, 22, 1, 64, 64])\n",
            "torch.Size([20, 22, 1, 64, 64])\n",
            "torch.Size([20, 22, 1, 64, 64])\n",
            "torch.Size([20, 22, 1, 64, 64])\n",
            "torch.Size([20, 22, 1, 64, 64])\n",
            "torch.Size([20, 22, 1, 64, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE1MB7Pq_EcU",
        "colab_type": "code",
        "outputId": "9692f439-2acc-49bd-b35f-4cb517d28da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "for f in glob.glob(\"{}/*.png\".format(output_dir)):\n",
        "    uploaded = drive.CreateFile({'title': f.split('/')[-1],  \"parents\": [{\"kind\": \"drive#fileLink\",\"id\": '1B8s6zgrNsCUcjSivvNcPY_ews2l717ui'}]})\n",
        "    uploaded.SetContentFile(f)\n",
        "    uploaded.Upload()\n",
        "    print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1niDuE1eJ__7GW5cCYya0gZIw7VZlwma7\n",
            "Uploaded file with ID 1kOq4mNdMsLlhdpgix7D7I-0Nt8JM128p\n",
            "Uploaded file with ID 1Ft2TtVIdE4noP4VE7k_ZooKvF6qc8lNT\n",
            "Uploaded file with ID 1fNp-ED_PGD8T5N_zajnjbQxb0j5ul81z\n",
            "Uploaded file with ID 1Wsye9jsqFX_oUiA-Z_OAdim2nhs01LSr\n",
            "Uploaded file with ID 1LUmZSgviGeVoRZNVlMGHSvII8GptmL3I\n",
            "Uploaded file with ID 1mnH9IuXPsGZrM7-8GpvrFOIOpVform7b\n",
            "Uploaded file with ID 1hJAcfPdMzdC2QkqOKx0WZPCGvaFjphtf\n",
            "Uploaded file with ID 1u-Eu9WnB1HQDTuk2l1h9mGWcgcoCZr-o\n",
            "Uploaded file with ID 19yhXfsqEMx9QeCu1BG0EBQIBDSyPP1lg\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}